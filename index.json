[{"authors":null,"categories":null,"content":" My evolving Brain dump ! This Documentation section contains :\n notes, quotes, summaries, tutorials, project documentation code snippets  Tools / Methodology: The above is maintained entirely with Org mode documents. Using the excellent ox-hugo library, the content is maintained in a mixture of stand-alone documents or sub-headings within larger topics. A lot of the content is now managed using the org brain package.\nNavigation Use the navigation bar on the left / right to jump to articles or sections and the search bar to find specific keywords.\n","date":1545289200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1545289200,"objectID":"4cdd37113783e47641dd300543c94e1b","permalink":"https://shrysr.github.io/docs/","publishdate":"2018-12-20T00:00:00-07:00","relpermalink":"/docs/","section":"docs","summary":"My evolving Brain dump ! This Documentation section contains :\n notes, quotes, summaries, tutorials, project documentation code snippets  Tools / Methodology: The above is maintained entirely with Org mode documents. Using the excellent ox-hugo library, the content is maintained in a mixture of stand-alone documents or sub-headings within larger topics. A lot of the content is now managed using the org brain package.\nNavigation Use the navigation bar on the left / right to jump to articles or sections and the search bar to find specific keywords.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":["Linux","bash","project"],"content":"  Table of Contents  Summary Preliminary notes: Plan Simple case Including variables for url prefix, start id and end id Figuring out a larger range  Implementing a simple conditional statement Implementing the for loop for a range \u0026gt; 500 Adding some functions and other minor streamlining  Enabling the script to be called with parameters Comparing logs for range 9998683 to 1000000 Concluding remarks References   \nSummary This project is an exploration of BASH scripting utilising cURL and diff to extract chat logs of an IRC channel and quickly compare the contents to check for any discrepancies. Several new concepts were learned, including defining variables, for loops, conditionals and making temporary files. The gradual build up in complexity is shown and has the benefit that that report can serve as a simple tutorial in BASH scripting.\nPreliminary notes:  The raw knob can be used to extract the text of the logs. The raw mechanism will spit out a maximum of 500 lines.  i.e if a user provides a large range of id\u0026rsquo;s - this will have to be split into batches of 500 lines.  W.r.t diff the focus will be on id \u0026lt; 1000,000. My initial idea to use R and connect to the db snapshot was an example of an unnecessarily bloated solution when readily available bash + curl + diff can do the job.  Plan  Create a simple case:  Use curl on raw knob links from each box \u0026gt; write this to a text file. Use diff to compare the text files.  Include variables to substitute start id and end id. Strategy for a id range above 500 Enable providing arguments (url(s), startid and endid) to supply to the bash script so it can be invoked easily from the command line.  Simple case Beginning with manually using curl.\n#!bin/bash  curl \u0026#34;http://logs.ossasepia.com/log-raw/ossasepia?istart=999600\u0026amp;iend=999700\u0026#34; \u0026gt; ~/temp/log-test.txt curl \u0026#34;http://logs.nosuchlabs.com/log-raw/ossasepia?istart=999600\u0026amp;iend=999700\u0026#34; \u0026gt; ~/temp/log2-test.txt diff -uNr ~/temp/log-test.txt ~/temp/log2-test.txt \u0026gt; ~/temp/hololo.txt Quick test of diffing post 1,000,000 id\u0026rsquo;s.\n#!bin/bash  curl \u0026#34;http://logs.ossasepia.com/log-raw/ossasepia?istart=1000000\u0026amp;iend=1000400\u0026#34; \u0026gt; ~/temp/log-test.txt curl \u0026#34;http://logs.nosuchlabs.com/log-raw/ossasepia?istart=1000000\u0026amp;iend=1000400\u0026#34; \u0026gt; ~/temp/log2-test.txt diff -uNr ~/temp/log-test.txt ~/temp/log2-test.txt \u0026gt; ~/temp/hololo.txt Including variables for url prefix, start id and end id After a few hours of head-banging using istart= 995000 and iend= 995500 - I realised that these do not exist in the ossasepia log, and I had the syntax right in my first attempt.\n#!bin/bash urlPrefix1=\u0026#34;logs.ossasepia.com/log-raw/ossasepia\u0026#34; urlPrefix2=\u0026#34;logs.nosuchlabs.com/log-raw/ossasepia\u0026#34; startid=1001700 endid=1001900 curl \u0026#34;${urlPrefix1}?istart=${startid}\u0026amp;iend=${endid}\u0026#34; \u0026gt; ~/temp/log-test.txt curl \u0026#34;${urlPrefix2}?istart=${startid}\u0026amp;iend=${endid}\u0026#34; \u0026gt; ~/temp/log2-test.txtdiff -uNr ~/temp/log-test.txt ~/temp/log2-test.txt \u0026gt; ~/temp/log-diff.txt So far, so good. Now comes the relatively tricky part: extending the above to cover more than 500 lines. This will need some conditionals and a for loop thrown in for dealing with a large range.\nFiguring out a larger range Strategy:\n Obtain a startid and endid (i.e istart and iend) If (endid-startid \u0026lt;= 500) - go ahead with directly using curl and diff. If endid-startid \u0026gt; 500  divide the number of lines by 500. Obtain the quotient and remainder. Use the quotient in a for loop as the number of times the internal startidi is incremented by 500. the internal endidi is subtracted by 1 to account for duplication of lines. Subtract the remainder from original endid to extract the last portion.   Implementing a simple conditional statement #!bin/bash urlPrefix1=\u0026#34;logs.ossasepia.com/log-raw/ossasepia\u0026#34; urlPrefix2=\u0026#34;logs.nosuchlabs.com/log-raw/ossasepia\u0026#34; startid=999700 endid=999900 rangelimit=500 let subtrid=endid-startid if [ \u0026#34;$subtrid\u0026#34; -le \u0026#34;$rangelimit\u0026#34; ] then echo \u0026#34;Lines \u0026lt;= 500. Proceeding to curl and diff.\u0026#34; curl \u0026#34;${urlPrefix1}?istart=${startid}\u0026amp;iend=${endid}\u0026#34; \u0026gt; ~/temp/log-test.txt curl \u0026#34;${urlPrefix2}?istart=${startid}\u0026amp;iend=${endid}\u0026#34; \u0026gt; ~/temp/log2-test.txt diff ~/temp/log-test.txt ~/temp/log2-test.txt \u0026gt; ~/temp/log-diff.txt else echo \u0026#34;Lines \u0026gt; 500. Additional calcs required.\u0026#34; fi Implementing the for loop for a range \u0026gt; 500 #!bin/bash urlPrefix1=\u0026#34;logs.ossasepia.com/log-raw/ossasepia\u0026#34; urlPrefix2=\u0026#34;logs.nosuchlabs.com/log-raw/ossasepia\u0026#34; startid=1001900 endid=1002900 rangelimit=500 let subtrid=endid-startid if [ \u0026#34;$subtrid\u0026#34; -le \u0026#34;$rangelimit\u0026#34; ] then echo \u0026#34;Lines \u0026lt;= 500. Proceeding to curl and diff.\u0026#34; curl \u0026#34;${urlPrefix1}?istart=${startid}\u0026amp;iend=${endid}\u0026#34; \u0026gt; ~/temp/log-test.txt curl \u0026#34;${urlPrefix2}?istart=${startid}\u0026amp;iend=${endid}\u0026#34; \u0026gt; ~/temp/log2-test.txt diff ~/temp/log-test.txt ~/temp/log2-test.txt \u0026gt; ~/temp/log-diff.txt else echo \u0026#34;Lines \u0026gt; 500. Entering Loop to split the range into batches of 500 lines.\u0026#34; let quotient=$subtrid/$rangelimit let remainder=$subtrid%$rangelimit echo $quotient echo $remainder for (( c=0; c \u0026lt;$quotient; c++ )) do let \u0026#34;startidi=$startid+ $c* $rangelimit\u0026#34; let \u0026#34;endidi=$startidi+ $rangelimit-1\u0026#34; echo $startidi echo $endidi curl \u0026#34;${urlPrefix1}?istart=${startidi}\u0026amp;iend=${endidi}\u0026#34; \u0026gt;\u0026gt; ~/temp/log-test.txt curl \u0026#34;${urlPrefix2}?istart=${startidi}\u0026amp;iend=${endidi}\u0026#34; \u0026gt;\u0026gt; ~/temp/log2-test.txt done let \u0026#34;portionstartid=$endid- $remainder\u0026#34; echo $portionstartid curl \u0026#34;${urlPrefix1}?istart=${portionstartid}\u0026amp;iend=${endid}\u0026#34; \u0026gt;\u0026gt; ~/temp/log-test.txt curl \u0026#34;${urlPrefix2}?istart=${portionstartid}\u0026amp;iend=${endid}\u0026#34; \u0026gt;\u0026gt; ~/temp/log2-test.txt diff ~/temp/log-test.txt ~/temp/log2-test.txt \u0026gt; ~/temp/log-diff.txt fi The above has been tested to work across a range of start and end ID\u0026rsquo;s.\nAdding some functions and other minor streamlining  function to check the output of curl as well as diff if empty. curl operations put into a function since repeated. Streamlined echo outputs to be more neat.   #!bin/bash urlPrefix1=\u0026#34;logs.ossasepia.com/log-raw/ossasepia\u0026#34; urlPrefix2=\u0026#34;logs.nosuchlabs.com/log-raw/ossasepia\u0026#34; startid=\u0026#34;1001900\u0026#34; endid=\u0026#34;1003700\u0026#34; log1_file=$(mktemp -t \u0026#34;$(date +\u0026#34;%Y_%H-%M-%S\u0026#34;).log1\u0026#34;) log2_file=$(mktemp -t \u0026#34;$(date +\u0026#34;%Y_%H-%M-%S\u0026#34;).log2\u0026#34;) diff_file=$(mktemp -t \u0026#34;$(date +\u0026#34;%Y_%H-%M-%S\u0026#34;).difflog\u0026#34;) rangelimit=500 let subtrid=endid-startid function check_output { echo \u0026#34;Log1 curl output is at $log1_file\u0026#34; echo \u0026#34;Log2 curl output is at $log2_file\u0026#34; echo \u0026#34;diff output is at $diff_file\u0026#34; if [ ! -s $1 ] || [ ! -s $2 ] then echo \u0026#34;Atleast One curl output returned nothing.\u0026#34; fi if [ -s $3 ] then echo \u0026#34;Diff file is not empty. Logs not equal\u0026#34; else echo \u0026#34;Diff file is empty.\u0026#34; fi } function curler { curl \u0026#34;${1}?istart=${3}\u0026amp;iend=${4}\u0026#34; \u0026gt;\u0026gt; $log1_file curl \u0026#34;${2}?istart=${3}\u0026amp;iend=${4}\u0026#34; \u0026gt;\u0026gt; $log2_file } if [ \u0026#34;$subtrid\u0026#34; -le \u0026#34;$rangelimit\u0026#34; ] then echo \u0026#34;Lines \u0026lt;= $rangelimit. Proceeding to curl and diff.\u0026#34; curler $urlPrefix1 $urlPrefix2 $startid $endid diff -uNr $log1_file $log2_file \u0026gt; $diff_file check_output $log1_file $log2_file $diff_file else echo \u0026#34;Lines \u0026gt; $rangelimit. Looping to split the range into batches.\u0026#34; let quotient=$subtrid/$rangelimit let remainder=$subtrid%$rangelimit echo \u0026#34;Batches of $rangelimitlines = $quotient. Remaining lines = $remainder\u0026#34; for (( c=0; c \u0026lt;$quotient; c++ )) do let \u0026#34;startidi=$startid+ $c* $rangelimit\u0026#34; let \u0026#34;endidi=$startidi+ $rangelimit-1\u0026#34; echo \u0026#34;istart is $startidiand iend is $endidi\u0026#34; curler $urlPrefix1 $urlPrefix2 $startidi $endidi done let \u0026#34;portionstartid=$endid- $remainder\u0026#34; echo \u0026#34;Last portion istart is $portionstartid\u0026#34; curler $urlPrefix1 $urlPrefix2 $portionstartid $endid diff -uNr $log1_file $log2_file \u0026gt; $diff_file check_output $log1_file $log2_file $diff_file fi Enabling the script to be called with parameters #!bin/bash urlPrefix1=$1 urlPrefix2=$2 startid=$3 endid=$4 log1_file=$(mktemp -t \u0026#34;$(date +\u0026#34;%Y_%H-%M-%S\u0026#34;).log1\u0026#34;) log2_file=$(mktemp -t \u0026#34;$(date +\u0026#34;%Y_%H-%M-%S\u0026#34;).log2\u0026#34;) diff_file=$(mktemp -t \u0026#34;$(date +\u0026#34;%Y_%H-%M-%S\u0026#34;).difflog\u0026#34;) rangelimit=500 let subtrid=endid-startid function check_output { echo \u0026#34;Log1 curl output is at $log1_file\u0026#34; echo \u0026#34;Log2 curl output is at $log2_file\u0026#34; echo \u0026#34;diff output is at $diff_file\u0026#34; if [ ! -s $1 ] || [ ! -s $2 ] then echo \u0026#34;Atleast One curl output returned nothing.\u0026#34; fi if [ -s $3 ] then echo \u0026#34;Diff file is not empty. Logs not equal\u0026#34; else echo \u0026#34;Diff file is empty.\u0026#34; fi } function curler { curl \u0026#34;${1}?istart=${3}\u0026amp;iend=${4}\u0026#34; \u0026gt;\u0026gt; $log1_file curl \u0026#34;${2}?istart=${3}\u0026amp;iend=${4}\u0026#34; \u0026gt;\u0026gt; $log2_file } if [ \u0026#34;$subtrid\u0026#34; -le \u0026#34;$rangelimit\u0026#34; ] then echo \u0026#34;Lines \u0026lt;= $rangelimit. Proceeding to curl and diff.\u0026#34; curler $urlPrefix1 $urlPrefix2 $startid $endid diff -uNr $log1_file $log2_file \u0026gt; $diff_file check_output $log1_file $log2_file $diff_file else echo \u0026#34;Lines \u0026gt; $rangelimit. Looping to split the range into batches.\u0026#34; let quotient=$subtrid/$rangelimit let remainder=$subtrid%$rangelimit echo \u0026#34;Batches of $rangelimitlines = $quotient. Remaining lines = $remainder\u0026#34; for (( c=0; c \u0026lt;$quotient; c++ )) do let \u0026#34;startidi=$startid+ $c* $rangelimit\u0026#34; let \u0026#34;endidi=$startidi+ $rangelimit-1\u0026#34; echo \u0026#34;istart is $startidiand iend is $endidi\u0026#34; curler $urlPrefix1 $urlPrefix2 $startidi $endidi done let \u0026#34;portionstartid=$endid- $remainder\u0026#34; echo \u0026#34;Last portion istart is $portionstartid\u0026#34; curler $urlPrefix1 $urlPrefix2 $portionstartid $endid diff -uNr $log1_file $log2_file \u0026gt; $diff_file check_output $log1_file $log2_file $diff_file fi The above script, if saved as ~/temp/log-bash-curl-diff.sh can be called as:\nsh ~/temp/log-bash-curl-diff.sh \u0026#34;logs.ossasepia.com/log-raw/ossasepia\u0026#34; \u0026#34;logs.nosuchlabs.com/log-raw/ossasepia\u0026#34; 1001900 1003700Lines \u0026gt; 500. Looping to split the range into batches. Batches of 500 lines = 3. Remaining lines = 300 istart is 1001900 and iend is 1002399 istart is 1002400 and iend is 1002899 istart is 1002900 and iend is 1003399 Last portion istart is 1003400 Log1 curl output is at /var/folders/39/l1557gl175s593l7zjj9kd640000gn/T/2019_06-37-41.log1.6FVYRfcq Log2 curl output is at /var/folders/39/l1557gl175s593l7zjj9kd640000gn/T/2019_06-37-41.log2.N73Mng1q diff output is at /var/folders/39/l1557gl175s593l7zjj9kd640000gn/T/2019_06-37-41.difflog.DwaqbBgW Diff file is not empty. Logs not equal   Comparing logs for range 9998683 to 1000000  998683 is the beginning of the ossasepia log.   sh ~/temp/log-bash-curl-diff.sh \u0026#34;logs.ossasepia.com/log-raw/ossasepia\u0026#34; \u0026#34;logs.nosuchlabs.com/log-raw/ossasepia\u0026#34; \u0026#34;998683\u0026#34; \u0026#34;1000000\u0026#34;Lines \u0026gt; 500. Looping to split the range into batches. Batches of 500 lines = 2. Remaining lines = 317 istart is 998683 and iend is 999182 istart is 999183 and iend is 999682 Last portion istart is 999683 Log1 curl output is at /var/folders/39/l1557gl175s593l7zjj9kd640000gn/T/2019_06-37-48.log1.dTY7wk3x Log2 curl output is at /var/folders/39/l1557gl175s593l7zjj9kd640000gn/T/2019_06-37-48.log2.LXpNkbWa diff output is at /var/folders/39/l1557gl175s593l7zjj9kd640000gn/T/2019_06-37-48.difflog.hKx9VdZf Diff file is not empty. Logs not equal Concluding remarks  a neat little bash script is constructed which will retrieve content from 2 specified URL\u0026rsquo;s and diff the output. Particularly, the script was constructed to compare the #o logs on logs.ossasepia.com and logs.nosuchlabs.com functions, conditionals, loops, for bash were learned and deployed, along with using curl and diff. Retrieving a large number of lines will take some time and is also dependent on the internet speed. The curl/diff files will be empty if the lines are non-existent. Diff results of the logs from line 9998683 to 1000000 indicates there are no missing lines. the check_output function only checks if the files are empty. It does not account for curl retrieving error messages. In a batch retrieval - the final curl output is checked whether empty. It does not account for empty retrievals for a particular batch. overflow/underflow is not accounted for in this script.  References  Unix SE discussion on making temporary files in bash SO discussion on making temporary files in bash Some general references for the bash syntax used above.  ","date":1569163380,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572788273,"objectID":"f022b560436510a8cd4325ffd0489a35","permalink":"https://shrysr.github.io/project/bash-scripting-mini-project/","publishdate":"2019-09-22T08:43:00-06:00","relpermalink":"/project/bash-scripting-mini-project/","section":"project","summary":"A BASH script to extract the raw text from different servers and compare them.","tags":["Linux","bash","project","shell"],"title":"Bash scripting to compare chat logs of an IRC channel","type":"project"},{"authors":null,"categories":["DataScience","R"],"content":" These are my notes while studying the research-compendium concept, which is essentially a bunch of guidelines to produce research that is \u0026lsquo;easily\u0026rsquo; reproducible.\nThe notes are mostly based on marwick-2018-packag-r , which is one canonical reading on the concept. Other references are mentioned throughout the text, and also collected separately. These notes were prepared a few weeks ago during a foray into Docker. They are neither complete not comprehensive - but will serve as a good refresher of the principle concepts.\nLanding page : contains several references explaining research-compendium. Principles  stick with the prevailing conventions of your peers / scholarly community Keep data, methods and outputs separate, but make sure to unambiguously express the connections between them. The result files should be treated disposable (can be regenerated). Specify computational environment as clearly as possible. Minimally, a text file specifying the version numbers of the software and other critical tools being used.  R\u0026rsquo;s package structure is conducive to organise and share a compendium, for any project. Dynamic documents : essentially like org files or Rmarkdown files i.e. literate programming. Sweave was originally introduced around 2002. However, around 2015 : knittr and rmarkdown made substantial progress and are in general more preferred than using sweave. Shipping data with the packages  CRAN : generally less than 5MB. A large percentage of the packages have some form of data. Data should be included if a methods package is being shipped with the analysis. use the piggyback package for attaching large datafiles to github repos.  It is convenient to be able to upload a new dataset to be associated with thep package, and this can be accessed with pb_download().  \u0026ldquo;medium\u0026rsquo; sized data files can be attached using arkdb  Adding a Dockerfile to the compendium  containerit : o2r/containerit repo to docker : jupyter/repo2docker Binder : https://mybinder.org Use the holepunch package to make the setup easier.  Summarising the folder structure for R packages esque  Readme file : self-explanatory and should be as detailed as possible, and preferably include a graphical connection between various components. R/ : Script files with resusable functions go here. If roxygen is used to generate the documentation, then man/ dicrectory is automatically populated with this. analysis/ : analysis scripts and reports. Considering using ascending names in the file names to aid clarity and order eg 001-load.R, 002 -\u0026hellip; and so on. The above does not capture the dependencies. Therefore an .Rmd or Makefile (or Makefile.R) can be included to capture the full tree of dependencies. These files control the order of execution. DESCRIPTION file in the project root provides formally structured, machine and human-readable information on authors / project license, software dependenceis and other meta data.  when this file is included, the project becomes an installable R package.  NAMESPACE: autogenerated file that exports R functions for repeated use. LICENSE : specifying conditions for use /reuse  Drone : CI service that operates on Docker containers. This can be used as a check. Makefiles  uses the make language. specifies the relationship between data, the output and the code generating the output. Defines outputs (targets) in terms of inputs (dependencies) and the code necessary to produce them (recipes). Allows rebuilding only the parts that are out of date. the remake package enables write Make like instructions in R.  Principles to consider before sharing a research compendium  Licensing, Version control, persistence, metadata : main aspects to consider. Archive a specific commit at a repository that issues persistent URL\u0026rsquo;s eg DOI which are designed to be more persistent than other URL\u0026rsquo;s. Refere re3data.org for discipline-specific DOI issuing repositories. Using a DOI simplifies citations by allowing the transfer of basic metadata to a central registry (eg CrossRef and Datacite). Doing this ensures that a publicly available snapshot of code exists that can match the results published. CRAN is generally not recommended for research-compendium packages, because it is strict about directory structures and contents of the R packages. It also has a 5MB limit for package data and documentation.  Tools and templates  devtools rrtools : extends devtools   Reference list  https://ropensci.org/commcalls/2019-07-30/?eType=EmailBlastContent\u0026amp;eId=2d18a2f6-57ef-4d15-8c52-84be5c49e039 | rOpenSci | Reproducible Research with R https://github.com/annakrystalli/rrtools-repro-research | annakrystalli/rrtools-repro-research: Tutorial on Reproducible Research in R with rrtools https://karthik.github.io/holepunch/ | Configure Your R Project for binderhub • hole punch https://github.com/karthik/holepunch | karthik/holepunch: Make your R project Binder ready https://peerj.com/preprints/3192/ | Packaging data analytical work reproducibly using R (and friends) [PeerJ Preprints] https://github.com/alan-turing-institute/the-turing-way/tree/master/workshops/build-a-binderhub | the-turing-way/workshops/build-a-binderhub at master · alan-turing-institute/the-turing-way https://github.com/alan-turing-institute/the-turing-way/tree/master/workshops | the-turing-way/workshops at master · alan-turing-institute/the-turing-way https://research-compendium.science/ | Research Compendium http://inundata.org/talks/rstd19/#/0/33 | reproducible-data-analysis https://github.com/benmarwick/rrtools | benmarwick/rrtools: rrtools: Tools for Writing Reproducible Research in R https://github.com/shrysr/correlationfunnel | shrysr/correlationfunnel: Speed Up Exploratory Data Analysis (EDA) https://github.com/cboettig/nonparametric-bayes | cboettig/nonparametric-bayes: Non-parametric Bayesian Inference for Conservation Decisions https://lincolnmullen.com/blog/makefiles-for-writing-data-analysis-ocr-and-converting-shapefiles/#fnref2 | Makefiles for Writing, Data Analysis, OCR, and Converting Shapefiles | Lincoln Mullen https://github.com/lmullen/civil-procedure-codes/blob/master/Makefile | civil-procedure-codes/Makefile at master · lmullen/civil-procedure-codes  Bibliography [marwick-2018-packag-r] @miscmarwick-2018-packag-r, DATE_ADDED = Mon Oct 14 13:55:11 2019, author = Ben Marwick and Carl Boettiger and Lincoln Mullen, doi = 10.7287/peerj.preprints.3192v2, title = Packaging data analytical work reproducibly using R (and friends), url = https://doi.org/10.7287/peerj.preprints.3192v2, year = 2018, ↩\n","date":1567401780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571087940,"objectID":"a9d6c20c20d3fba68c0ee58a4481e823","permalink":"https://shrysr.github.io/post/research-compendium/","publishdate":"2019-09-01T23:23:00-06:00","relpermalink":"/post/research-compendium/","section":"post","summary":"These are my notes while studying the research-compendium concept, which is essentially a bunch of guidelines to produce research that is \u0026lsquo;easily\u0026rsquo; reproducible.\nThe notes are mostly based on marwick-2018-packag-r , which is one canonical reading on the concept. Other references are mentioned throughout the text, and also collected separately. These notes were prepared a few weeks ago during a foray into Docker. They are neither complete not comprehensive - but will serve as a good refresher of the principle concepts.","tags":["R","Data-Science"],"title":"Some notes on research-compendium","type":"post"},{"authors":null,"categories":null,"content":"  Scheduler-Psuedo-Algorithm   Introduction Code On Github\nPresentation\nWiki on Github\nThis is a Python script for a portable, scalable job scheduler with multiple priorities - for ANSYS CFX simulations. The script was designed to be called every minute by an external scheduler program.\n In the practical case, the free version of the software System Scheduler was used to deploy the script successfully, for over 3 years, managing 2 computing clusters.  Once called, the program basically loops through pre designated folders and lists .def files based on the last modified date available in Windows. The system interaction is via BASH scripts created via the Python code, as well as the python OS library. There are several in-built flags to support priority, pausing a particular cluster, logging data and troubleshooting.\nThe idea behind the project was to create a multi-platform job scheduler for ANSYS CFX that has a balance between sophistication and ease of deployment (and management). Typically job schedulers and load balancing programs are relatively very sophisticated and complex to setup with several pre-requisites and constraints. Such complexity dictates expensive commercial support and licensing considerations.\nProblem Statement A job scheduler or simulation management system was required to address the following:\n Optimum and continuous simulation solver license utilisation by all members of the team in a First-In-First-Out (FIFO) basis, Provision for dynamic or urgent priority jobs, as well as an interface to submit simulations or view job history. Optimisation and management of workload of simulation jobs facilitating overall project management and planning.  What the program accomplished  Allowed users to submit simulations by simply placing the input files in a particular folder location, which also served as a particular priority basket. Removed the need of creating manual scripts to submit multiple simulations and resolved inefficient license utilisation approaches. Facilitated a optimised approach to certain design cases, thus resulting in a 75% reduction in simulation time Enabled the use of consistent solver and memory utilisation parameters and settings, allowing efficient deployment and reducing inefficiencies due to errors. Allowed optimal or perfect utilisation of available licensing scheme, resulting in a significant increase in team output and productivity.  Tools used and links  Written with Python 2.7, using portable python, Spyder, Notepad ++ and Sublime Text 3. System Scheduler  ","date":1565282760,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565283128,"objectID":"34fa2a56a1f01e863dea78235f90f595","permalink":"https://shrysr.github.io/project/cfx-job-scheduler/","publishdate":"2019-08-08T10:46:00-06:00","relpermalink":"/project/cfx-job-scheduler/","section":"project","summary":"`python` script to manage multi-priority ANSYS CFX simulations on distributed computing clusters","tags":["CFD","python","project"],"title":"CFX Job scheduler","type":"project"},{"authors":null,"categories":null,"content":" Me : Shreyas Ragavan I’m an engineer, dreamer, hacker and a geek who enjoys performing in-depth research and analysis, as well as developing end-to-end solutions that drive Business Intelligence and Growth.\nCurrently, I have 6+ years of work experience revolving around R\u0026amp;D, Product design, numerical simulation (CFD), Technical Sales,\nPossess a keen eye to comprehend the big picture along with a penchant towards implementing workflow automation.\nI have a deep interest in the field of Data Science and Machine Learning. My interests also extend to quantified self improvement and productivity techniques, writing, research and using Emacs for all my workflows.\nThis site  powered by Hugo hosted on a debian VPS on Linode the entire content is maintained in Org files and ox-hugo is used to export subtrees and entire files into hugo content.  ","date":1565281980,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565282716,"objectID":"405ba581599f556cd14af94d199e20b1","permalink":"https://shrysr.github.io/page/about/","publishdate":"2019-08-08T10:33:00-06:00","relpermalink":"/page/about/","section":"page","summary":"Me : Shreyas Ragavan I’m an engineer, dreamer, hacker and a geek who enjoys performing in-depth research and analysis, as well as developing end-to-end solutions that drive Business Intelligence and Growth.\nCurrently, I have 6+ years of work experience revolving around R\u0026amp;D, Product design, numerical simulation (CFD), Technical Sales,\nPossess a keen eye to comprehend the big picture along with a penchant towards implementing workflow automation.\nI have a deep interest in the field of Data Science and Machine Learning.","tags":null,"title":"About","type":"page"},{"authors":null,"categories":null,"content":" IRC @ Freenode: nick: shrysr\nI\u0026rsquo;ll respond to your messages on IRC sometime or the other. I\u0026rsquo;m basically logged in via Weechat on a tmux server, which runs on a Linux host on Linode. I use a terminal to SSH into the server. Gosh, that\u0026rsquo;s a mouthful \u0026lsquo;innit?\nCheck out Kiwi IRC, a browser based IRC client. This link will connect you to Freenode: https://kiwiirc.com/nextclient/irc.freenode.net\nCurrently, I hang around the following channels #ossasepia #emacs #trilema #gnupg #docker #org-mode.\nPublic key Use my public key available with deedbot and the WoT to send me secure messages: http://wot.deedbot.org/211A199BC99152DEFA326D792E4554DE8D51E8D9.asc\nReproduced below for convenience:\n-----BEGIN PGP PUBLIC KEY BLOCK----- mQINBF0wubgBEADG5pIBn/QcmFNQhPWtdFvzRQRZccOkCOIg5swE278oSdU41ECY QwGc976oI4pmvb7Mepun2jPX9nYrP29TzV8hEvYRpmsC8nJUb8TyRUvu5xGmurCc uM4be/CI/SfhfWsLmdsodfYuqWq4uf/JmcjhaNkDvBKkpROI8fym2OUyLkNH66XY iwFGa6xx3ScMbpJdDjNYtjwztvGfa0RcN6bSn/crdyiLReeAPzoUp+j7rXQpLWJg HBkZALWAiyZQ79GkVVkMNdGVVcvlCgPcrY6Qx88kJ6wyZ/6/cX18Cg4xdJ62kjJV lenIkK3hl5CAOdOHmVETs32AXnucTbWS01HIAXK9vrsbgDPBuBzzS9iQaCT8dn1d Vq4/StG4QIZalOyGKVPxZgTo7PQeCzQKf3RazU/noXYS7RlsxKUwTdF8j6ghp/Dn F3+2NxOsdqbnujJY9ltgf6erHqcmLsZTXfGuVuKr7uPwHX4MiMspmhIjLdfqP0FU 2bIq0KWAg1sQhUfw6zV/AGB0X+WsYuhbl4gkngVpOtToKjbf29Ki81qZGApabBrE nQ/9rIEmBrr+FB9c5QbrKWkwBSjbXmFqIRNeRs4M1OvElRpGvV9t93BxT92VQd/3 iFQmeS3WgrXCqTR+IewGZ1FH7NBT5puq1+GiK5GPc5tcu+/nwZH4nbaFuQARAQAB tChTaHJleWFzIFJhZ2F2YW4gKG1haW5zdHJlYW0pIDxzckBlbWwuY2M+iQJUBBMB CgA+FiEEIRoZm8mRUt76Mm15LkVU3o1R6NkFAl0wubgCGwMFCQWjmoAFCwkIBwIG FQoJCAsCBBYCAwECHgECF4AACgkQLkVU3o1R6NkEEg//d0CZTv1iLd0Fhu6nUAyY DJUoGUCgSW1tvLIf98NDwaryBVr3y7F4IVlUWNAsPP4hb3IeEemH4Zqm8ayYuMQV 8jstClB+XOSy/vFB0w/+ocObNiHAwlpZgNfra3RqY0kxcksxFrRlMQSdJ+tV7zsX 79lYWSfEM27HL/mkZcP85EMf4wQQQxdro66KpcH9D+EjprIe6/Q6N3+sQ7VKpbSp teOv53+CUKCvw3bny4740fEWLAY7qcq4rDU4j55jixrYS7vyUbHFOpHJWD984hfm gdE9D7HIX9ajB+OuBMQ3XppN9gpW1vqEUPlfu13VjJUlw6HYOGE5V5yFDnYUJFEy vR6drPdD5nocPJALNYmFGivGZlxcBIVwXBzjnxC/xRs0d1ZsuwxFpX9iIbdujHLX PN0LMg297MV/zMyPG+enn9pWQXkrZI962KfKuDdypOOPfWwazp5j8R8rVBuF7hUQ OZfCauRP+AwSbfZknzRXA58GCIb5ouzGsyHRdHr1W/UZVKSRGBE2MwJx/qki7I8U tbZcUCC9lyYobUTlt7KnSpDtwaisY2LPqmoE9Vkvv7Qz1aDoVoWIcFNhm9nke+FL 0GAzosPWCQSVvWzlmqC45YVWcCksqWVThKUIcj7/8H08Pt6LJZPxk2vDGp4ERcai +8sPNHWtRxD4+UU2EbQ6k2O5Ag0EXTC5uAEQALZ3hDSzh6TEsZicoHc/BS8keUbY 12l1d4eANZWuWxyKCBWudhG21i667UkxqX6pMuLCRj+39tAn6oIGvsLwr/SIwmhr SWWgP02iut/mjsRhMTyRA4Z0dmHarSbiaJm7a9GYDAYvgE3OLtGwGot2FjuIuiGe Zyh6gH9y+qwcNvEK82hPq5uliVmBYqzM+1zXzlZa5wUlYuP0Lxdip87fYk6Ixe7S 0ilu5racNLmgurOVK9SDZdM3Zksynq6/OohCiH/SqUpNEcPD5+uPtNYNmPoWdM3S ufWRfxKGWK2uxEZB3cWbO+q+dM/BWZFLT6vida07BSbgGUIPUIHz1GxkO1x6cTVX qRoubm3jUHbdKYTTMjOLXUZFwLHGoVdclgPt8L0OYY8ndFa1hq0uUVq9MdAqS7ym k02Ep9HKLI6Yeqq0vH+Yz6wxT/AXl5L8ZiBTqAVp9jEO5yA407O7IyhtfVhKw7ma 0c5tfnL2BVom8I1Gzt1UhSkmLBSfhlrp30ZzGeegh0WqWbSNjZxRI3oi1zfqbvFj I0yaOLqI3nuuiPtRWiBnHG8FHFgVLrrU3QnqSdP396VEG4hG7hO9KxY0W1PD5BeP D9OT+x2bl5NV0enAVTkRfB1a+/8TpfqnoQK/DkiOZbbojYYSSQPpAwox0H4MbneN NFBoGVn5X+ADhxT7ABEBAAGJAjwEGAEKACYWIQQhGhmbyZFS3voybXkuRVTejVHo 2QUCXTC5uAIbDAUJBaOagAAKCRAuRVTejVHo2bLiEAC7UcT29nntZzT9uNI+VQ/q 84fnVvKOF7jI41SqColOvOP3QM8i1CnxJ2MxGDjJjjd3PyQrFL7s2O7US97Kh1zD Z4IHmxftNF0hj6/9DGezlrdVdb1ZUB9wVzkhi3LPy9gwf+jRWN8ILY3C6ecUKHJP XO8t9Y5zJhLdWJ8wWpkk2TzgtSvi7/LbA4xBDFdpo1/YNfj6IOty8BENxhBLEnsp mNukaDnYxgqZq8kEW4EbGn20OAJ2gKMBS5QMWYIPh2/NUIYHQa0u9GMdhXXIMnHH /igi5ydrdCeGAEBT96hdK9w36Wucmfzh0yTdFbbNiD8ZIfXjKdUwYvBAiVUo+fAg xDNrDLKQNbGfGagZCjUEveRvU9nYnhUWURPsTI6VKf0q5tTbX7anhL+CVjKxFwXn 5cdoL2QwTbrSd8pcwNxHy3OT59StMtduNDZAlLlm86cb1+++UUNjVX5L1Tk6+396 KzZhEBtzKr3xgl5BgoAdULnKTV9nlxIAqNkwjrG4FCCQPwUU91S92IlhNq3LUD27 wcODzTnEAp0kMfy/5Oqespy9z+UGjTyQkbdQYut5/1Yi9Ua9lZPGjJi2vaZE5YT+ Xxq39eg80umkGuYnz6hZ48ekSRBXtGKe+hnW81eN/yQTolkogl96VdV3klc6jf+s wcnWSykZNTJuuFw4D2Mhrg== =Cnf3 -----END PGP PUBLIC KEY BLOCK----- keybase.io If you are on keybase, I\u0026rsquo;ve posted proof on github. If you have keybase installed, run this in a terminal\nkeybase id shrysr Github: https://github.com/shrysr\nLinked in: https://linkedin.com/in/shreyasragavan/\n","date":1565280840,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565281154,"objectID":"69f5adb59c0fc243cb31ffe8afa0550b","permalink":"https://shrysr.github.io/page/connect/","publishdate":"2019-08-08T10:14:00-06:00","relpermalink":"/page/connect/","section":"page","summary":"IRC @ Freenode: nick: shrysr\nI\u0026rsquo;ll respond to your messages on IRC sometime or the other. I\u0026rsquo;m basically logged in via Weechat on a tmux server, which runs on a Linux host on Linode. I use a terminal to SSH into the server. Gosh, that\u0026rsquo;s a mouthful \u0026lsquo;innit?\nCheck out Kiwi IRC, a browser based IRC client. This link will connect you to Freenode: https://kiwiirc.com/nextclient/irc.freenode.net\nCurrently, I hang around the following channels #ossasepia #emacs #trilema #gnupg #docker #org-mode.","tags":null,"title":"Connect","type":"page"},{"authors":null,"categories":["Emacs","Data-Science","R"],"content":" RStudio is a formidable IDE to work with and offers an environment to seamlessly work with multiple languages beyond R. It is especially convenient for tasks involving frequent visualisation of data frames and plots, and for use with Shiny app development.\nHowever, the text (i.e code) editing capabalities are still significantly lacking compared to the likes of Emacs and Vim. Besides this, it does not offer a seamless interface integrating task, time management and multi-language programming environments to the extent available within Org-mode via Emacs. Enter ESS !\nThis is an evolving document of how I use ESS and will be a useful guide to anybody starting out with ESS especially for R based workflows. My ESS configuration is mostly available in my Dotemacs documentation. However this is a deeper dive into ESS workflows for data science projects.\n Emacs Speaks Statistics (ESS) is an add-on package for GNU Emacs. It is designed to support editing of scripts and interaction with various statistical analysis programs such as R, S-Plus, SAS, Stata and OpenBUGS/JAGS. Although all users of these statistical analysis programs are welcome to apply ESS, advanced users or professionals who regularly work with text-based statistical analysis scripts, with various statistical languages/programs, or with different operating systems might benefit from it the most.\nThe rationale for developing ESS is that most statistical analysis systems provide a more or less sophisticated graphical user interface (GUI). However, their full power is only available using their scripting language. Furthermore, complex statistical analysis projects require a high degree of automation and documentation which can only be handled by creating statistical analysis scripts. Unfortunately, many statistics packages provide only weak text editor functionality and show major differences between them. Without a unified text editor user interface additional effort is required from the user to cope with limited functionality and with text editor differences.\nESS website\n Different versions of the ESS manual are available online and it is worth a frequent read to aid familiarisation with the commands and features available. The ESS mailing list is also worth subscribing to.\nResources While it seems that ESS is reasonably popular, it was surprising to find relatively few examples of configurations on the web. The Emacs ESS wikipage and Yi Tang\u0026rsquo;s Emacs configuration are among the few useful resources I\u0026rsquo;ve been able to find.\nStarting a new project Typically, I start with a fresh Org-mode document for a new project in a repository of its own. This is as easy as M-x nb-new in Scimax. This initialises a new git repository in the designated projects folder. Currently, I have each such project as a submodule of the main project repo.\nIt may seem convenient to include libraries and a variety of other customisations in the .Rrofile startup. However, as mentioned in the initial comments of this SO Discussion, in the interest of reproducibility - it is better to have a script run commands at the beginning of each session. Alternately, one could use a package like YASnippet to insert snippets of frequently used code.\nOrg documents for literate programming Being a fan of literate programming, my code is usually embedded into Org-babel source blocks in line with the explanations or analysis.\nFor longer projects, I often define a Yasnippet extension for the source code blocks specifying a unique session name to cater to that project. This prevents mixing up of variables and environments between projects as I switch, and I can search and insert snippets with the handy ivy-yasnippet package that allows previews of snippets before insertion.\nTypically, I enter the major mode from the Org-Babel source block (C-c ' inside a source block) to enable access to mode specific features like command completion, variable access and so on.\n It is worth noting that when entering a major mode from a source block, the correct or desired ESS process has to be attached, especially if you are simultaneously using multiple sessions. This can be done with the C-c C-s command after entering the major mode buffer.\n Frequently used ESS commands Though there are many commands available - the ones listed below are worth noting. Going through the ESS manual is definitely worth the effort to understand detailed descriptions of these commands. Another simple way to search for commands within ESS is using the M-x command and type in \u0026lsquo;ess\u0026rsquo; to view the commands available.\n M-p, M-n : Previous and next command in comint input history. M-r : Regex search of input history C-c C-x : List of objects in the environment. Prepend C-u to print to console. Note that it is possible to list commands of libraries by prepending numbers to C-c C-x. The default prefix is the global environment, which is a prefix of 1, i.e C-1 C-c C-x. C-c C-v : Help at point. C-c C-q : Ess-quit. This is important to use when exiting an R session. Using this makes sure that temporary buffers are quit. Such buffers can pile up very easily as you use the help documentation. C-c C-z : Switch between the R script and the process buffer. This is a nifty feature especially when when using C-M-x : Sends the current selected region or function or paragraph. C-c C-d v: (ess-display-vignettes) this is a handy method to browse all the available vignettes. This opens up a buffer, which contains links to vignettes in multiple formats (PDF, Rmd, Rnw). Note that the vignettes of a newsly installed package is loaded only after being loaded with the library function. C-e w : Resizing the display to adapt to a buffer that has changed dimension. i.e if I split the R terminal buffer which changes it\u0026rsquo;s size - this command will enable the output to be better adjusted to the buffer size and thus enable better readability.  Window configuration The ESS manual has a helpful snippet if you prefer your window arrangement similar to Rstudio\u0026rsquo;s, which is quite sensible as such. The width values can be modified as required.\n(setq display-buffer-alist `((\u0026#34;*R Dired\u0026#34; (display-buffer-reuse-window display-buffer-in-side-window) (side . right) (slot . -1) (window-width . 0.33) (reusable-frames . nil)) (\u0026#34;*R\u0026#34; (display-buffer-reuse-window display-buffer-at-bottom) (window-width . 0.35) (reusable-frames . nil)) (\u0026#34;*Help\u0026#34; (display-buffer-reuse-window display-buffer-in-side-window) (side . right) (slot . 1) (window-width . 0.33) (reusable-frames . nil)))) Rmarkdown : Polymode Polymode makes it easy to work with Rmd, Rnw, Snw format documents within Emacs. The only configuration necessary for this Is\n(require \u0026#39;poly-markdown) (require \u0026#39;poly-R) ;; MARKDOWN (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\\\.md\u0026#34; . poly-markdown-mode)) ;; R modes (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\\\.Snw\u0026#34; . poly-noweb+r-mode)) (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\\\.Rnw\u0026#34; . poly-noweb+r-mode)) (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\\\.Rmd\u0026#34; . poly-markdown+r-mode)) TODO Exporting When sharing documents, it is necessary to convert to a format non-Emacs users can user. My current approach is to use ox-ipynb package to export to as a jupyter notebook, and then the excellent jupytext package to convert to Rmd.\n","date":1552671780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562788452,"objectID":"03636e32b2bed1c7bfd34aaa37a46331","permalink":"https://shrysr.github.io/docs/ess-datascience-r/","publishdate":"2019-03-15T11:43:00-06:00","relpermalink":"/docs/ess-datascience-r/","section":"docs","summary":"RStudio is a formidable IDE to work with and offers an environment to seamlessly work with multiple languages beyond R. It is especially convenient for tasks involving frequent visualisation of data frames and plots, and for use with Shiny app development.\nHowever, the text (i.e code) editing capabalities are still significantly lacking compared to the likes of Emacs and Vim. Besides this, it does not offer a seamless interface integrating task, time management and multi-language programming environments to the extent available within Org-mode via Emacs.","tags":["Emacs","ESS","R","Data-Science"],"title":"Using ESS for Data Science","type":"docs"},{"authors":null,"categories":["Emacs"],"content":"TLDR: Check out the Docs section for my Emacs config in Org-mode\n The literate programming paradigm, as conceived by Donald Knuth, represents a move away from writing programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts. Literate programs are written as an uninterrupted exposition of logic in an ordinary human language, much like the text of an essay, in which macros are included to hide abstractions and traditional source code.\nWikipedia article on Literate Programming\n I had graduated to using an Org-mode based configuration with vanilla Emacs, until discovering Scimax a few years ago. At this point, it seemed easier to switch back to using elisp script files in multiple files which were loaded in the desired / necessary order. The plan was to use a file for each major \u0026lsquo;concept\u0026rsquo;, for example one file each for hydras, Org-mode, mu4e, and so on.\nWhile it is not difficult to manage multiple script files with the projectile package, it does become cumbersome and inelegant to record notes and thoughts in the comment form along with code. Over time, it also becomes difficult to decide the placement of multi-package functions and snippets. As my configuration has evolved - I\u0026rsquo;ve felt an increasing need to shift back to a literate configuration using Org for Emacs, and also separate the personal parts of my configuration to enable sharing on Github.\nUsing a literate configuration enables a live documentary of my Emacs configuration and also adding meaningful notes and snippets which are directly or indirectly related to configuring Emacs. For example, it is important to have IPython and Jupyter installed for Scimax to work correctly, and I can include notes and working scripts for the same.\nThere are discussions on Emacs init time increasing by using a tangled org file. However, this is atleast partially remedied by including a function to tangle the config file whenever it is saved, and there are other methods like the one described by Holger Schurig, which I intend to try out soon. Personally, I have not found any degrade in Emacs init time via Scimax.\n","date":1550415720,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562463793,"objectID":"1b82caa706de7acaa1616e075db3b5b0","permalink":"https://shrysr.github.io/post/d16caa34-c2e2-439b-894f-d95be5708160/","publishdate":"2019-02-17T08:02:00-07:00","relpermalink":"/post/d16caa34-c2e2-439b-894f-d95be5708160/","section":"post","summary":"TLDR: Check out the Docs section for my Emacs config in Org-mode\n The literate programming paradigm, as conceived by Donald Knuth, represents a move away from writing programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts. Literate programs are written as an uninterrupted exposition of logic in an ordinary human language, much like the text of an essay, in which macros are included to hide abstractions and traditional source code.","tags":["Emacs","Org-mode","lisp"],"title":"Literate Org-mode configuration for Emacs is liberating","type":"post"},{"authors":null,"categories":["general","Productivity"],"content":"While reading the book Atomic Habits by James Clear, I was reflecting that my choice of embracing Emacs and progressively gaining mastery over it was intimately connected with the philosophy preached in the book.\nMy efforts initially started out with a craving for a system to quantify and manage my tasks, habits, notes, blog writing, job applications and projects in a custom environment, and to be able to build toolkits of code to perform repetitive tasks. As mentioned in an earlier blog post , I tried several approaches before settling on Emacs. The idea was to find or create a single system to track everything of importance in my life (with ease and efficiency). This was instead of a fragmented approach of using multiple tools and techniques, for example, Sublime Text / Atom as a text editor and Todoist as a task management tool.\nI started with a vanilla configuration of Emacs and painstakingly borrowed (and eventually) modified lisp snippets to implement desired \u0026lsquo;features\u0026rsquo; or behaviors. It was a just a couple of features every week, initially focused on Org mode\u0026rsquo;s behavior alone. That was nearly 3 years ago. As of now, I am able to manage my blog [hugo], view my email [mu4e], browse the web [w3m], seamlessly capture notes / ideas / tasks from (almost) anywhere [Org mode], chat on IRC, build multi-language code notebooks with ease [Org babel]. All the above provide me significant advantages in speed and efficiency which still have plenty of potential to improve.\nSure, I certainly appear closer to my goal today.. however, I did not know if it was a pipe dream when I started out. It was often extremely frustrating, right from memorizing the \u0026lsquo;crazy\u0026rsquo; keybindings in Emacs, to struggling with getting a lisp snippet to work as expected.\nChoosing Emacs had unexpected rewards as well. For example, the need of synchronizing my notes and Emacs configuration with multiple machines led me to Git. Magit\u0026rsquo;s easily accessible commands and relatively visual interface has been a massive help in getting things done with Git, despite not having any deep technical knowledge of how Git works.\nMy journey with Emacs is testament that an incremental, compounding improvement over time can ultimately result in significant gains. It is also important to acknowledge that I am standing on the shoulder of giants and the awesome Scimax is a cornerstone in my toolkit.\n","date":1547951580,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562857746,"objectID":"fdccb9e1e5640af8c82669cf55387060","permalink":"https://shrysr.github.io/post/32266f09-c9b9-48ff-9c48-e2348eeda33d/","publishdate":"2019-01-19T19:33:00-07:00","relpermalink":"/post/32266f09-c9b9-48ff-9c48-e2348eeda33d/","section":"post","summary":"While reading the book Atomic Habits by James Clear, I was reflecting that my choice of embracing Emacs and progressively gaining mastery over it was intimately connected with the philosophy preached in the book.\nMy efforts initially started out with a craving for a system to quantify and manage my tasks, habits, notes, blog writing, job applications and projects in a custom environment, and to be able to build toolkits of code to perform repetitive tasks.","tags":["Emacs","Org-mode"],"title":"Incremental improvements can lead to significant gains","type":"post"},{"authors":null,"categories":["DataScience"],"content":"A slide deck from Netflix, mentions using Nteract as their programming notebook, and prompted a mini exploration.\nThis blog post by Safia Abdalla, (a maintainer/ developer of Nteract) introduces Nteract as an open source, desktop-based, interactive computing application that was designed to overcome a bunch of limitations in Jupyter Notebook\u0026rsquo;s design philosophy. One key difference (among many others) is the ability to execute code in a variety of languages within a single notebook, and it also appears that that the electron based desktop app should make it easier for beginners to start coding.\nAlong similar lines, this blog post is a nice primer to the evolution of Ipython, Jupyter Notebooks and Nteract, from the plain vanilla Python console, which was the starting point. Beyond the illuminating definition that the Jupyter notebook is an \u0026lsquo;establishment of well-defined protocols and formats\u0026rsquo;, and is not just a console or a programming notebook, the blog post provides a deeper insight into how these protocols are implemented and communicate with interpreters or Jupyter kernels.\nThis reddit discussion has a few interesting pros and cons regarding using nteract.\nWhile I can see the value of computing notebooks like Jupyter and Nteract, I do think that these do not come close to the functionality and ease that can be achieved with Org mode and Emacs, which have been in existence a lot longer. I was able to intuitively transition to using multiple language code \u0026lsquo;notebooks\u0026rsquo; using Org mode. This reddit thread and blog post elucidate the advantages of using Babel and Org mode over Jupyter notebooks.\n","date":1547951400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562438036,"objectID":"8055a28ad7391e622d83f47dfbac9ed6","permalink":"https://shrysr.github.io/post/a642fab6-6704-4e57-9f97-43e7dd8d9caa/","publishdate":"2019-01-19T19:30:00-07:00","relpermalink":"/post/a642fab6-6704-4e57-9f97-43e7dd8d9caa/","section":"post","summary":"A slide deck from Netflix, mentions using Nteract as their programming notebook, and prompted a mini exploration.\nThis blog post by Safia Abdalla, (a maintainer/ developer of Nteract) introduces Nteract as an open source, desktop-based, interactive computing application that was designed to overcome a bunch of limitations in Jupyter Notebook\u0026rsquo;s design philosophy. One key difference (among many others) is the ability to execute code in a variety of languages within a single notebook, and it also appears that that the electron based desktop app should make it easier for beginners to start coding.","tags":["Data-Science"],"title":"Nteract : An interactive computing environment","type":"post"},{"authors":null,"categories":["Emacs","Productivity"],"content":"The primary power of Emacs is that you can create customised workflows to suit your needs. However, lisp is probably not a language that many learn as a typical requirement in the academic systems, perhaps even for a software engineer.\nHow would one then start customisting Emacs? One way would be to hunt for snippets from forums like reddit and stack overflow, and customise them.\nAnother easy way to learn a programming language, especially one that is intrinsic to a software is to record macros and edit these macros. Emacs is no different in this regard, and in fact makes it easy being a self-documenting text editor.\nThe elmacro package reduces some of the burden. The recorded macro does require a subsequent clean-up to be useful, which is still easier than coding lisp from scratch. In any case, exploring the recorded code will eventuall lead towards proficiency in writing lisp.\nThis blog post provides a more detailed introduction, including creating a menu entry for elmacro. As highlighted by the blog, some commands do not register in Emacs, since external packages handle those functions.\nFor example, I have 3 main repositories where I commit my work. This is a frequent, repetitive process that is often done till (and at) the last minute.\nThese are snippets that were developed leveraging elmacro:\n;; Maximise current frame, open scimax user directory, ;; call magit, switch window and open the scimax directory ;; Scimax magit status and dired (defun sr/windows-magit-scimax () (interactive) (ace-delete-other-windows) (dired \u0026#34;~/scimax/user/\u0026#34;) (switch-window-then-split-right nil) (magit-status \u0026#34;~/scimax/\u0026#34;) (switch-window) (split-window-vertically) (dired-up-directory) (windmove-right) ) ;; Maximise current frame, open org directory, call magit ;; my_org magit status (defun sr/windows-magit-org () (interactive) (ace-delete-other-windows) (magit-status \u0026#34;~/my_org/\u0026#34;) ) ;; Maximise current frame, call magit for my_projects directory ;; split buffer and call dired in case I need to navigate to a particular directory. ;; the latter can also be done via magit itself if desired. (defun sr/windows-magit-projects () (interactive) (ace-delete-other-windows) (switch-window-then-split-right nil) (magit-status \u0026#34;~/my_projects/\u0026#34;) (switch-window) (dired \u0026#34;~/my_projects/\u0026#34;) (switch-window) ) Another more complicated example, is using projectile to switch to a project, call a particular file in the project and then split the buffer and open the tasks of that particular project with a narrowed view.\nI capture each project\u0026rsquo;s tasks and notes separately in an org file using org-projectile. This is useful especially for coding projects so that the code is better separated from notes and yet linked.\n;; This is to rapidly switch between projects and have a similar window configuration, ;; i.e. a main file, and a narrowed view of the tasks heading. (defun sr/windows-projects () (interactive) (ace-delete-other-windows) (switch-window-then-split-right nil) (projectile-switch-project) (switch-window) (find-file \u0026#34;~/my_org/project-tasks.org\u0026#34;) (widen) (helm-org-rifle-current-buffer) (org-narrow-to-subtree) (outline-show-children) ) These are not perfect. For example, I\u0026rsquo;d rather have to select the project name only once and have that feed into helm-org-rifle. These are topics of future exploration.\nWhat then remained was being able call these functions with a few keypresses. Hydras enable this.\n(defhydra sr/process-window-keys () \u0026#34; Key^^ ^Workflow^ -------------------- o org magit s scimax magit p projects magit w select project and set window config SPC exit \u0026#34; (\u0026#34;o\u0026#34; sr/windows-magit-org ) (\u0026#34;p\u0026#34; sr/windows-magit-projects ) (\u0026#34;s\u0026#34; sr/windows-magit-scimax ) (\u0026#34;w\u0026#34; sr/windows-projects) (\u0026#34;SPC\u0026#34; nil) ) (global-set-key (kbd \u0026#34;\u0026lt;f8\u0026gt; m\u0026#34;) \u0026#39;sr/process-window-keys/body) With the above in place, now all I have to do is call the menu to choose the desired function by typing F8 m and then type o or p and so on. The hydra exits with Space, which makes it easy to switch to another project in case there is nothing to commit in the current choice.\nThough simple and in many ways primitive - these functions have still saved me a lot of repetitive acrobatics on my keyboard and I enjoy using Them.\n","date":1549127760,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562463820,"objectID":"14cf9e0dca916f2f8ff99e6c94443918","permalink":"https://shrysr.github.io/post/7b7b94ca-2d77-4814-8cae-c9e95d3f8bc4/","publishdate":"2019-02-02T10:16:00-07:00","relpermalink":"/post/7b7b94ca-2d77-4814-8cae-c9e95d3f8bc4/","section":"post","summary":"The primary power of Emacs is that you can create customised workflows to suit your needs. However, lisp is probably not a language that many learn as a typical requirement in the academic systems, perhaps even for a software engineer.\nHow would one then start customisting Emacs? One way would be to hunt for snippets from forums like reddit and stack overflow, and customise them.\nAnother easy way to learn a programming language, especially one that is intrinsic to a software is to record macros and edit these macros.","tags":["Emacs","lisp"],"title":"Leverage recorded macros to learn elisp and hack together workflows in Emacs","type":"post"},{"authors":null,"categories":["DataScience"],"content":"Title: Navigating Diverse Data Science Learning: Critical Reflections Towards Future Practice\nAuthor: Yehia Elkhatib\nDownload link\nThis are my notes on the above paper, which mainly deals with detailing the methods explored and implemented to impart a high quality of education in data science. The paper also provides an interesting breakup of the different roles in data science workflows.\n The importance of being able to work in a team is highlighted. Working in isolation for a data scientist almost renders the results meaningless.\n Considering the typically diverse backgrounds of DS practitioners, it is difficult to devise a curriculum that caters to everybody. This factor is certainly critical to consider before taking up any formal university courses. I would not want to spend a great deal of time and money in learning obsolete techniques or technologies.\n There are differences in learning rates based on the background, and past academic environments. In particular, most students do not seem to realize that the best learning takes place in a \u0026lsquo;social\u0026rsquo; manner. Besides addressing the above, several aspects of effective learning and aligning the curriculum and teaching methodology to the typical industrial workflows are explored in this paper.\n The literature references of past studies and research would certainly make interesting reads. However, they are more relevant to those in the teaching line. An interesting approach would be to read between the lines to extract the best practices for students to learn rapidly and effectively. However, there are many direct resources and techniques to approach the latter.\n DS Roles :- Core.\n Janitor  data cleaning, pre-processing  Scout  EDA, early insights  Analyst  identifying patterns, initial hypothesis, evidence of unforeseen narratives)  Decision Builder  automate decision making, ML, DL  Curator  storage formats across interfaces, data governance  Engineer  Manage the interface between development and production products, efficiency and reliability of data interaction.   Auxiliary roles : these roles come into the picture as the DS team grows.\n Domain specialist  data significance, sources of bias  Infrastructure manager  support to build and operate, beyond the data engineer  Communicator  Communicating explanatory and confirmatory analyses, setting up systems to interact with the audiences outside the DS team  Facilitator  A/B experiments, additional support to the communicator.    ","date":1547951400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562438009,"objectID":"423a87faca6f8f66b184e79e3cd9fe88","permalink":"https://shrysr.github.io/post/44d30b28-0de8-4211-afad-18fe22323bf3/","publishdate":"2019-01-19T19:30:00-07:00","relpermalink":"/post/44d30b28-0de8-4211-afad-18fe22323bf3/","section":"post","summary":"Title: Navigating Diverse Data Science Learning: Critical Reflections Towards Future Practice\nAuthor: Yehia Elkhatib\nDownload link\nThis are my notes on the above paper, which mainly deals with detailing the methods explored and implemented to impart a high quality of education in data science. The paper also provides an interesting breakup of the different roles in data science workflows.\n The importance of being able to work in a team is highlighted.","tags":["Paper-review"],"title":"Technical notes : Research paper on learning/teaching data science","type":"post"},{"authors":null,"categories":["Emacs","Productivity"],"content":"I\u0026rsquo;ve written several posts on different ways and tools available to aid productivity, and probably a lot about Emacs. My background is in computational physics, and not in programming, and yet Emacs has been an indispensable driver of my daily workflow for the past 3 years.\nThe fact is that knowing Emacs (or Vim), or having a custom configuration is not a wildly marketable skill, nor is it mandatory to achieve spectacular results. An Emacs configuration suits personal workflows and style, which may be borderline peculiar to another person. Such a dependence on customised tools would also drastically reduces your speed while using a new IDE or text editor.\nSo : why add Emacs to the ever-growing to-do list? The question is more pertinent considering that mastery of a \u0026lsquo;text editor\u0026rsquo; is not something you can freely talk about and frequently expect empathetic responses or even a spark like connection. Emacs would be considered by many to be an esoteric and archaic software with a steep learning curve that is not beginner friendly.\nHowever \u0026hellip;..\nThis article elucidates many points where Emacs can help PHB\u0026rsquo;s (Pointy Haired Boss). The internet abounds with several examples on how org-mode and Emacs have changed lives for the better. Here is another cool article by Howard Abrams on using Emacs as his (only) window manager, in place of a desktop environment.\nWatching an experienced person handle his tools emphasises the potential art form behind it, especially when compared to the bumbling of an amateur. Yes, the amateur may get the job done given enough time, and depending on his capabilities - even match the experienced professional\u0026rsquo;s output (eventually).\nHowever, as experience is gained, the workflows and steps to achieve an optimal result become more lucid. I\u0026rsquo;ve experienced an exponentially increasing and compelling need to implement specific preferences to achieve the required optimized results faster and with fewer mistakes.\nIt is therefore obvious that the workflow and tools used must allow the provision to evolve, customise and automate. This is particularly true with respect to the world of data science and programming. I don\u0026rsquo;t think there is anything better than Emacs with respect to customisation.\nImagine the following:\n having a combination of scripts or snippets in different languages to jumpstart a project, which is available with a few keypresses? (Yasnippet)1 Maintaining a blog with a single document, with articles updated automatically on a status change. (ox-hugo) working with multiple R environments in a single document. (Org-babel, ESS)2 Different Window configurations and processes for different projects that can be called with a few keypresses (hint : keyboard macros) An integrated git porcelain that can actually help you learn git so much faster (magit) Intimately integrating email with tasks, projects, documentation and workflows (mu4e, Org-mode) A customised text editor available right in your terminal (Use Emacsclient launched off a daemon within a terminal) Not requiring to use the mouse for navigation!3  Now : imagine the consolidated effect of having all the above at your disposal, in a reasonably streamlined state. Then, considering the cumulative effect over multiple projects! The above is just a shallow overview of the possibilities with Emacs.\nInvesting in learning Emacs, has the serious potential to spawn exponential results in the long run.\n Articles on using Yasnippet: \u0026mdash; Using Emacs Yasnippet against repetitive boileplate code || Tweaking Emacs Yasnippet || Expanding snippets\r^ Links to using R with Emacs: Using R with Emacs and ESS || Using R with Emacs || Tips from R Coders who use ESS || Why I use Emacs for R programming\r^ See this article of a non-technical user\u0026rsquo;s experiment with not using the mouse, reporting significant gains in speed and productivity. I\u0026rsquo;ve experienced this myself after gaining basic proficiency in moving around Emacs.\r^   ","date":1562349720,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562437825,"objectID":"f2af00e15e37e0cb570a35f65a51345e","permalink":"https://shrysr.github.io/post/11ef85e6-9efc-4af4-b5f3-7648f9ee9308/","publishdate":"2019-07-05T12:02:00-06:00","relpermalink":"/post/11ef85e6-9efc-4af4-b5f3-7648f9ee9308/","section":"post","summary":"I\u0026rsquo;ve written several posts on different ways and tools available to aid productivity, and probably a lot about Emacs. My background is in computational physics, and not in programming, and yet Emacs has been an indispensable driver of my daily workflow for the past 3 years.\nThe fact is that knowing Emacs (or Vim), or having a custom configuration is not a wildly marketable skill, nor is it mandatory to achieve spectacular results.","tags":["Emacs","yasnippet"],"title":"Why bother with Emacs and workflows?","type":"post"},{"authors":null,"categories":["Emacs","DataScience"],"content":"Matt Dancho\u0026rsquo;s course DSB-101-R is an awesome course to step into ROI driven business analytics fueled by Data Science. In this course, among many other things - he teaches methods to understand and use cheatsheets to gain rapid level-ups, especially to find information connecting various packages and functions and workflows. I have been hooked to this approach and needed a way to quickly refer to the different cheatsheets as needed.\nFavio Vazquez\u0026rsquo;s ds-cheatsheets repo, akin to the One Ring to Rule them All (with respect to Cheatsheets of course), combined with Emacs (Projectile + Helm packages) make it almost a breeze to find a specific cheatsheet quickly, by just typing in a few words.\u0026nbsp;1\nThe built-in Hydras in Scimax make it very easy to do the above with a few key presses. All I do is F12 \u0026gt;\u0026gt; p \u0026gt;\u0026gt; ww, start typing in \u0026ldquo;ds-\u0026rdquo; and choose the project and then start typing in the name of the PDF file I\u0026rsquo;m looking for. Check out the animation below.\n Rapidly switching to a cheatsheet PDF   The above concept applies to switching to any file in any git based project that is added to Projectile\u0026rsquo;s lists.\nThe next aspect to consider was switching between maximized buffer of the opened cheatsheet PDF and the current code buffer. As it goes in Emacs, \u0026ldquo;there\u0026rsquo;s probably a package for that..\u0026rdquo; ! My solution was to use one of the various frame/window configuration packages in Emacs to save the position and orientation of the buffers and rapidly switch between the maximised PDF frame and the split code and interpreter frames.\nFacilitating the above was in fact already available in Scimax, where a frame or window configuration can be saved into a register that is valid for that session. Persistent saving of window configuration across sessions (i.e Emacs restarts) is a little more complex, but it is still possible with some tweaking. Winner-mode is also an interesting option to switch rapidly between window configurations.\n To some extent, it is also possible that launchers like the Alfred app could be set or programmed to search in particular locations. This is a less hacky and still a functional option for Mac users.\r^   ","date":1549128240,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562437932,"objectID":"497cec360d5bd8f945e2a1734e1a243a","permalink":"https://shrysr.github.io/post/e86e171e-cc0d-4957-b587-ed2bbf36a8cf/","publishdate":"2019-02-02T10:24:00-07:00","relpermalink":"/post/e86e171e-cc0d-4957-b587-ed2bbf36a8cf/","section":"post","summary":"Matt Dancho\u0026rsquo;s course DSB-101-R is an awesome course to step into ROI driven business analytics fueled by Data Science. In this course, among many other things - he teaches methods to understand and use cheatsheets to gain rapid level-ups, especially to find information connecting various packages and functions and workflows. I have been hooked to this approach and needed a way to quickly refer to the different cheatsheets as needed.","tags":["Data-Science"],"title":"Rapidly accessing cheatsheets to learn data science with Emacs","type":"post"},{"authors":null,"categories":["general","Productivity"],"content":" Why use RSS? Off late, I had been relying more on email based content consumption. The phenomenally fast search and filtering capabilities that can be leveraged with mu4e make this easy.\nEven with all these filters, it is quite difficult to keep on top of news and information from different sources. It is actually inconvenient to mix important emails and correspondence with newsletters and the like, which arrive by the dozen(s) everyday.\nThere\u0026rsquo;s also a nagging feeling that relevant and \u0026lsquo;up to date\u0026rsquo; information is better searched through Google, with a fresh search each time. This approach invites distractions. One remedy is to link a google news feed of a search term into your RSS.\nI\u0026rsquo;ve always liked RSS, however, the exploration made me actually realise that a dedicated RSS reader could inspire focused reading and aid in retention of information, and could be a better option than flooding my inbox.\nAn all-in-one solution for reading RSS feeds with a capable in-built browser to view images/webpages/videos would be excellent, along with the ability to sync with multiple services and facilitate capturing notes.\nExploration: Within Emacs - Elfeed (along with Elfeed-goodies) is a good option to read feeds and is strongly integrated with Emacs and org-mode. A single keypress can be programmed to store a link as an org-heading with a note. This would really be my first choice as I\u0026rsquo;ve found it to work rather well. I can use an org file to easily organise my feeds !\nUnfortunately, there seems no easy way to sync completed feeds to my iOS devices, though solutions exist for Android. I do spend a lot of time on my computer, however, it seems I can just read better and faster on my iPad and therefore a sync to mobile devices is still important.\nThough it does not seem to be a mainstream recommendation on reviews like the sweet setup : Vienna is a reliable solution (open source!) to consider using to browse RSS feeds on the Mac OS. This comes with a caveat - some tinkering is required to get it to sync with a service.Vienna has inbuilt share options to share via Buffer or Twitter. Side note: I would recommend using Buffer to manage posts on multiple social media sites in a seamless manner. Buffer\u0026rsquo;s free tier should be sufficient for moderate, personal purposes. I use it to post on Twitter and Linked in simultaneously.\nHarvesting information The next consideration was harvesting notable information of interest from the RSS feeds. If not Emacs, the information has to go to DEVONThink Pro (DTP), which has a handy pull out drawer into which content can be dragged. I was able to just drag and drop the article or text selection into the DTP drawer. This appears as a URL / bookmark in DTP, and can be converted to a formatted note or web archive subsequently. A script could probably accomplish this automatically. That\u0026rsquo;s for a future project.1\n Screenshot - Vienna + DTP drawer   Granted, an application external to Emacs (especially without a customisable keyboard driven flow) is not the desirable way to do things. Most websites usually have an RSS feed or email subscription possibility.\nOpting for Feedly as a susbcription service and RSS app Unfortunately, Vienna had to be abandoned as it felt more sensible to opt for a Feedly subscription to enable a seamless mobile experience. The Feedly app turned out to run surprisingly well on my ancient iPad and I can still drag and drop entire articles into DTP which come out to be formatted RTFD files which could be read and highlighted in leisure. While it may be nice to opt for a standalone app in the Mac for RSS feeds, the Feedly app satisfies my needs and is also available cross-platform. Note: I use the excellent Unread app to read RSS on my newer iPhone.\nBesides the numerous sync options, Feedly provides other interesting features in their pro subscription, like setting up Google keyword searching and organising multiple feeds into \u0026lsquo;boards\u0026rsquo;. This will certainly help in enabling some level of filtering. The method of organising sources and OPML imports in the mac app is a little clunky and not comfortably intuitive, but it is usable.\nThere\u0026rsquo;s no easy way to use Elfeed as a feedly client either.\nHow to cover them all? With numerous sources available on most topics - a technique to read is of even more importance. Besides leveraging custom boards, it seems the best way to consume content is to rapidly sweep through the titles and the short descriptions, and in parallel skim through articles of interest. If the article (even slightly) feels worth recording and reading in detail, I select the entire article and drag it into DTP via the drawer for a future session.\nI try to deploy DTP as my primary reading app, because of the ability to highlight lines (which are generally available across devices). Besides aiding in skimming the article in the future, it helps me know I\u0026rsquo;ve actually read the article. This is in addition to the core ability to use DTP\u0026rsquo;s AI algorithms in searching through my notes and forming connections between ideas. I also use smart groups that show me the articles captured in the last 1 week, 2 weeks, 3 weeks, which helps me re-visit them in a structured method. The latter works rather well as a memory aid.\n Article captured from Feedly into DTP   Future plans? It would be ideal to setup my own server which will process the RSS feeds. Perhaps a Raspberry Pi or something else could be employed. This would be a cost efficient approach for the long term. Such a setup would enable using Elfeed to source articles from the server and thus sync with my mobile devices.\nFor now, I guess I will have to rely on Feedly.\n It is probably worth noting that Feedly pro has several 3rd party integrations available out of the box including Evernote.\r^   ","date":1548514260,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562857593,"objectID":"21d339b95df19c96baf992571086b7e1","permalink":"https://shrysr.github.io/post/c641a230-37c9-46aa-84eb-e78cc00d0c7e/","publishdate":"2019-01-26T07:51:00-07:00","relpermalink":"/post/c641a230-37c9-46aa-84eb-e78cc00d0c7e/","section":"post","summary":"Why use RSS? Off late, I had been relying more on email based content consumption. The phenomenally fast search and filtering capabilities that can be leveraged with mu4e make this easy.\nEven with all these filters, it is quite difficult to keep on top of news and information from different sources. It is actually inconvenient to mix important emails and correspondence with newsletters and the like, which arrive by the dozen(s) everyday.","tags":["Emacs"],"title":"Back to RSS","type":"post"},{"authors":null,"categories":["Emacs","Productivity","Org-mode"],"content":"  Table of Contents  TLDR - for the busy folks  Goals: Summary:  Multiple email accounts. Lack of a unified interface. Creating sync channels via mbsync Text based email client! Speed + simplicity Why mu4e rocks [for me] - the perks Quirks Multiple levels of filters are still necessary. Takeaways Links and References   \nThis dev.to blog post inspired me to complete this languishing draft of my current email setup, and the benefits I\u0026rsquo;ve gained from using a text based email client in Emacs.\nHope you find it entertaining. In any case, the links and reference section will certainly prove useful.\nTLDR - for the busy folks Goals:  Unification of email accounts while preserving separate individual components. Local backup of email. Potential to extend system to a personal server Email access from Emacs ! Hopefully improve overall productivity with reduced context switching.  Summary:  Started with 2 Gmail accounts and 1 MSN account. Switched to a paid account with Fastmail. Used Fastmail\u0026rsquo;s tools to transfer email from both Gmail and MSN accounts. Setup forwarding for all new emails from to Fastmail. Decided between retaining copies of emails in Gmail/MSN or deleting them once forwarded. Used customised settings in mu4e to manage Email from within Emacs. Occasionally rely on web browser / iOS app. Fastmail\u0026rsquo;s interface is clean and very fast. Goals Achieved !! Live with the quirks and enjoy the perks.  Look at the Links and References section for almost all the resources I relied on.\nA portion of my mu4e configuration is available on my website. The personal filters and configuration are placed in an encrypted file.\nMy mbsync configuration is posted as a public gist.\nMultiple email accounts. Lack of a unified interface. Some years back, I found that I had 2 Gmail accounts, and an MSN account. I discarded age old Yahoo and rediffmail accounts which were luckily not used much (and God knows how many more I made as a kid).\nGmail\u0026rsquo;s interface felt just about tolerable, but inconvenient. The idea of viewing ads tailored to the content of emails had become disconcerting. Their Inbox app was interesting, but did not work smooth enough. MSN\u0026rsquo;s web interace and apps always felt cumbersome, though updates over the years, this has improved significantly.\nUseful emails could be email digests that contain a wealth of links, discussions, articles and information. Or perhaps email digests of product and technology news that are useful to retain as an archive of reference.\nIt would be nice to be able to process these links in a systematic manner, and have them available with a fast search system that is also integrated with a task management system.\n My solution was to switch to forwarding all my emails to a single Fastmail account. It\u0026rsquo;s been an excellent experience over 2+ years.1,2\n Creating sync channels via mbsync My mbsync configuration is posted as a public gist. It is reasonably self explanatory, and shows how separate channels were made grouping together folders, by specifying a pattern. This took some time, but was finally very satisfying to know as a fine grained control technique.\n I started out using offlineimap. I found mbsync to be significantly faster.\n Text based email client! Speed + simplicity Imagine being engrossed with your code or engineering notebook and the need for shooting off an urgent brief email arises. What if this could be done with a few key-presses on an email client, right from the terminal or the code editor that you are already engrossed in?\nHow about adding an email as a task in your organiser with a deadline / planned date?\nWhat if I had the option to setup separate channels of mail transfer, such that I can sync the inbox or a custom group of folders alone when I am pressed for bandwidth or space?\nPractical solutions will need to cater to a lot more situations.\n The good news is: usually anything you need is possible (or already implemented) using Emacs.\n I use mu4e, which uses the indexer mu as it\u0026rsquo;s back-end. There are other popular options like notmuch and mutt. I have briefly experimented with mutt, which has a fast email search capability, but has to be coupled with another front-end to be used within Emacs or elsewhere. The philosophy and system behind notmuch (leveraging the Gmail tag based approach) differ from mu4e.\nOver a few years of using this system, I have found that text and terminal based email clients offer a speed and integrity that is extremely pleasing.\nWhy mu4e rocks [for me] - the perks The ability to create custom search filters that can be accessed with easy shortcuts. An example to demonstrate\n(setq mu4e-bookmarks `( ,(make-mu4e-bookmark :name \u0026#34;Unread messages\u0026#34; :query \u0026#34;flag:unread AND NOT flag:trashed\u0026#34; :key ?u) ,(make-mu4e-bookmark :name \u0026#34;Today\u0026#39;s messages\u0026#34; :query \u0026#34;date:today..now\u0026#34; :key ?t) ,(make-mu4e-bookmark :name \u0026#34;Last 7 days\u0026#34; :query \u0026#34;date:7d..now\u0026#34; :key ?w) ,(make-mu4e-bookmark :name \u0026#34;Messages with images\u0026#34; :query \u0026#34;mime:image/*\u0026#34; :key ?p) ,(make-mu4e-bookmark :name \u0026#34;Finance News\u0026#34; :query (concat \u0026#34;from:etnotifications@indiatimes.com OR \u0026#34; \u0026#34;from:newsletters@valueresearchonline.net\u0026#34; \u0026#34;from:value research\u0026#34;) :key ?f) ,(make-mu4e-bookmark :name \u0026#34;Science and Technology\u0026#34; :query (concat \u0026#34;from:googlealerts-noreply@google.com OR \u0026#34; \u0026#34;from:reply@email.engineering360.com OR \u0026#34; \u0026#34;from:memagazine@asme.org\u0026#34; \u0026#34;from:action@ifttt.com\u0026#34; \u0026#34;from:digitaleditions@techbriefs.info\u0026#34;) :key ?S) )) This is how it looks:\n Mu4e start page   Complete keyboard based control, and using it with Emacs means the ability to compose email from anywhere and build all kinds of workflows. Examples:\n Hit Control+x and m (C-x m) in Emacs parlance, and I have a compose window open.\n There are built-in workflows and functions in starter-kits like Scimax, which enable you to email an org-heading or buffer directly into an email, with the formatting usually preserved, and as intended.\n  I often use yasnippet to insert links to standard attachments like my resume. This essentially means being able to attach files with a 1-2 key strokes.\nWhile Mu4e may be a programmatic solution with no pleasing GUI - it allows one to search a large number of emails with glorious ease. This is particularly more effective on a SSD drive, rather than the conventional Hard disk.\nOne has to experience the above to know the dramatic impact it makes in getting closer in speed to your thoughts, using a customisable system. Emails can be easily captured or added as tasks into Org mode documents as a part of task and project management.\nUsing the mu4e and mbsync, I\u0026rsquo;ve devised a \u0026lsquo;sane inbox\u0026rsquo; which is bereft of the noise, like annoying digests, social media updates and so on. The idea was to dedicate focused blocks to rapidly process email, all within Emacs.\nI have tried using Todoist extensively in the past, along with their integration with Gmail. This approach is a reasonable solution, if one is open to using different applications.\nQuirks mu4e is a text based email interface. It can be set such that the rendered HTML is displayed in the mu4e-view buffer for each email, which enables graphics and pictures (if any). However, the render is not perfect at all times. The HTML parsing engine can be specified. Thus, heavy HTML emails are unlikely to render correctly, to the extent of being a nuisance.\n Such emails can be viewed in the browser of your choice with merely 2 key presses, \u0026lsquo;a\u0026rsquo; and then \u0026lsquo;v\u0026rsquo;, with cursor in the body of the email. This could be Firefox, or w3m or any other browser of your choice.3\n Email syncing frequency is set in mu4e. This update process takes a few seconds, and it is not as seamless as a web app. Notifications for new email can be configured on the mode line or through pop-ups in Emacs. However, the experience with working synced emails is good.\nMultiple levels of filters are still necessary. Situations where I do not have access to Emacs will need me to use the iOS app or the web interface. Therefore the inbox in the web interface here cannot be \u0026lsquo;insane\u0026rsquo;. Therefore a higher level of filters are implemented in Fastmail itself.\nFor example all Linked in group and job updates have their own folders. These folders are all subfolders of the Archive. They never reach the inbox at all. These emails often remain unread, or if necessary, I can focus on bunches of them at a time.\n By grouping all such incoming mails into subfolders within the Archive folder, I can use a single channel for all the relatively unimportant mail.\n Takeaways  Using an \u0026lsquo;archaic\u0026rsquo; text based email client (mu4e) has significantly boosted the speed with which I can handle my emails and focus on tasks. The simple interface and speed enables better focus.\n While there are many articles and plenty of guidance on this topic, it takes time and patience to get this working the way you need it to. However, once it is setup, it does become rather comfortable to use.\n Context switching is expensive on the brain and dents productivity.\n Integrating email with time and project management is important. mu4e integrates well with Org mode. Beyond tasks, it is also a good reference, and I can easily attach notes, summaries etc to these emails.\n  Links and References These are the links and references I\u0026rsquo;ve used in setting up and troubleshooting my email setup.\n These could be organized better, and some links may be repeated. All put together, these should give you all you need to get hooked up!\n   Some of the links have additional comments, and many are tagged with dates, as a reference to when I collected the link. Sometimes, this is fun to reflect on!\n A Complete Guide to Email in Emacs using Mu and Mu4e, \u0026lt;2017-03-08 Wed 10:04\u0026gt; Reading IMAP Mail in Emacs on OSX | Adolfo Villafiorita, \u0026lt;2016-11-27 Sun 08:17\u0026gt; Excellent link talking about mu4e and notifications Handling Email with Emacs – malb::blog, \u0026lt;2016-08-01 Mon 18:37\u0026gt; Which email client (mu4e, Mutt, notmuch, Gnus) do you use inside Emacs, and why? : emacs \u0026lt;2016-05-31 Tue 07:32\u0026gt; emacs-fu: introducing mu4e, an e-mail client for emacs - Emacs and mu4e stuff \u0026lt;2016-04-20 Wed 13:02\u0026gt; Emacs as email client with offlineimap and mu4e on OS X / KG / Hacks. Thoughts. Writings. - nice blog related to Emacs and linux \u0026lt;2016-04-21 Thu 22:44\u0026gt; EOS: Mail (Email) Module - explaining multiple email setup in mu4e \u0026lt;2016-04-27 Wed 07:56\u0026gt; The Ultimate Emailing Agent with Mu4e and Emacs – Emacs, Arduino, Raspberry Pi, Linux and Programming etc, \u0026lt;2016-08-17 Wed 13:19\u0026gt; Varun B Patil | EOM a.k.a End of Mail a.k.a Emacs + offlineimap + mu4e - multiple accounts \u0026lt;2016-04-19 Tue 12:19\u0026gt; Master your inbox with mu4e and org-mode | Pragmatic Emacs \u0026lt;2016-03-26 Sat 14:56\u0026gt; notmuch - email setup My personal mail setup — Articles — WWWTech \u0026lt;2017-06-13 Tue 16:09\u0026gt; Search-oriented tools for Unix-style mail | Mark J. Nelson, \u0026lt;2017-05-10 Wed 16:29\u0026gt;  interesting comparison of mu and notmuch, going beyond superficial differences, but not too much depth either.  Mutt with multiple accounts, mbsync, notmuch, GPG and sub-minute updates | French to English translator, \u0026lt;2017-04-28 Fri 07:19\u0026gt;  interesting link, author profile and content available on-line.  Assorted Nerdery - Notmuch of a mail setup Part 2 - notmuch and Emacs, \u0026lt;2017-04-27 Thu 18:41\u0026gt; Mutt, mu4e and notmuch links  bash - Send Html page As Email using \u0026ldquo;mutt\u0026rdquo; - Stack Overflow Reading html email with mutt Prefer plain text format over HTML in mutt Using emacs and notmuch as a mail client - Foivos . Zakkak . net Help with mu4e multiple accounts : emacs Using Mutt, OfflineIMAP and Notmuch to wrangle your inbox. : linux \u0026lt;2016-06-16 Thu 15:23\u0026gt; A year with Notmuch mail {LWN.net} \u0026lt;2018-04-17 Tue 01:21\u0026gt;  mu4e specific Links \u0026lt;2016-04-19 Tue 21:48\u0026gt;  Mu4e 0.9.16 user manual: Gmail configuration mu4e tutorials - Google Search Tutorial: email in Emacs with mu4e and IMAP+SSL : emacs mu4e tutorials | Pragmatic Emacs Drowning in Email; mu4e to the Rescue. Emacs \u0026amp; the obsessive email mongerer | Moved by Freedom – Powered by Standards Mu4e + nullmailer - Google Groups Leaving Gmail Behind « null program view html mails in mu4e - Google Search Mu4e 0.9.16 user manual: Reading messages In mu4e, is this how your HTML-heavy emails render? : emacs Varun B Patil | EOM a.k.a End of Mail a.k.a Emacs + offlineimap + mu4e Mu4e 0.9.16 user manual: Marking messages change the date column format in mu4e - Google Search Mu4e 0.9.16 user manual: HV Overview increase column size in mu4e - Google Search Mu4e 0.9.16 user manual: HV Custom headers mu4e-manual-0.9.9.pdf do mu4e folders sync with gmail folders - Google Search mu4e Send mail with custom SMTP and archive in Gmail \u0026ldquo;Sent\u0026rdquo; folder : emacs Using mu4e · Brool  are maildir folders synced back to gmail ? - Google Search Some real use cases About Backing up Gmail messages with offlineimap notmuch email versus mu4e - Google Search Which email client (mu4e, Mutt, notmuch, Gnus) do you use inside Emacs, and why? : emacs A Followup on Leaving Gmail | Irreal Sup? Mutt + Gmail + Offlineimap Migrating from offlineimap to mbsync for mu4e | Pragmatic Emacs    Fastmail allows for a variety of interesting features like aliases, easy email transfer (from a different email provider like Gmail or MSN), responsive technical support, and many more aspects, and much more. They have their own implementation of the IMAP protocol, called JMAP, which is significantly faster.\r^ While there are many advantages in Gmail and many swear by it\u0026rsquo;s search capabilities - it is worth noting that Fastmail\u0026rsquo;s ad-free interface and search just feels a lot quicker than Gmail, and I can find my way around the settings better than I used to with Gmail.\r^ You may be surprised to see the ease in browsing a good number of websites on a text based web browser. Besides the added advantage of being within Emacs - a surprising number of websites can be viewed functionally on w3m. It works fine for quick searches on Google (which like anything else, can be done within a few key strokes in Emacs).\r^   ","date":1563067980,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563075093,"objectID":"bc70f3595632dc251a504d1786996bed","permalink":"https://shrysr.github.io/post/e4e7ebb1-4c0c-41d6-b7e4-1c1c09e48c80/","publishdate":"2019-07-13T19:33:00-06:00","relpermalink":"/post/e4e7ebb1-4c0c-41d6-b7e4-1c1c09e48c80/","section":"post","summary":"Table of Contents  TLDR - for the busy folks  Goals: Summary:  Multiple email accounts. Lack of a unified interface. Creating sync channels via mbsync Text based email client! Speed + simplicity Why mu4e rocks [for me] - the perks Quirks Multiple levels of filters are still necessary. Takeaways Links and References   \nThis dev.to blog post inspired me to complete this languishing draft of my current email setup, and the benefits I\u0026rsquo;ve gained from using a text based email client in Emacs.","tags":["mu4e","Emacs","Productivity","lisp","Orgmode"],"title":"Archaic text based email clients rock!","type":"post"},{"authors":null,"categories":["General"],"content":" Whiplash: Wikipedia\nWhiplash is a fascinating movie on many levels regarding a topic that interests me deeply\u0026hellip; How to progressively perform, and strive to become the very best in a chosen field. Personally, I found each step of the movie riveting and would recommend it to anybody who would find the above question even mildly interesting. The movie\u0026rsquo;s climax was immensely interesting, inspiring and supported by great acting. At any rate, the movie induced a blog post !\nThe story revolves around the mind and life of a student who wants to be among the greats in his field, and the way he deals with an abrasive, abusive and unorthodox teacher whose intentions are to bring out the best in a student. No movie is perfect - while some points in Whiplash do appear extreme and therefore relatively unrealistic - the overriding message and theme conveyed certainly rings out clearly, in an engaging plot.\nI could relate to the following pointers from the movie:\nLeverage stress to achieve new levels of insight and performance The belief of the teacher, that the best performance or attributes hidden inside a person can come out only via repeated, unexpected and stressful prodding. I\u0026rsquo;m not sure if this works as shown in the movie, but I have found unexpected insights at times of extreme stress, that have were taken forward to habits that changed my life.\nWeathering criticism The mental conditioning required to weather and beat intense, sharp, depressing criticism along with verbal and physical abuse from a mentor or teacher and use the same as a motive force for self-improvement and eventually superlative performance. Though there are examples of extreme abrasiveness in leaders like Steve Jobs - such an approach would not be tolerated by most people today.\n I know other stories of people working under such mentors, striving to learn and gain their approval and eventually winning the same. These efforts paid off by resulting in skills, thinking patterns and a superior mental conditioning. Finding such a mentor at the formative stage is probably the best thing to happen to anybody.\n An effective strategy to find mentors is to shadow people on Linked in and learn from their profiles and activity. Some of them may be willing to connect and invest time in mentoring.\n Another possibility to find like minded people and mentors would be to join the communities of on-line courses, like Datacamp and Dataquest, who have lively channels in Slack for paid members.\n  Getting back up after a fall Everybody breaks. Just as the promising student in Whiplash breaks. But the champions among us rally, to stage a comeback and performance that make history.\nRegularly surpassing the level of deliberate knowledge of your own performance, and thus improvement by exactly being able to measure your performance and pinpoint mistakes. This point is portrayed in a very interesting manner in Whiplash, where the teacher expects the student to know exactly what mistake is being made.\nBe Great, not Good Rejecting the \u0026lsquo;Good\u0026rsquo; or \u0026lsquo;Good enough\u0026rsquo; feedback from anybody. The goal is to be Great, not good. The goal should be to strive to set the precedent and not just follow a beaten track. The pinpoint focus should be on progressive improvement to become the best, and that entails never being satisfied and to be ruthless in rooting out flaws.\nAchieving Balance : mind + body + surroundings Great performance is about that perfect balance between the body, mind and environment to leverage the best result possible. I view the scene where the student survives a car crash, just to reach a performance and then not being able to perform, as a good example of overreaching, without strengthening the core, and thus inviting instability.\nGo off the beaten track and Lose yourself It was the ending of Whiplash that truly drove me to comprehend the points so far. It is twisted, unexpected and led me to truly enjoy the movie and appreciate that: despite the above points being reasonably discernible - the human mind and nature is exceedingly complex. Stability and reasoning are not the only keystones to the foundation of greatness. There has to be a healthy mix of some form of abnormal obsession thrown in, to make a stellar performance what it is. However, can this be practically repeated on a regular basis?\nLearning velocity and Flow There are several bodies of research work available today that can be studied to get closer to consciously stimulating a great performance. One such example is:\n Unlocking the Talent Code With Dan Coyle on the Unmistakable Creatives podcast provides an insight in line with the points seen above, into what constitute outliers and performers. The interesting concept of \u0026lsquo;Learning velocity\u0026rsquo; is explained by Dan with a lucid example. It is surmised that progress and maximum learning to become better occurs at the boundary line dividing what we know at the moment, and the unknown skills that beckon.  That point sems to be an amalgamation of several factors, that are typically present when someone is in \u0026lsquo;flow\u0026rsquo;. Perhaps this flow can be described as a heightened sense of what is, and what should be and the energy to strive and achieve what should be.. It certainly does feel logical to think that we become better by pushing that boundary.\n","date":1547951820,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547951877,"objectID":"b9f96ac1c15730097b7736a9cb740fee","permalink":"https://shrysr.github.io/post/5fc69e19-e330-4dd9-9317-7280a9c93966/","publishdate":"2019-01-19T19:37:00-07:00","relpermalink":"/post/5fc69e19-e330-4dd9-9317-7280a9c93966/","section":"post","summary":"Whiplash: Wikipedia\nWhiplash is a fascinating movie on many levels regarding a topic that interests me deeply\u0026hellip; How to progressively perform, and strive to become the very best in a chosen field. Personally, I found each step of the movie riveting and would recommend it to anybody who would find the above question even mildly interesting. The movie\u0026rsquo;s climax was immensely interesting, inspiring and supported by great acting. At any rate, the movie induced a blog post !","tags":["Movie-notes","excellence"],"title":"Notes from the movie Whiplash","type":"post"},{"authors":null,"categories":["Emacs","Productivity"],"content":"Scimax has a convenient feature of immediately creating projects (M-x nb-new). The location of the project directory is defined by the setting (setq nb-notebook-directory \u0026quot;~/my_projects/\u0026quot;), which has to be set in your Emacs config. Once the name of the project is chosen, a Readme.org buffer is immediately opened and one can start right away. It is an awesome, friction-free method to get started with a project.\nThese projects are automatically initialised as git repositories, to which it is trivial to add a new remote using Magit. Therefore individual folders and git repos are automatically created for each project in the specified project directory. This enables the convenient possibility of keeping the data, folder structures, tasks, notes and scripts of each project separate.\nDifferent projects can be switched to using M-x nb-open and typing in a few words that denote the title of the project. Choosing a project automatically provides the option to open the Readme.org files created earlier. Therefore it would be convenient to include relevant links to different locations / scripts and etc in the Readme file.\nUsing the above technique resulted in me creating a huge number of projects over a period of time. Especially while working on multiple computers, it is worth inculcating the discipline of adding a remote on github/bitbucket and regularly pushing to the remote.\nThe advantage of using a separate repo for each project is the alignment with the space constraints imposed by the free tier repos on bitbucket or github. However, it is also useful to have the entire project folder as a git repo. This can be resolved by adding each project as a sub-module. In this way, all the projects are available with a single clone of the project foder, and then specific sub-modules or projects can be initialized as required. Having separate repos for each project also enables more streamlined collaboration or publishing of a particular project, rather than the entire project folder and allowing separate gitignore lists for each project.Using a single file for all the projects will also enable adding notes pertaining to the content of each project, which can be searched before intialising the entire project repo. Scripts for initializing and commit can also be included in this file for convenience.\nOnce the above is done, the org-projectile package can be leveraged to plan the tasks and manage the notes for each project. It is possible to have all the tasks for a project within a separate file within each project, or specify a single file as the task management for all the projects. This file is then appended to the org-agenda files for tasks to show up in the agenda. As mentioned in the Readme of the org-projectile package the settings would look like the following (for a single file pertaining to all the projects):\n;; Setting up org-projectile (require \u0026#39;org-projectile) (setq org-projectile-projects-file \u0026#34;~/my_org/project-tasks.org\u0026#34;) (push (org-projectile-project-todo-entry) org-capture-templates) (setq org-agenda-files (append org-agenda-files (org-projectile-todo-files))) (global-set-key (kbd \u0026#34;C-c n p\u0026#34;) \u0026#39;org-projectile-project-todo-completing-read) The above snippet adds a TODO capture template activated by the letter \u0026lsquo;p\u0026rsquo;, and also adds the project-tasks file to the agenda files. Inside a project, it is then possible to capture using C-cc p and add a task which will create a top level heading linked to the project, and the task or note as a sub-heading.\n org-projectile task capture   ","date":1548452640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562858461,"objectID":"0bb846017bd18605fbd51deb896bb826","permalink":"https://shrysr.github.io/post/8f702ce2-8bb7-40a3-b44b-a47222c02909/","publishdate":"2019-01-25T14:44:00-07:00","relpermalink":"/post/8f702ce2-8bb7-40a3-b44b-a47222c02909/","section":"post","summary":"Scimax has a convenient feature of immediately creating projects (M-x nb-new). The location of the project directory is defined by the setting (setq nb-notebook-directory \u0026quot;~/my_projects/\u0026quot;), which has to be set in your Emacs config. Once the name of the project is chosen, a Readme.org buffer is immediately opened and one can start right away. It is an awesome, friction-free method to get started with a project.\nThese projects are automatically initialised as git repositories, to which it is trivial to add a new remote using Magit.","tags":["Org-mode","Emacs"],"title":"Juggling multiple projects and leveraging org-projectile","type":"post"},{"authors":null,"categories":["Emacs","DataScience"],"content":" This post provides a simple example demonstrating how a shell script can be called with appropriate variables from any Org file in Emacs. The script essentially converts a Jupyter notebook to Org source, and Babel is leveraged to call the script with appropriate variables from any Org file. This reddit thread and blog post elucidate the advantages of using Babel and Org mode over Jupyter notebooks.\nDirectly editing code in a Jupyter notebook in a browser is not an attractive long term option and is inconvenient even in the short term. My preference is to have it all in Emacs, leveraging a versatile Org file where it is easy to encapsulate code in notebooks or projects within Org-headings. Thus, projects are integrated with the in-built task management and calendar of Org mode.\nHowever, it may be a frequent necessity to access an external Jupyter notebook for which there is no Org source.\nOne solution is to start up a Jupyter server locally, open the file and then File \u0026gt;\u0026gt; save as a markdown file, which can be converted to an Org file using pandoc. Remarkably, the output code seems similar to the code blocks used in the R-markdown notebooks, rather than pure markdown markup. Therefore this markdown export should work fine in RStudio as well. However, unless the Jupyter server is always running on your machine, this is a relatively slow, multi-step process.\nThis SO discussion provided my answer, which is a 2 step script via the versatile pandoc. A workable solution, as a test conversion revealed. The headings and subheadings and code are converted into Org markup along with Org source blocks.\njupyter nbconvert notebook.ipynb --to markdown pandoc notebook.md -o notebook.org The next consideration was to have the above script or recipe handy for converting any Jupyter notebook to an Org file quickly.1 For the script to be referenced and called from any other location, the source block needs to be defined with a name and the necessary arguments, and also added into the org-babel library.\nIn this example the path to the Jupyter notebook, markdown file and resulting org file are specified as variables or arguments. Note that the absolute path to any file is required. Save the following in an Org file, named appropriately, like my-recipes.org\n#+NAME: jupyter-to-org-current #+HEADER: :var path_ipynb=\u0026#34;/Users/xxx/Jupyter_notebook\u0026#34; #+HEADER: :var path_md = \u0026#34;Jupyter_notebook-markdown\u0026#34; #+HEADER: :var path_org = \u0026#34;Jupyter-notebook-org\u0026#34; #+BEGIN_SRC sh :results verbatim cwd=$(pwd) jupyter nbconvert --to markdown $path_ipynb.ipynb --output $cwd/$path_md.md pandoc $cwd/$path_md.md -o $cwd/$path_org.org cp $path_ipynb.ipynb $cwd ls The path_ipynb variable can be changed as required to point to the Jupyter notebook.2\nAll such blocks above can be stored in Org files and added to the Library of Babel (LOB) by including the following in the Emacs init configuration.\n(org-babel-lob-ingest \u0026#34;/Users/shreyas/my_projects/my-recipes.org\u0026#34;) The named shell script source block can now be called from any Org file, with specified arguments and have the notebook. The script is called using the #+CALL function and using the name and arguments of the source block above.\n#+CALL: jupyter-to-org-current(path_md=\u0026#34;Jup-to-markdown\u0026#34;, path_org=\u0026#34;Markdown-to-org\u0026#34;) Therefore, the snippet above will convert a Jupyter notebook to a markdown file named Jup-to-markdown and then an Org file called Markdown-to-org. If an argument is not specified, the default value of the paths specified in the original source block will be used.\nOf course, the #+CALL function used above is also too lengthy to remember and reproduce without headaches. This is also bound to happen as the number of such named code snippets increase. One solution (though not ideal) is to store the #+CALL as a snippet using M-x yas-new-snippet, and load it when needed using the excellent ivy-yasnippet package (see MELPA), with minimal exertions.\nFurther possibilities It would be nice to improve the options available for modifications on the fly. Python may be an \u0026lsquo;easier\u0026rsquo; option to write up for such activities rather than a shell script. For example, a script with the working directory being an additional /optional argument could be considered.\nAnother desirable factor in the resulting Org file would be iPython blocks in place of python. As a temporary solution, the python blocks could be converted to ipython blocks via a search and replace throughout the document. A lisp macro / source block could run after the above source block to facilitate the search and replace.\u0026nbsp;3\n In Scimax - it is possible to quickly start a new project using M-x nb-new, which creates a sub-folder in the specified projects folder and creates and opens a readme.org file for the project.\r^ The option C-u-cl is a messy way to quickly get the full file name path, the resulting path will need to be modified slightly.\r^ It is worth noting that a bunch of additional HTML blocks and hyperlinks are inserted via the above export procedure. It should be possible to add some hooks to clean up the org file after the export from pandoc.\r^   ","date":1548452640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562857565,"objectID":"0a062dfc6660944d9e2a163216e27989","permalink":"https://shrysr.github.io/post/0b63f316-6f6b-4ec2-84a4-5ff287ecf7a7/","publishdate":"2019-01-25T14:44:00-07:00","relpermalink":"/post/0b63f316-6f6b-4ec2-84a4-5ff287ecf7a7/","section":"post","summary":"This post provides a simple example demonstrating how a shell script can be called with appropriate variables from any Org file in Emacs. The script essentially converts a Jupyter notebook to Org source, and Babel is leveraged to call the script with appropriate variables from any Org file. This reddit thread and blog post elucidate the advantages of using Babel and Org mode over Jupyter notebooks.\nDirectly editing code in a Jupyter notebook in a browser is not an attractive long term option and is inconvenient even in the short term.","tags":["Emacs","Jupyter","Python","Org-mode"],"title":"Jupyter notebooks to Org source + Tower of Babel","type":"post"},{"authors":null,"categories":["Emacs"],"content":"I like to have any reading material and my notes side by side1. This is easily done with Emacs by splitting the buffer vertically (C-x 3)2\nFor example: Once a link has been opened via w3m, I hit org-capture (C-c) with a preset template that grabs the URL to the article along with the created date in the properties, with the cursor in position ready to take notes.\n(setq org-capture-templates \u0026#39;((\u0026#34;l\u0026#34; \u0026#34;Link + notes\u0026#34; entry (file+headline \u0026#34;~/my_org/link_database.org\u0026#34; \u0026#34;.UL Unfiled Links\u0026#34;) \u0026#34;** %? %a \u0026#34;))) The snippet above is activated by the command \u0026lsquo;l\u0026rsquo; and is listed with the title Link + notes in the agenda. It captures the link of the file being viewed as the heading and allows further notes to be inserted below. This is stored into the file link_database and under the specified heading .UL Unfiled Links.\nIt is also possible to capture a highlighted chunk of text to be added under the heading mentioned above. That would look something like:\n(setq org-capture-templates \u0026#39;((\u0026#34;e\u0026#34; \u0026#34;Snippet + Notes\u0026#34; entry ;; \u0026#39;w\u0026#39; for \u0026#39;org-protocol\u0026#39; (file+headline \u0026#34;~/my_org/link_database.org\u0026#34; \u0026#34;.UL Unfiled Links\u0026#34;) \u0026#34;*** %a, %T\\n %:initial\u0026#34;))) Now I have the capture buffer and the viewing content side by side, by calling C-c l. I can browse through the article use the mark-paragraph function (conveniently set to M-h) can be used to select and copy (M-w) entire paragraphs or alternately use C-spc to select lines of interest from the article them to the kill ring. The figure below depicts how it looks for me:\n Emacs content capture and buffer split   It is now possible to continue highlighting interesting lines / paragraphs and copy them, which adds them to the kill-ring. Once the article is done with, I switch over to the capture buffer and hit M-x browse-kill-ring, which brings up a pop-up buffer with all the items in the kill-ring3. Once called, I can hit n to move to the next item, and hit \u0026lsquo;i\u0026rsquo; to insert the current item at the cursor location. It is also possible to append / prepend/ edit the item before yanking. All the available shortcuts can be found using \u0026lsquo;?\u0026rsquo;, while in the browse-kill-ring buffer.\nThe above methodology curiously enables me to ensure capturing atleast some details of interest from an article / source, and also serve as a quick revision of the read content before filing it away.\nOne issue with the above workflow is that while reading multiple articles, there is a chance of mixing up the content being captured from different articles. This could be solved by using \u0026lsquo;x\u0026rsquo; in order to pop items out of the kill ring in the selection process above. However, it seems excessive to clear the entire kill ring for each article read. On the other hand, it could promote a focused workflow.\nAdditional possibilities:\n To view pdf files side by side and capture notes is via the Interleave package. The org-web-clipper concept outlined here is also very convenient to rapidly capture entire webpages being browsed in w3m.  Further reading:\n Howard Abrams has some great tips on customising the org-capture mechanism, Bernt Hansen\u0026rsquo;s comprehensive documentation.   Sometimes, this procedure has to be set specifically. Some good discussions on SO : link1, link2. However, at times horizontal splitting is useful. Therefore, I would rather not set a 0 width-threshold enabling only vertical splitting. lisp (setq split-width-threshold 75) (setq split-height-threshold nil)\r^ C-x essentially means Control + x. M-x or Meta-x is Alt + x\r^ The browse-kill-ring package can be installed via MELPA. (M-x install package)\r^   ","date":1548452700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562857568,"objectID":"98b5e4f4b4998b7115b9f77793c9df2b","permalink":"https://shrysr.github.io/post/2d1b3227-28de-4b30-93c8-ad5cbe276e44/","publishdate":"2019-01-25T14:45:00-07:00","relpermalink":"/post/2d1b3227-28de-4b30-93c8-ad5cbe276e44/","section":"post","summary":"I like to have any reading material and my notes side by side1. This is easily done with Emacs by splitting the buffer vertically (C-x 3)2\nFor example: Once a link has been opened via w3m, I hit org-capture (C-c) with a preset template that grabs the URL to the article along with the created date in the properties, with the cursor in position ready to take notes.\n(setq org-capture-templates \u0026#39;((\u0026#34;l\u0026#34; \u0026#34;Link + notes\u0026#34; entry (file+headline \u0026#34;~/my_org/link_database.","tags":["Emacs"],"title":"Emacs notes: Select paragraph and browse-kill-ring for effective content capture","type":"post"},{"authors":null,"categories":["Emacs","Productivity"],"content":"Before my foray into Emacs, I purchased applications like IAWriter (classic)1, Marked2, Texts (cross platform Mac/Windows), and have also tried almost all the recommended apps for longer form writing. I am a fan of zen writing apps. In particular the font and environment provided by IAWriter are conducive to focused writing. There also exist apps like Hemingway that also help check the quality of your writing.\nZen writing apps are called so because they have a unique combination of fonts, background color, including line spacing and overall text-width - all of which enable a streamlined and focused flow of words onto the screen. Any customisation required towards this end is possible in Emacs.\nThe Texts app has some nifty features (besides being cross platform), but the font and appearance is not as beautiful as IAWriter. Both IAWriter (classic) and Texts have minimal settings for further customisation. See the comparison below:\n Emacs (writeroom-mode + Iosevka font) || Texts (Sepia theme)    Emacs (writeroom-mode, Iosevka font) || IAWriter(Classic)   While everybody\u0026rsquo;s style and approach vary, there are many authors who swear by archaic text editors and tools that enable distraction free writing. One example is Tony Ballantyne\u0026rsquo;s post on writing tools, and several more examples are available in this blog post.\nThe next best thing to a clear retina display on a MacBook Pro, is a beautiful font face to take you through the day, enhancing the viewing pleasure and thus the motivation to work longer.\nIn Emacs, writeroom-mode and Emacs can be customised to mimic IAWriter. In this regard, the font Iosevka, is a great font to try. This old Emacs reddit has many more suggestions. One post described Iosevka as \u0026ldquo;it doesn\u0026rsquo;t look like much, but after a few hours it will be difficult to use any other font.\u0026rdquo; This is exactly what happened to me.\nThere\u0026rsquo;s still a lot of tweaking to be done with writeroom-mode, but this is certainly a workable result. My nascent configuration for writeroom-mode in emacs is as follows (munged off the internet!). It\u0026rsquo;s remarkable how much was achieved with a few lines of code!\n(with-eval-after-load \u0026#39;writeroom-mode (define-key writeroom-mode-map (kbd \u0026#34;C-s-,\u0026#34;) #\u0026#39;writeroom-decrease-width) (define-key writeroom-mode-map (kbd \u0026#34;C-s-.\u0026#34;) #\u0026#39;writeroom-increase-width) (define-key writeroom-mode-map (kbd \u0026#34;C-s-=\u0026#34;) #\u0026#39;writeroom-adjust-width)) (advice-add \u0026#39;text-scale-adjust :after #\u0026#39;visual-fill-column-adjust) The latest version of IAWriter has a truck load of features and advantages over over the Classic version. I did consider purchasing it, but Emacs won the day. Nevertheless, as a plain vanilla writing app - IAWriter offers much right out of the box.\r^   ","date":1548452640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562857572,"objectID":"4609ad29370e465e8bfca11bdb12ee34","permalink":"https://shrysr.github.io/post/951004ce-add0-4e7e-b6e2-2932e0dee429/","publishdate":"2019-01-25T14:44:00-07:00","relpermalink":"/post/951004ce-add0-4e7e-b6e2-2932e0dee429/","section":"post","summary":"Before my foray into Emacs, I purchased applications like IAWriter (classic)1, Marked2, Texts (cross platform Mac/Windows), and have also tried almost all the recommended apps for longer form writing. I am a fan of zen writing apps. In particular the font and environment provided by IAWriter are conducive to focused writing. There also exist apps like Hemingway that also help check the quality of your writing.\nZen writing apps are called so because they have a unique combination of fonts, background color, including line spacing and overall text-width - all of which enable a streamlined and focused flow of words onto the screen.","tags":["Emacs","writing","font","Linux"],"title":"Iosevka - an awesome font for Emacs","type":"post"},{"authors":null,"categories":["Emacs","Productivity"],"content":"Discovered the glorious awesome lists today on Github. They are available through a simple search on github, and contain curated lists of resources of all kinds on a multitude of topics.\nAs one might expect, there is a lot of common ground between these lists, including topics and links.\nHow could one search for a keyword through all these repositories? I have always wanted search for particular keywords or code snippets in my Emacs configuration files, or in other files in a particular location. This is especially to verify if a bit of code or note is already available, in another location. Something that looks like this ;):\n Searching for \u0026lsquo;datascience\u0026rsquo; with emacs-helm-ag through a bunch of awesome-lists and other local repositories.   An answer had been available in Howard\u0026rsquo;s cool blog post on why one should learn Emacs - in a footnote (!), in which he\u0026rsquo;s mentioned ack and ag (the silver searcher).\u0026nbsp;1. It is even possible to edit in line with each search.\nThe silver searcher github page provides clear examples of how it\u0026rsquo;s significantly faster than ack (and similar tools). Further exploration led me to the emacs-helm-ag package, which is a helm interface to the silver searcher. Implementing emacs-helm-ag was as simple as adding it to my list of packages, and adding a basic setup to my helm configuration.[^fn:2]\nAs of now, I add packages to Scimax using this bit of code that I\u0026rsquo;ve obviously borrowed from the internet, and this case - I\u0026rsquo;m afraid I did not note the source.\n;; Setting up use packages ;; list the packages you want (setq package-list \u0026#39;(diminish org-journal google-this ztree org-gcal w3m org-trello org-web-tools ox-hugo auto-indent-mode ob-sql-mode dash org-super-agenda ox-hugo workgroups2 switch-window ess ess-R-data-view interleave deft org-bookmark-heading writeroom-mode evil evil-leader polymode helm-ag)) ;;fetch the list of packages available (unless package-archive-contents (package-refresh-contents)) ;; install the missing packages (dolist (package package-list) (unless (package-installed-p package) (package-install package))) ;; Remember to start helm-ag. As per the Silver searcher github site, the helm-follow-mode-persistent has to be set before calling helm-ag. (custom-set-variables \u0026#39;(helm-follow-mode-persistent t)) (require \u0026#39;helm-ag) This is how it looks in action \u0026gt;\u0026gt; Sweet !!\n Notice the search across multiple files. So I\u0026rsquo;ve called require org capture perhaps more times than necessary.   [^fn:2]:\n This is my first animated gif in a blog post! It was tricky! I used the free GIPHY capture app on the Mac store.\r^   ","date":1548452280,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562857876,"objectID":"e8f6607cd25cb050be8d81b299f356d9","permalink":"https://shrysr.github.io/post/03133c10-709e-4d06-9f3d-c00ffeae64a7/","publishdate":"2019-01-25T14:38:00-07:00","relpermalink":"/post/03133c10-709e-4d06-9f3d-c00ffeae64a7/","section":"post","summary":"Discovered the glorious awesome lists today on Github. They are available through a simple search on github, and contain curated lists of resources of all kinds on a multitude of topics.\nAs one might expect, there is a lot of common ground between these lists, including topics and links.\nHow could one search for a keyword through all these repositories? I have always wanted search for particular keywords or code snippets in my Emacs configuration files, or in other files in a particular location.","tags":["Emacs"],"title":"Searching the awesome-lists on Github","type":"post"},{"authors":null,"categories":["Emacs","Productivity"],"content":"I\u0026rsquo;m an admirer of Howard Abrams, especially because his posts and videos show the awesome power of doing things in Emacs, and the importance of writing clean and logical code. Watching his videos and reading his posts make me feel like I was born yesterday and I am just getting started. But more importantly, they also fire up my imagination regarding the possibilities out there and the potential to create glorious workflows.\nHoward\u0026rsquo;s tutorial on Literate Programming, combined with his Literate Devops with Emacs video are among the best ways to get started with understanding the power of using Org Mode and Org-Babel to create complex, inter-connected, multi-language programs / documents / research that are of course well documented (this being one basic tenet of literate programming). Essentially, Org Mode and Org-Babel enable a high quality programming environment in a single Org mode buffer or document. The said environment is significantly more feature rich compared to Jupyter notebooks, especially being supported by it\u0026rsquo;s foundation in Emacs.\nThough I\u0026rsquo;ve been using Org files for a while now for all my programming explorations, I\u0026rsquo;ve been bothered about my sub-par workflows. I could not easily reference other code blocks and snippets and recipes for a new document or project. It was inefficient and time consuming to locate the necessary snippet and re-write or re-paste the code in the new source blocks. I was not making much progress plodding through the vast documentation of org-babel.\nTherefore, I was thrilled to discover the Library of Babel through Howard\u0026rsquo;s tutorial, which can be used to add files to a global library that is accessible from anywhere! Did I mention that it involves hitting barely 3 keys, and any number of arguments can be passed to these source blocks? I\u0026rsquo;m not sure such a feature is available with any other IDE.\nIn addition, the above tutorial clearly elucidates how different languages can be combined together, and the video elucidates typical Devops procedures, which are easily taken care of with appropriate arguments and headers to the source code blocks. For example, all the source code blocks could be tangled into appropriately named and located script files using a single argument. These tutorials tied up bits and pieces of info in my head from various sources and was invaluable in enhancing my understanding of using Emacs and Org-Babel\nThe Library of Babel can be made persistent across sessions by loading a specified org-file from which the named source code blocks are automatically read in. It is surprising that the internet does not seem to contain more references and examples using the Library of Babel. Perhaps there are some caveats that I am yet to encounter. One question that arises is whether the Library of Babel is automatically updated when the source code block is updated.\n","date":1548452640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562858145,"objectID":"24dc122c5526a5e7387e25c70c388d73","permalink":"https://shrysr.github.io/post/6953c104-a8b3-4779-aad3-c33032beb111/","publishdate":"2019-01-25T14:44:00-07:00","relpermalink":"/post/6953c104-a8b3-4779-aad3-c33032beb111/","section":"post","summary":"I\u0026rsquo;m an admirer of Howard Abrams, especially because his posts and videos show the awesome power of doing things in Emacs, and the importance of writing clean and logical code. Watching his videos and reading his posts make me feel like I was born yesterday and I am just getting started. But more importantly, they also fire up my imagination regarding the possibilities out there and the potential to create glorious workflows.","tags":["Emacs"],"title":"Literate Programming - Emacs, Howard Abrams and Library of Babel","type":"post"},{"authors":null,"categories":["R","project","EDA","DataScience"],"content":" Summary This is a short exploration into the tidy tuesday dataset focused on the Federal R\u0026amp;D budget towards global climate change. The data has been extracted from a TidyTuesday dataset, which in return is moderately cleaned dataset from publicly available data. The analysis will show that NASA\u0026rsquo;s budget dwarfs the money going into other departments, and that the median spend towards climate change has been increasing since the year 2000.\nUseful links:\n Github Repo of Tidy Tuesday explorations Tidy tuesday dataset: link Data Dictionary link Viz posted on Twitter to participate in TidyTuesday. Tools used: ESS, Org mode  Download R script : this is the entire script below.\nLoading libraries The easypackages library allows quickly installing and loading multiple packages. Note: Uncomment the appropriate line if this library needs to be installed.\n# Loading libraries # install.packages(\u0026#34;easypackages\u0026#34;) library(\u0026#34;easypackages\u0026#34;) libraries(\u0026#34;tidyverse\u0026#34;, \u0026#34;tidyquant\u0026#34;, \u0026#34;DataExplorer\u0026#34;)All packages loaded successfully Reading in the data Since this is a small dataset, the data can be read in directly from Github into memory.\n# Reading in data directly from github climate_spend_raw \u0026lt;- readr::read_csv(\u0026#34;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/climate_spending.csv\u0026#34;, col_types = \u0026#34;cin\u0026#34;) Exploring the data We have 6 departments, and the remaining departments are lumped together as \u0026lsquo;All Other\u0026rsquo;.\nThe data is available for the years 2000 to 2017.\nThe above can be found using the unique function.\nclimate_spend_raw$department %\u0026gt;% unique() climate_spend_raw$year %\u0026gt;% unique()[1] \u0026#34;NASA\u0026#34; \u0026#34;NSF\u0026#34; \u0026#34;Commerce (NOAA)\u0026#34; \u0026#34;Energy\u0026#34; [5] \u0026#34;Agriculture\u0026#34; \u0026#34;Interior\u0026#34; \u0026#34;All Other\u0026#34; [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 [16] 2015 2016 2017 Some Notes on the data:\n We have the following columns:  name of the department. (chr) year (int) spending (double)  The data is relatively clean. However some manipulation is required to summarise the department wise spending.  An overview of missing data can be easily scrutinised using the plot_intro command, and actual numbers can be extracted using introduce. These functions are from the DataExplorer package.\n##plot_str(climate_spend_raw, type = \u0026#39;r\u0026#39;) plot_intro(climate_spend_raw) ##introduce(climate_spend_raw)   There are no missing values or NA\u0026rsquo;s.\nFor a quick look at the outliers, we can use a boxplot, using DataExplorer\u0026rsquo;s functions.\nvariance_climate_spend \u0026lt;- plot_boxplot(climate_spend_raw, by = \u0026#34;year\u0026#34;)   Figure 1: It can be seen above that there are not many outliers. Subsequent visualisations will show that NASA is the most significant outlier. The median spending has been increasing over the years.   Data Conditioning Note: this initial conditioning need not have involved the date manipulation, as the year extracted from a date object is still a double.\nclimate_spend_conditioned \u0026lt;- climate_spend_raw %\u0026gt;% mutate(year_dt = str_glue(\u0026#34;{year}-01-01\u0026#34;)) %\u0026gt;% mutate(year_dt = as.Date(year_dt)) %\u0026gt;% mutate(test_median = median(gcc_spending)) %\u0026gt;% mutate(gcc_spending_txt = scales::dollar(gcc_spending, scale = 1e-09, suffix = \u0026#34;B\u0026#34; ) ) Applying some summary statistics to calculate the total spend per department, per year.\n# Total spend per department per year climate_spend_dept_y \u0026lt;- climate_spend_conditioned %\u0026gt;% group_by(department, year_dt = year(year_dt)) %\u0026gt;% summarise( tot_spend_dept_y = sum(gcc_spending)) %\u0026gt;% mutate(tot_spend_dept_y_txt = tot_spend_dept_y %\u0026gt;% scales::dollar(scale = 1e-09, suffix = \u0026#34;B\u0026#34;) ) %\u0026gt;% ungroup() Lets see how much money has been budgeted in each department towards R\u0026amp;D in climate change from 2000 to 2017.\nclimate_spend_conditioned %\u0026gt;% select(-c(gcc_spending_txt, year_dt)) %\u0026gt;% group_by(department) %\u0026gt;% summarise(total_spend_y = sum(gcc_spending)) %\u0026gt;% arrange(desc(total_spend_y)) %\u0026gt;% mutate(total_spend_y = total_spend_y %\u0026gt;% scales::dollar(scale = 1e-09, suffix = \u0026#34;B\u0026#34;, prefix = \u0026#34;$\u0026#34;) )    Department Total Spend from 2000-2017     NASA $25.77B   Commerce (NOAA) $5.28B   NSF $5.26B   Energy $3.32B   Agriculture $1.63B   All Other $1.54B   Interior $0.86B    It is clear from here that the outlier department is NASA. Further exploration would be needed to understand the function of each department and the justification of this expenditure and the skew. For example, one might think the Interior department would not be able to produce R\u0026amp;D superior to NASA/NSF.\nFunction to plot a facet grid of the department spending By using a function to complete the plot, the plot can be easily repeated for any range of years. It can also work for a single year.\nThe function below takes the following arguments:\n The range of the years we want to look into , example 2005-2010 The number of columns in the facet wrap plot. The caption that consititues the observation from the plots and anything else.  The title of the plot includes the year range that is input above.\nclimate_spend_plt_fn \u0026lt;- function( data, y_range_low = 2000, y_range_hi = 2010, ncol = 3, caption = \u0026#34;\u0026#34; ) { plot_title \u0026lt;- str_glue(\u0026#34;Federal R\u0026amp;D budget towards Climate Change: {y_range_low}-{y_range_hi}\u0026#34;) data %\u0026gt;% filter(year_dt \u0026gt;= y_range_low \u0026amp; year_dt \u0026lt;= y_range_hi) %\u0026gt;% ggplot(aes(y = tot_spend_dept_y_txt, x = department, fill = department ))+ geom_col() + facet_wrap(~ year_dt, ncol = 3, scales = \u0026#34;free_y\u0026#34; ) + #scale_y_continuous(breaks = scales::pretty_breaks(10)) + theme_tq() + scale_fill_tq(theme = \u0026#34;dark\u0026#34;) + theme( axis.text.x = element_text(angle = 45, hjust = 1.2), legend.position = \u0026#34;none\u0026#34;, plot.background=element_rect(fill=\u0026#34;#f7f7f7\u0026#34;), ) + labs( title = plot_title, x = \u0026#34;Department\u0026#34;, y = \u0026#34;Total Budget $ Billion\u0026#34;, subtitle = \u0026#34;NASA literally dwarfs all the other departments, getting to spend upwards of 1.1 Billion dollars every year since 2000.\u0026#34;, caption = caption ) } Visualizing department-wise spending over the years Calling the function and passing in the entire date (year) range of 2000-2010. Note that for a single year, have both the arguments y_range_low and y_range_high equal to the same year.\nclimate_spend_plt_fn(climate_spend_dept_y, y_range_low = 2000, y_range_hi = 2010, caption = \u0026#34;#TidyTuesday:\\nDataset 2019-02-12\\nShreyas Ragavan\u0026#34; )   Figure 2: R\u0026amp;D Budget towards Climate Change from year 2000-2010 across departments.   climate_spend_plt_fn(climate_spend_dept_y, y_range_low = 2011, y_range_hi = 2017, caption = \u0026#34;#TidyTuesday:\\nDataset 2019-02-12\\nShreyas Ragavan\u0026#34; )   Figure 3: R\u0026amp;D Budget towards Climate Change from year 2011-2017 across departments.   Some Concluding statements NASA has the highest R\u0026amp;D budget allocation towards climate change, and one that is significantly higher than all the other departments put together. The median spending on R\u0026amp;D towards climate change has been increasing over the years, which is a good sign considering the importance of the problem. Some further explorations could be along the lines of the percentage change in spending per department every year, and the proportion of each department in terms of percentage for each year.\n","date":1572640020,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572742371,"objectID":"b92a04639ea87163e3943f765ab6b43a","permalink":"https://shrysr.github.io/project/tt-fed-rnd-spending/","publishdate":"2019-11-01T14:27:00-06:00","relpermalink":"/project/tt-fed-rnd-spending/","section":"project","summary":"An EDA using `R` of federal government data of the R\u0026D budget towards Climate Change.","tags":["R","EDA","ggplot","TidyTuesday","Data-Science"],"title":"Federal R\u0026D Spending on climate change","type":"project"},{"authors":null,"categories":["https"],"content":" What is Let\u0026rsquo;s Encrypt? Let\u0026rsquo;s Encrypt is a Certificate Authority (CA). A certificate from a CA is required to enable HTTPS.\nCertbot\u0026rsquo;s documentation summarises it well:\n Certbot is part of EFF’s effort to encrypt the entire Internet. Secure communication over the Web relies on HTTPS, which requires the use of a digital certificate that lets browsers verify the identity of web servers (e.g., is that really google.com?). Web servers obtain their certificates from trusted third parties called certificate authorities (CAs).\n How Let\u0026rsquo;s Encrypt works  To certify my domain, I need to demonstrate control over my domain. i.e one has to run a software tool to generate this certificate (periodically) on the server. being able to do this demonstratesa control over the domain.  Similar to domain control, there are other certificates for different purposes as well. See the excerpt from the ACME protocol below:    Different types of certificates reflect different kinds of CA verification of information about the certificate subject. \u0026ldquo;Domain Validation\u0026rdquo; (DV) certificates are by far the most common type. For DV validation, the CA merely verifies that the requester has effective control of the web server and/or DNS server for the domain, but does not explicitly attempt to verify their real-world identity. (This is as opposed to \u0026ldquo;Organization Validation\u0026rdquo; (OV) and \u0026ldquo;Extended Validation\u0026rdquo; (EV) certificates, where the process is intended to also verify the real-world identity of the requester.)\n  Let\u0026rsquo;s Encrypt\u0026rsquo;s documentation mentions that the software above will use the ACME protocols to generate the cert, and there are different approaches to do so, depending on the availability of shell access (or not) to the server. ACME stands for Automatic Certificate Management Environment : The introduction in the RFC demonstrates how ACME automates a significantly manual procedure combining ad-hoc protocols.   \u0026hellip;protocol that a certificate authority (CA) and an applicant can use to automate the process of verification and certificate issuance. The protocol also provides facilities for other certificate management functions, such as certificate revocation.\n  Since I have shell access to my VPS, I will focus on this approach. There are multiple ACME clients to choose from, and Certbot is \u0026lsquo;recommended\u0026rsquo; (by the EFF). On a superficial glance, GetSSL looks interesting as an alternative.   At this point, I will proceed with Certbot, because I\u0026rsquo;ve not yet found any particular reason not to.\n On Certbot [0/1] The Certbot website provides customized instructions for the OS and server. The main requirement(s) is having an online HTTP website with an open port 80, hosted on a server. I can go ahead since I\u0026rsquo;ve got these.\n Certbot will run on the web server (not locally) periodically and will help in automating the process of certificate management.\n Setting up Certbot (on debian)\nwget https://dl.eff.org/certbot-auto sudo mv certbot-auto /usr/local/bin/certbot-auto sudo chown root /usr/local/bin/certbot-auto sudo chmod 0755 /usr/local/bin/certbot-auto Checking that the above was actually done with a simple:\nls -al /usr/local/bin/cert* Next, a one-command certificate setup is possible (with nginx)\n Note that this command may require additional dependencies to be installed, and will need a bunch of user input as well, and so should not be run in a dumb terminal.\n sudo /usr/local/bin/certbot-auto --nginx This will:\n Install necessary dependencies and the certbot plugins (authenticator, installer) for nginx.   Noted the option of --no-boostrap for debian. I\u0026rsquo;m not sure, but this probably has to do with addressing the dependencies for different debian versions.\n For reference, the following packages were checked/installed:\nca-certificates is already the newest version (20190110). ca-certificates set to manually installed. gcc is already the newest version (4:8.3.0-1). libffi-dev is already the newest version (3.2.1-9). libffi-dev set to manually installed. libssl-dev is already the newest version (1.1.1c-1). openssl is already the newest version (1.1.1c-1). openssl set to manually installed. python is already the newest version (2.7.16-1). python-dev is already the newest version (2.7.16-1). python-virtualenv is already the newest version (15.1.0+ds-2). virtualenv is already the newest version (15.1.0+ds-2). virtualenv set to manually installed. Suggested packages: augeas-doc augeas-tools The following NEW packages will be installed: augeas-lenses libaugeas0 An email address has to be entered for \u0026lsquo;urgent\u0026rsquo; communication regarding the certificate, and optionally can be shared with the EFF (which was a trifle annoying (as a part of an installation process), though I said yes).\n I had to enable https with UFW to complete the test successfully. sudo ufw allow https. Earlier, only HTTP had been enabled.\n Automatic certificate renewal by setting up a cron job.\necho \u0026#34;0 0,12 * * * root python -c \u0026#39;import random; import time; time.sleep(random.random() * 3600)\u0026#39; \u0026amp;\u0026amp; /usr/local/bin/certbot-auto renew\u0026#34; | sudo tee -a /etc/crontab \u0026gt; /dev/null deciphering the cron job, and verifying it is as expected. For now, I\u0026rsquo;ve not run this command because I want to know what it is doing first.  As an alternative to a \u0026lsquo;one-step\u0026rsquo; installation, getting just the certificate will mean nginx\u0026rsquo;s configuration will have to done manually. This is probably a good choice to \u0026lsquo;learn more\u0026rsquo;.\nsudo /usr/local/bin/certbot-auto certonly --nginx  I need to verify this, but it appears nginx\u0026rsquo;s main configuration is at /etc/nginx/nginx.conf , and a quick peek showed me that the user was still set as \u0026lsquo;www-data\u0026rsquo;, which was used as the initial setup of the nginx test website. This was changed subsequently. Perhaps this is why I am unable to get Wordpress plugins write access.\n At the end of it all, I received a link, through which it appears I can get a detailed \u0026lsquo;SSL Report\u0026rsquo;.\nCongratulations! You have successfully enabled https://s.ragavan.co You should test your configuration at: https://www.ssllabs.com/ssltest/analyze.html?d=s.ragavan.co  This report appears to be quite important, but I could not make much sense of it, and it needs to be re-visited. As such, I see that the ACME challenges need to be understood to comprehend these results.\n Short Peek under the hood. A skim of the extensive documentation of Certbot shows that certbot relies on 2 types of plugins to function.\n authenticators: plugins to obtain a certificate, but not install (i.e edit the server configuration). Used with the certonly command. Installers: used to modify the server\u0026rsquo;s configuration. Used with the install command. Authenticators + installers : can be used with the certbot run command.  These plugins use \u0026lsquo;ACME Protocol challenges\u0026rsquo; to prove domain ownership. Section 7 (as of today) of the internet draft of the standard provides an overview, and the challenges are described in detail in the draft.\n There are few types of identifiers in the world for which there is a standardized mechanism to prove possession of a given identifier. In all practical cases, CAs rely on a variety of means to test whether an entity applying for a certificate with a given identifier actually controls that identifier.\nChallenges provide the server with assurance that an account key holder is also the entity that controls an identifier. For each type of challenge, it must be the case that in order for an entity to successfully complete the challenge the entity must both:\n Hold the private key of the account key pair used to respond to the challenge\n Control the identifier in question\n   Conclusions  HTTPS via Let\u0026rsquo;s Encrypt is setup for my website. Come visit at https://s.ragavan.co Had a brief introduction into the methodology/philosophy behind Let\u0026rsquo;s Encrypt. Brief exploration of ACME and it was quite interesting to go through the draft standard, though it will take a lot more effort to fully comprehend all the tests. I think it is likely that I have visit this in more detail as I make progress in learning about encryption. Learned about the existence of \u0026lsquo;Internet Standards\u0026rsquo;. These are documented by one or more documents called RFC\u0026rsquo;s (Request for Comments) and revised until deemed satisfactory to become a standard.  ","date":1564006380,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572786887,"objectID":"3b2c23b5fa2103cd37dec5bbdc84597c","permalink":"https://shrysr.github.io/post/implementing-https-lets-encrypt/","publishdate":"2019-07-24T16:13:00-06:00","relpermalink":"/post/implementing-https-lets-encrypt/","section":"post","summary":"What is Let\u0026rsquo;s Encrypt? Let\u0026rsquo;s Encrypt is a Certificate Authority (CA). A certificate from a CA is required to enable HTTPS.\nCertbot\u0026rsquo;s documentation summarises it well:\n Certbot is part of EFF’s effort to encrypt the entire Internet. Secure communication over the Web relies on HTTPS, which requires the use of a digital certificate that lets browsers verify the identity of web servers (e.g., is that really google.com?). Web servers obtain their certificates from trusted third parties called certificate authorities (CAs).","tags":["https","encryption"],"title":"Implementing HTTPS : Let's Encrypt","type":"post"},{"authors":null,"categories":["Docker","DataScience"],"content":" Docker is a fascinating concept that could be potentially useful in many ways, especially in Data science, and making reproducible workflows / environments. There are several articles which have great introductions and examples of using docker in data science\nThis is an evolving summary of my exploration with Docker. It should prove to be a handy refresher of commands and concepts.\nTODO What is Docker A brief summary of what Docker is all about.\n The main idea: disposable buckets of code that can do a specific task and either exit or run indefinitely.  The task / purpose of the container could even be a single command. Like pwd, which is piped into another container. In a way this is an extension of the Unix philosophy of small tools that can do a single task well (i.e reliably).  These buckets of code can be connected with each other and also stacked on top of each other to form a pipeline. These buckets of code are complete libraries The buckets consist of images which can be launched as containers. Docker images are stored in a registry. There are a number of registries, of which dockerhub is popular.  These schematics provide a good refresher of the core concept of Docker:\n Containers versus VM    Docker Engine components   Containers versus VM\nEngine Components\nDive into Docker This is an excellent course run by Nick Janatakis (link), which enabled me to tie together various bits and pieces of knowledge I had about Docker. I would recommend this course for anybody starting out with Docker. A lot of the notes in this document were gathered while going through the course.\nBiggest wins of Docker  isolate and manage applications. eg: 12 apps with 12 dependency sets. VM : waste of resources. Vagrant : lets you manage VM\u0026rsquo;s on the command line (including Docker)  Disk space occupied for each app is very high. Overhead of system boot up and restart / killing is high.  Docker can be used to manage common dependencies.  Example of time frame: 2 seconds for loading 8 services. Spinning up an entire stack is very fast, compared to a VM.  Docker: portability of applications and dev environment. Dozens of scenarios where something works for you but not for me. New dev environments can be discouraging. With all the libraries and dependencies already installed, it is possible to become aggressive with the actual development and experimenting with new technology. Multiple versions of a programming language can be installed within a single docker container. Smaller Microservices that talk to each other are not always good, but Docker enables this in a streamlined manner. LXC: raw linux containers. Existed long before docker.  uses runC very complicated and brittle system. runs only on Linux. LXC\u0026rsquo;s are still better than VM\u0026rsquo;s for rapid build and deploy.  ANSIBLE: what files and tools should be on a server (very basic definition)  Easy ways to get documentation help  Just typing in docker will provide a list of primary level commands that can be used. For further flags, provide the primary command like docker run --help The official documentation is a good resource.  Definitions  Image: Setup of the virtual computer. Container: Instance of an image. Many containers can run with the same image.  TODO Running Emacs on Docker  Note taken on [2019-07-07 Sun 17:25]  Matrix DS offers a viable alternative as a platform. However, a customised docker container with all my tools is a good way to reproduce my working environment and also share my work with the community. Note taken on [2019-07-06 Sat 17:54]  This needs to be evaluated. Today I have a vague idea : set up a docker container combining Rocker + data science at the command line + Scimax together. A separate layer could also cater to shiny apps.\n https://www.christopherbiscardi.com/2014/10/17/emacs-in-docker/\n Silex - github : Also contains references to other kinds of Emacs docker containers\n  TODO Good Online resources for Rocker Introducing Rocker: Docker for R | R-Bloggers Rocker: Using R on Docker - A Hands-On Introduction - useR2015_docker.Pdf Jessie Frazelle\u0026rsquo;s Blog: Using an R Container for Analytical Models ROcker Images - Wiki Github Introduction to Docker - Paper Need to find a way to extract a bunch of links from the bookmark and directly available with org Mode. Play with Docker link  TODO Introduction to Rocker - Technical paper link Installation Note on Docker Toolbox versus Native apps The native Docker application uses the type 1 hypervisor (hyperkit for Mac OS and hyper-V for Windows). docker-machine uses a virtualbox based hypervisor (type 2). This can also be specified while creating docker machines.\nIn general, the native applications have a better user experience and commands can be directly typed into the terminal. The native apps (on Windows/ Mac OS) are newer than the Docker toolbox, and are being actively developed by the Docker company to reach performance on par with the original virtualbox based Docker Toolbox approach.\nNote that any performance lag depends on the application and as a thumb rule it may be better to start off with the native applications and switch to the toolbox when required.\nInstalling Docker on debian The docker repository has to be added first for being able to install docker. Detailed instructions are available at https://docs.docker.com/install/linux/docker-ce/debian/.\nA package is also available, and is probably the easiest method to install. Choose the appropriate version at: https://download.docker.com/linux/debian/dists/\nManual version without using the package:\nAdding Docker\u0026rsquo;s official GPG key:\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - Searching that the key has been installed:\nsudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) docker@docker.com sub rsa4096 2017-02-22 [S]\nAdding the stable Docker repository:\nsudo add-apt-repository \\  \u0026#34;deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs)\\ stable\u0026#34; Update the package lists and now search for docker-ce. It should be available since the repository has been added and the list updated.\nsudo apt-get update Installing docker and necessary components. Note that the manual recommends removing any older installations if they exist.\nNote from the manual that different versions of docker can be installed by including sudo apt-get install docker-ce=VERSION=abcd. Therefore multiple versions can probably exist side by side.\nsudo apt-get install docker-ce docker-compose docker-ce-cli containerd.io Creating a docker group and adding this to the sudoers list will enable running docker commands without using root privileges (sudo). A logout will be necessary to have the changes take effect.\nNote: Sometimes the $USER variable does not seem to work. This can be replaced with your actual user name.\nsudo groupadd docker sudo usermod -aG docker $USER To configure docker to start on boot, enable it as a service. The need to do this depends on how frequently you use docker commands.\nsudo systemctl start docker Installing Docker on Antergos / Arch Linux Installation can be done via Pacman\nsudo pacman -S docker Enable and start docker service.\nsudo systemctl enable docker sudo systemctl start docker Add docker to the user\u0026rsquo;s group using usermod. After adding this, a log-out is necessary. Note that $USER can be replaced with the output of whoami in the shell if desired. If this step is not performed, each docker command will have to be executed with Sudo elevation.\nsudo usermod -a -G docker $USER Installing Docker on Mac OS Docker can be downloaded as an app from the docker store : https://hub.docker.com/editions/community/docker-ce-desktop-mac.\nOn the Mac, the docker app has to be launched run first, and this will create a docker icon in the menu bar indicating the status of the docker machine. This launches the docker daemon, and then commands can be directly entered into the terminal.\nDocker can also be installed using Brew:\nbrew cask install docker This created an app in the Applications folder which has to be launched. However, it seems additional components are required to run Docker from the command Line. These are available via brew.\nbrew install docker-compose docker-machine Checking the installation docker info Trying the hello world container as an additional check. Note the steps listed in the output, which is the typical process.\ncd ~/docker-test docker run hello-world Checking docker-compose version.\ndocker-compose --version General notes on containers and images  images contain the entire filesystem and parameters needed to run the application. When an image is run, a container is created. containers are generally immutable and changes do not linger One image can spawn any number of containers, simultaneously. Each container will be separate.  Default location of images By default, on Antergos (Linux), the images are stored at /var/lib/docker/\nsudo ls -al /var/lib/docker Docker version and info docker --version docker info docker version Listing Docker containers and images List Docker Images\ndocker image ls List running Docker Containers\ndocker container ls List all docker containers (running and Stopped)\ndocker container ls -a Obtain only container ID\u0026rsquo;s (All). This is useful to extract the container number alone. The q argument stands for quiet.\ndocker container ls -aq Getting started Ropenscilabs has a basic introduction to Docker, and the Docker documentation is also a good place to start. A rocker specific introduction is available here.\nIf a local image is not found, docker will try to search and download the image from docker hub.\nIt is better to create a folder wherein the docker container will reside.\nmkdir ~/docker-test/ cd ~/docker-test docker --rm -p 8787:8787 rocker/tidyverse The --rm flag indicates the container will be deleted when the container is quite. The -p flag denotes using a particular port. iner a Note that the interim messages and download progress are not shown in eshell.\nDifferent rocker images are available, depending on the need to be served.\nAttaching shells -t and Interactive containers -i Example to run an ubuntu container and run bash interactively, by attaching a terminal to the container. This will login to Ubuntu and start bash.\nAn alternative option is to use alpine linux, which is a much smaller download.\ndocker run -t -i ubuntu /bin/bashdocker run -ti alpine /bin/bash Running a detached container  use the -d flag  docker container ls -al docker run -d ubuntu Build process of a docker image  docker commit : used to commit changes to a new image layer. This is a manual process. Commit has little place in the real world. Dockerfile is superior. Dockerfile : blue print or recipe for creating a docker image. Each actionable step becomes a separate layer.  Docker image : result of stacking up individual layers. Only the parts or layers that have changed are downloaded for a newer version of a specific image.\nScratch image: docker image with no base operating system\nWorking with dockerfiles  sample or reference docker files can be saved as \u0026ldquo;dockerfile.finished\u0026rdquo; or with some other useful extension. Dockerfiles are read top to bottom. the first non-comment instruction should be FROM  FROM allows you import a docker image.  RUN : basically executes the specified commands WORKDIR : setting the desired working directory. This can be set or used multiple times in the same docker file.  ","date":1562877206,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562877206,"objectID":"600f189b738b121d5e495540c8519b09","permalink":"https://shrysr.github.io/docs/docker-notes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/docker-notes/","section":"docs","summary":"Docker is a fascinating concept that could be potentially useful in many ways, especially in Data science, and making reproducible workflows / environments. There are several articles which have great introductions and examples of using docker in data science\nThis is an evolving summary of my exploration with Docker. It should prove to be a handy refresher of commands and concepts.\nTODO What is Docker A brief summary of what Docker is all about.","tags":["Docker","Data-Science"],"title":"Notes on Docker","type":"docs"},{"authors":null,"categories":["R","Data-Science"],"content":" Lubridate - introductory technical paper This paper (Grolemund and Wickham) offers a good introduction and comparison between using lubridate and not using it, as well as several examples of using the library. It also offers some case studies which can serve as useful drill exercises.\nImporting multiple excel sheets from multiple excel files This is one approach to importing multiple sheets from multiple excel files into a list of tibbles. The goal is that each sheet is imported as a separate tibble.\nLoading the libraries: While you may have the tidyverse package installed, this approach uses the package rio ( ).\n## install the rio library. ## Rio makes data import a little easier for different file types. ## install.packages(\u0026#34;rio\u0026#34;) library(\u0026#34;rio\u0026#34;) library(\u0026#34;tidyverse\u0026#34;) User input for the path. This basically points towards a folder which presumably contains multiple excel files.\n## Note that patterns can be provided as an argument to filter file types. folder_path \u0026lt;- c(\u0026#34;~/temp/bsu_test/\u0026#34;) The information in the directory can be gleaned with the fs::dir_info function, and from this the path variable can be pulled which will contain the paths to the excel files found.\nexcel_paths_tbl \u0026lt;- fs::dir_info(folder_path) paths_chr \u0026lt;- excel_paths_tbl %\u0026gt;% pull(path)  import_list() from the rio package is used and the class is set to tibble using the argument tbl.\n An anonymous function is used to map the paths and apply the import_list function on each path.\n For example: assuming that there were 2 Nos. excel files in the specified directory; = the map function creates 2 lists containing 2 tibbles each. Each tibble represents an excel sheet from the file.\n The final combine() function combines these 2 Nos. lists into a single list of 4 tibbles, each being a sheet in the excel file.\n  excel_data \u0026lt;- paths_chr %\u0026gt;% map(~ import_list(. , setclass = \u0026#34;tbl\u0026#34;)) %\u0026gt;% combine() glimpse(excel_data) References  BSU Course DSB-101-R I learnt about the Rio package in this Stack Overflow discussion  TODO Data Explorer package The DataExplorer package aims to have tools for EDA, Feature engineering and Data reporting. It is handy to get quick overview of the data from multiple perspectives.\nInstallation\ninstall.packges(\u0026#34;DataExplorer\u0026#34;) Salient points:\n A list of data frames can be provided as the input. plot_str : display a graphic networking the various variables, their types and the list of data frames. This is displayed in the browser. The type = \u0026quot;r\u0026quot; argument can be used for a radial network. introduce : provides a table of numbers rather than percentages, like the number of rows, columns, missing data and so on. plot_intro : Visualises the output of introduce. plot_missing : useful to know the percentage of missing values in each feature. 6.  Devtools package  \u0026hellip;devtools package, which is the public face for a suite of R functions that automate common development tasks.\nR Packages (book)\n Official details of package development : link\nBasic libraries to aid package development install.packages(c(\u0026#34;devtools\u0026#34;, \u0026#34;roxygen2\u0026#34;, \u0026#34;testthat\u0026#34;, \u0026#34;knitr\u0026#34;)) Visdat : preprocessing visualisation link This package could be very useful in exploring new data or looking at how the data is changing after a wrangling operation. It could save repeatedly looking at the CSV file manually to make sure the change is implemented.\nInstalling Visdat\nlibrary(\u0026#34;easypackages\u0026#34;) packages(\u0026#34;visdat\u0026#34;) Main Functions:\nvis_dat vis_miss vis_compare vis_expect vis_cor vis_guess General Exploration\nNote: typical_data is a dataset that is included with the package and is useful to explore the functions.\nlibraries(\u0026#34;tidyverse\u0026#34;, \u0026#34;visdat\u0026#34;) vis_dat(typical_data) vis_miss(typical_data) Clustering the missing data in the columns\nvis_miss(typical_data, cluster = TRUE) Long \u0026lt;-\u0026gt; Wide formats : example for gathering library(\u0026#34;tidyverse\u0026#34;) ## Defining a sample tribble with several duplicates a \u0026lt;- tribble( ~IDS, ~\u0026#34;client id 1\u0026#34;, ~\u0026#34;client id 2\u0026#34;, ~\u0026#34;client id 3\u0026#34;, ~\u0026#34;client id 4\u0026#34;, ~\u0026#34;old app\u0026#34;, ~\u0026#34;new app\u0026#34;, 123, 767, 888,\u0026#34;\u0026#34; , \u0026#34;\u0026#34;, \u0026#34;yes\u0026#34; , \u0026#34;no\u0026#34;, 222, 333, 455, 55, 677, \u0026#34;no\u0026#34;, \u0026#34;yes\u0026#34;, 222, 333, 343, 55,677, \u0026#34;no\u0026#34;, \u0026#34;yes\u0026#34; ) ## Defining vector to form column names vec1 \u0026lt;- seq(1:4) vec2 \u0026lt;- \u0026#34;client id\u0026#34; vec3 \u0026lt;- str_glue(\u0026#34;{vec2} {vec1}\u0026#34;) ## Gathering and removing duplicates a %\u0026gt;% gather( key = \u0026#34;Client number\u0026#34;, value = \u0026#34;client ID\u0026#34;, vec3 ) %\u0026gt;% unique() Matrix Defining a matrix A matrix is a collection of elements of the same data type (numeric, character, or logical) arranged into a fixed number of rows and columns.\nA matrix is called two-dimensional, since there are rows and columns. It is constructed using the matrix() function.\nArguments:\n Elements of the matrix byrow to have the matrix filled by rows. By default, this is set to false. nrow for number of rows  matrix(1:10,byrow = TRUE, nrow = 4) Demonstrating the difference of not using byrow\nmatrix(1:10, ncol = 2, nrow = 5)matrix(1:10, ncol = 2, nrow= 5 , byrow = TRUE) Naming the rows and the columns rownames() and colnames() can be used.\n#Defining the row data row_1 \u0026lt;- c(250, 300) row_2 \u0026lt;- c(55, 350) # Defining the matrix my_matrix \u0026lt;- matrix(c(row_1, row_2), byrow = TRUE, nrow = 2) # Defining row and column names my_rownames \u0026lt;- c(\u0026#34;test_row1\u0026#34;, \u0026#34;test_row2\u0026#34;) my_colnames \u0026lt;- c(\u0026#34;test_col1\u0026#34;, \u0026#34;test_col2\u0026#34;) # Attaching row and column names to the created matrix rownames(my_matrix) \u0026lt;- my_rownames colnames(my_matrix) \u0026lt;- my_colnames my_matrix Sums - rowSums() and colSums(), adding rows - rbind() and columns - cbind() my_rowsums \u0026lt;- rowSums(my_matrix) # Adding a new column of the calculated sums my_new_matrix \u0026lt;- cbind(my_matrix, my_rowsums) my_new_matrix # Adding a new row and calculating the sums again row_3 \u0026lt;- c(200, 100 ) my_newest_matrix \u0026lt;- rbind(my_matrix, row_3) my_new_rowsums \u0026lt;- rowSums(my_newest_matrix) my_newest_matrix \u0026lt;- cbind(my_newest_matrix, my_new_rowsums) my_newest_matrix Dates  The ISO 8601 format is the way R accepts and stores dates. This is basically in the yyyy-mm-dd format. Internally stored by R as the number of days since January 1, 1970. Alternative format year/month/day Dates are internally stored as numerics with some special characteristics over typical numerics. Current time from the system : Sys.time() Current date from the system : Sys.Date() Character vectors are most common source of creating dates. class of dates  could be a date class catering to calendar dates. could also be a POSIX - Portable Operating System Interface class, which is commonly used in the finance world  POSIXlt and POSIXct allow holding a date. POSIXct is a way to represent datetime objects like \u0026ldquo;2015-01-22 08:39:40 EST\u0026rdquo;. This method is important for storing intraday financial data.  Using the simplest date class is generally the best strategy. There are other classes of date as well.  as.date() can be used to convert the object to a date class.  the format argument can facilitate conversion from different formats to the necessary ISO format.  Extractor functions  weekdays() can be used to extract the day of the week from a date object. format() can be used to convert existing date objects to different date formats. months() for extracting the months of the date objects quarters() to extract the quarter in which the date object falls  Dates can be subtracted, just like numerics.  The object must be in the Date format. Direct subtraction provides the difference in days. difftime(date1, date2, units = \u0026quot;secs\u0026quot;) can be used to find the difference in time, with the argument units specifying the output type  Argument units should be one of “auto”, “secs”, “mins”, “hours”, “days”, “weeks” The 2nd argument date2, will be subtracted from the first argument date1.   Formats of representing alternate date formats  Y: 4-digit year (1982) y: 2-digit year (82) m: 2-digit month (01) d: 2-digit day of the month (13) A: weekday (Wednesday) a: abbreviated weekday (Wed) B: month (January) b: abbreviated month (Jan)   # Using the system date and time todays_date \u0026lt;- Sys.Date() todays_time \u0026lt;- Sys.time() todays_date todays_time # Class of defined date and time class(todays_date) class(todays_time) # Reading alternate formats of dates test_date_alt_format \u0026lt;- \u0026#34;23/02/2019\u0026#34; as.Date(test_date_alt_format, format = \u0026#34;%d/%m/%Y\u0026#34;) test2_date_alt_format \u0026lt;- \u0026#34;Sep 25,2020\u0026#34; as.Date(test2_date_alt_format, format = \u0026#34;%B %d,%Y\u0026#34;) # Extractor functions weekdays(as.Date(test2_date_alt_format, format = \u0026#34;%B %d,%Y\u0026#34;)) # Subtracting dates date1 \u0026lt;- as.Date(\u0026#34;2030-02-20\u0026#34;) date2 \u0026lt;- as.Date(\u0026#34;2040-03-30\u0026#34;) date2 - date1 difftime(date2, date1, units = \u0026#39;secs\u0026#39;) difftime(date1, date2, units = \u0026#39;mins\u0026#39;) # Setting the weekdays as names() dates3 \u0026lt;- c(date1, date2, as.Date(c(\u0026#34;2025-03-23\u0026#34;, \u0026#34;2015-04-25\u0026#34;))) names(dates3) \u0026lt;- weekdays(dates3) dates3 # Syntax example of using Not (relational operators) a \u0026lt;- c(100,140,2,240, 300) # checking where a is Not greater than 200 !(a \u0026gt; 200) # Testing runif() Vectors  One dimensional collection of data. vectors need to contain a similar data type. To combine multiple data types, a data frame type object or a list is required. length() can be used with numeric type vectors to find the length of the vector. However the nchar() function should be used for character type vectors (using length() will provide an answer of 1) A single number is also stored as a vector of length 1.  a \u0026lt;- c(\u0026#34;This is a character type vector\u0026#34;, \u0026#34;which contains 2 strings\u0026#34;) a length(a) # the result will be 2 because there are 2 elements nchar(a) # Actual number of characters in each string Vectorised functions Most functions in R are vectorised. The function will apply itself to each element of a vector. This concept is important to understand especially while progressing onto tidyeval style Functions.\nExample of multiple substitutions with the assignment operator which is a vectorised function.\nlanguages \u0026lt;- c(\u0026#34;English\u0026#34;, \u0026#34;Italian\u0026#34;, \u0026#34;Urdu\u0026#34;) print(languages) languages[c(2,3)] \u0026lt;- c(\u0026#34;Norwegian\u0026#34;, \u0026#34;Latin\u0026#34;) print(languages) Lists  The list is a one dimensional collection of data, like a vector. The list data type is equivalent to the dictionary data type in Python. Use the list() with the chosen data structures as the arguments. The list can contain multiple types of objects or data types. Lists are used to create Dataframes.  # Creating a simple list of 4 elements, name, age, height, horn.sizre my.list \u0026lt;- list( name = \u0026#34;Shreyas\u0026#34;, age = 776, height = 167, horn.size = 25 ) my.list # the tag names can be extracted using the names() names(my.list)  Subsetting: using a [] returns a subset of the list and using [[]] returns the data inside the list being referenced.  A single bracket always means to filter a location. list[] is actually a filtered list. Single brackets return a list and Double brackets return the element itself. A subset can be used on a dateframe to extract specific data. Syntax example with conditionals: subset(dataframe, column1 \u0026gt; condition1 \u0026amp; column2 \u0026lt; condition2)  The elements of the list can be named, by adding the element to the arguments while defining the list. adding names to an existing list can be done using the names(list name) function. With a named list, the $ operator can also be used to access specific list items. items can be added to the list using c(), which would look like c(list_name, new_item_name = item_name) Removing elements from a list can be done by assigning the item the NULL value. Other list creating functions  split() : split(list-name, item-name). This will create 2 lists separated by the item name specified. unsplit() : to unsplit a list. unsplit(split-list-name, grouping) Similar syntax to the above. split-apply-combine class of problems. Example is where a particular factor is to be applied for a portion of the data and another factor for the other portion, and after which the 2 portions are recombined. For eg: offering customer A a discount of 10% and customer B a discount of 20% via splitting and them recombining the split parts into a common dataframe.  attributes(): meta data of an object. For example the dim or dimension is an attribute of a matrix, and the names, row.names and class are common attributes of a dataframe.  use attr() to access a specific attribute. This takes 2 arguments at least. attr(matrix_name, which = \u0026quot;desired attribute\u0026quot;)  Applying functions to lists  lapply is for lists. sapply : simplified apply works well with Vectors.   people \u0026lt;- c(\u0026#34;shreyas\u0026#34;, \u0026#34;tom\u0026#34;, \u0026#34;harry\u0026#34;) lapply(people, toupper) # the first argument is the list and the 2nd argument is the function. Additional arguments to the function can also be supplied. This returns a new list and the old list remains unmodified. lapply(people, paste, \u0026#34;hello\u0026#34;) people Examples using lapply and other list and vector Manipulation\n# Creating vectors of meals and meal items breakfast \u0026lt;- c(\u0026#34;eggs\u0026#34;, \u0026#34;bread\u0026#34;, \u0026#34;orange juice\u0026#34;) lunch \u0026lt;- c(\u0026#34;pasta\u0026#34;, \u0026#34;coffee\u0026#34;) meals \u0026lt;- list(breakfast = breakfast, lunch = lunch) meals meals \u0026lt;- c(meals, list(dinner = c(\u0026#34;noodles\u0026#34;, \u0026#34;bread\u0026#34;))) meals names(meals) # Extracting dinner dinner \u0026lt;- meals$dinner # Adding earlier meals to a separate list early_meals \u0026lt;- c(meals[\u0026#34;breakfast\u0026#34;], meals[\u0026#34;lunch\u0026#34;]) early_meals # Finding the number of items in each meal. number_items_meal \u0026lt;- lapply(meals , length) number_items_meal # Write a function `add_pizza` that adds pizza to a given meal vector, and returns the pizza-fied vector add_pizza \u0026lt;- function(vector, string = \u0026#34;pizza\u0026#34;) { pizzafied \u0026lt;- paste(vector, string, sep = \u0026#34;-\u0026#34;) return(pizzafied) } add_pizza(breakfast) # Create a vector `better_meals` that is all your meals, but with pizza! updated_meals \u0026lt;- c(add_pizza(breakfast), add_pizza(lunch), add_pizza(dinner) ) updated_meals Factors  factor() can be used to store the unique levels of a vector.  The vector to be converted to a factor is passed in as an argument.  levels() can be used to access the unique levels of a factor object.  Rename the levels by just passing a vector levels(factor_object)  cut() can be used to break up a vector into specified buckets or based on specified intervals.  argument \u0026lsquo;breaks\u0026rsquo; to specify the demarcations in which the vector will be cut up. R treats the left side of the bucket as exclusive and the right side of the bucket as inclusive. This is represented by \u0026lsquo;(\u0026rsquo; and \u0026lsquo;]\u0026rsquo;.  summary() can be used to provide the counts of items under each factor. This is best used on a factor object. Ordering and sub-setting vectors  ordered() : R has an inbuilt system to order the object alphabetically. passing the levels argument to factor() along with the argument ordered = T, with levels containing the desired order (written as least to greatest) will enable a custom ordering of factors. drop = T argument to drop a level completely. Subsetting with [-1] only drops the object at the first position, but retains the level. R\u0026rsquo;s default behavior when creating data frames is to convert all characters into factors   Working with categorical data:  forcats::as_factor() : assigns factor values based on order in the vector base::as.factor() : uses an alphabetical order. Assigns factor order based on the alphabetical order  ranking \u0026lt;- c(1:20) head(ranking) buckets \u0026lt;- c(0, 5, 10, 15, 20) ranking_grouped \u0026lt;- cut(ranking, breaks = buckets) head(ranking_grouped) ranking_grouped Dataframe Used to store a table of data. Multiple data types can be stored in a single dataframe. A matrix can store only a single data type.\n Defined using data.frame() colnames() : to rename the columns in a dataframe subset() : to extract a particular subset of a dataframe. Compared to calling a column name, using this is more informative or robust.  first argument: name of the dataframe 2nd argument: the condition or the column name within the dataframe  A column can be deleted by assigning it NULL There is no need to use a c() to add multiple objects to the dataframe. Directly add the vectors like data.frame(variable 1, variable 2) and so on.  TODO Dataframe peek function in R head() tail() str() desc() glimpse() Package installation (especially for data science and ML) The package easypackages enables quickly loading or installing multiple libraries. This snippet will enable installing multiple packages. In general, it is better to install packages one by one. They can however be called together.\ninstall.packages(\u0026#34;easypackages\u0026#34;) library(\u0026#34;easypackages\u0026#34;) packages(\u0026#34;tidyverse\u0026#34;, \u0026#34;tidyquant\u0026#34;, \u0026#34;glmnet\u0026#34;, \u0026#34;rpart\u0026#34;, \u0026#34;rpart.plot\u0026#34;, \u0026#34;ranger\u0026#34;, \u0026#34;randomForest\u0026#34;, \u0026#34;xgboost\u0026#34;, \u0026#34;kernlab\u0026#34;, \u0026#34;visdat\u0026#34;) Basic Statistics concepts Median ##\u0026#39; Source: Conway, Drew; White, John Myles. Machine Learning for Hackers: Case Studies and Algorithms to Get You Started (p. 39). O\u0026#39;Reilly Media. Kindle Edition. ##\u0026#39; Additional comments are my own. ##\u0026#39; Function to illustrate how a median is calculated for odd and even datasets my.median \u0026lt;- function(x){ # Step 1: Sort x ascending or descending sorted.x \u0026lt;- sort(x) # Find the length of x whether (odd number of digits or even). If odd : there are 2 medians. If even: there is a single median. if(length(x) %% 2 != 0){ indices \u0026lt;- c(length(x)/2 , length(x)/2 +1) # These numbers are used as indices for the initially sorted vector to return the exact median. return(mean(sorted.x[indices])) } else { index \u0026lt;- ceiling(length(x)/2) return(sorted.x[index]) } Quantile # Defining a sample of numbers to calculate quantile. a \u0026lt;- c(seq(from = 1, to = 30), seq(from = 40, to = 50, by = 0.2)) quantile(a) # Defining bins or cuts for quantile. The default is 0.25. quantile(a, probs = seq(0,1,by = 0.2)) promptData() : generate shell documentation of dataset If the filename argument is given as \u0026ldquo;NA\u0026rdquo;, the output will provide lists of the information. If no filename is specified, then an .Rd file will be created in the same working directory.\npromptData(sunspots, filename = NA) Downloading a file to specific location With wget : -P is the flag for the prefix directory for the file being downloaded. The path will be created if it does not exist. If the file already exists, a duplicate will be created with the \u0026lsquo;.1\u0026rsquo; suffix. Since this is a string being passed to wger, the \u0026ldquo; and other characters have to be explicitly escaped.\n## Download file to specific location system(\u0026#34;wget \\\u0026#34;https://raw.githubusercontent.com/amrrs/sample_revenue_dashboard_shiny/master/recommendation.csv\\\u0026#34; -P ./sales-rev-app/\u0026#34;) Removing user installed packages alone Sometimes, it is not possible to remove R completely. This is a nice snippet from an R-bloggers post to remove the user installed packages alone.\n# create a list of all installed packages ip \u0026lt;- as.data.frame(installed.packages()) head(ip) # if you use MRO, make sure that no packages in this library will be removed ip \u0026lt;- subset(ip, !grepl(\u0026#34;MRO\u0026#34;, ip$LibPath)) # we don\u0026#39;t want to remove base or recommended packages either\\ ip \u0026lt;- ip[!(ip[,\u0026#34;Priority\u0026#34;] %in% c(\u0026#34;base\u0026#34;, \u0026#34;recommended\u0026#34;)),] # determine the library where the packages are installed path.lib \u0026lt;- unique(ip$LibPath) # create a vector with all the names of the packages you want to remove pkgs.to.remove \u0026lt;- ip[,1] head(pkgs.to.remove) # remove the packages sapply(pkgs.to.remove, remove.packages, lib = path.lib) Rprofile and user files  ?Startup in the R interpreter for information on how the R environment is started up. Note that the Rprofile.site and other user files are not setup by default. These have to be created by the user. The default CRAN repo can be set in the Rprofile.site file  To find the installation location of R, use the R.home() function with component specified as shown below. More information.\nR.home(component=\u0026#39;home\u0026#39;) R.home(component=\u0026#39;etc\u0026#39;) Jupytext for conversion to Rmd  Jupytext can save Jupyter notebooks as:\n Markdown and R Markdown Documents, Julia, Python, R, Bash, Scheme, Clojure, Matlab, Octave, C++ and q/kdb+ scripts.  Jupytext package\n The is a convenient tool to convert the jupyter notebook into multiple formats, and it also enables collaboration across documents.\nInstalling Jupytext using conda:\nconda install -c conda-forge jupytext My most common usage of this tool is to convert jupyter notebooks (.ipynb) to Rmarkdown(Rmd). Deploying jupytext as a Library of Babel(LOB) Ingest makes it easy to be called from anywhere in Emacs.\n\njupytext $jup_notebook --to rmarkdown Package installation (especially for data science and ML) The package easypackages enables quickly loading or installing multiple libraries. This snippet will enable installing multiple packages. In general, it is better to install packages one by one. They can however be called together.\ninstall.packages(\u0026#34;easypackages\u0026#34;, ) library(\u0026#34;easypackages\u0026#34;) packages(\u0026#34;tidyverse\u0026#34;, \u0026#34;tidyquant\u0026#34;, \u0026#34;glmnet\u0026#34;, \u0026#34;rpart\u0026#34;, \u0026#34;rpart.plot\u0026#34;, \u0026#34;ranger\u0026#34;, \u0026#34;randomForest\u0026#34;, \u0026#34;xgboost\u0026#34;, \u0026#34;kernlab\u0026#34;) Installing the R kernel for Jupyter notebooks Reference: link\nThe easiest way for me to export org files to a notebook format will be using the Ipython notebook export available in Scimax. Installing the R kernel for Jupyter notebooks is as simple as installing an R package:\ninstall.packages(\u0026#39;IRkernel\u0026#39;) To register the kernel in the current R installation:\nIRKernel::installspec() Per default IRkernel::installspec() will install a kernel with the name “ir” and a display name of “R”. For having multiple versions of R available as kernels:\n# in R 3.3 IRkernel::installspec(name = \u0026#39;ir33\u0026#39;, displayname = \u0026#39;R 3.3\u0026#39;) # in R 3.2 IRkernel::installspec(name = \u0026#39;ir32\u0026#39;, displayname = \u0026#39;R 3.2\u0026#39;) It is possible to install the IRKernel package via Docker.\nNote: Some additional packages may be required before installing IRKernel. Try the following:\ninstall.packages(c(\u0026#39;repr\u0026#39;, \u0026#39;IRdisplay\u0026#39;, \u0026#39;evaluate\u0026#39;, \u0026#39;crayon\u0026#39;, \u0026#39;pbdZMQ\u0026#39;, \u0026#39;devtools\u0026#39;, \u0026#39;uuid\u0026#39;, \u0026#39;digest\u0026#39;)) devtools::install_github(\u0026#39;IRkernel/IRkernel\u0026#39;) Troubleshooting with R version.  finding the R version being used is as simple as typing in version on the R console the shell command which R can also be used to find the path from R is being loaded. anaconda installs earlier versions of R. This has to be removed completely, so that a single version of R is accesed by R studio and R console and within Emacs as well. in my case, differing versions 3.4 and 3.5 of R were being accessed, which made package installation difficult. therefore, I uninstalled the older conda version and then downloaded the R pkg from CRAN as a fresh install on the mac. it is possible to set the default R version for the inferior ESS shell in Emacs as specified here link  versionwhich R How an R session starts Source: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html\nUpgrading packages in R (R session) Source: Arch wiki When you also need to rebuild packages which were built for an older version:\nupdate.packages(ask=FALSE,checkBuilt=TRUE) when you also need to select a specific mirror (https://cran.r-project.org/mirrors.html) to download the packages from (changing the url as needed):\nupdate.packages(ask=FALSE,checkBuilt=TRUE,repos=\u0026#34;https://cran.cnr.berkeley.edu/\u0026#34;) You can use Rscript, which comes with r to update packages from a Shell:\nRscript -e \u0026#34;update.packages()\u0026#34; Installing R on Debian sudo cat \u0026gt;\u0026gt; /etc/apt/sources.list \u0026lt;\u0026lt; EOF # adding mirror for installation of R deb http://cran.rstudio.com/bin/linux/debian stretch-cran34/ EOF sudo apt-get update Using Debian\u0026rsquo;s GPG Key\nsudo apt install dirmngr sudo apt-key adv --keyserver keys.gnupg.net --recv-key \u0026#39;E19F5F87128899B192B1A2C2AD5F960A256A04AF\u0026#39; Installing r-Base\nsudo apt-get install r-base Some pre-requisite libraries are required for installing various R Packages\nsudo apt-get install libcurl4-openssl-dev","date":1562865696,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562865696,"objectID":"08b9fffc7e0a085a97e7b27fcda5d51a","permalink":"https://shrysr.github.io/docs/r-notes-snippets/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/r-notes-snippets/","section":"docs","summary":"Lubridate - introductory technical paper This paper (Grolemund and Wickham) offers a good introduction and comparison between using lubridate and not using it, as well as several examples of using the library. It also offers some case studies which can serve as useful drill exercises.\nImporting multiple excel sheets from multiple excel files This is one approach to importing multiple sheets from multiple excel files into a list of tibbles.","tags":["R","Data-Science"],"title":"R notes and snippets","type":"docs"},{"authors":null,"categories":["Emacs"],"content":" Introduction This is my literate, Org-mode based configuration for Emacs, which are essentially customisations built on top of the starter-kit Scimax. View a nicely rendered version with easy navigation on my website, or if you prefer: on github.\n Scimax - Awesome editing for scientists and engineers. Scimax is an Emacs starterkit for scientists and engineers. It provides a comprehensive configuration of Emacs for scientific programming and publishing.\nJohn Kitchin\n Scimax specific variables have their own heading to make it \u0026lsquo;easier\u0026rsquo; to experiment with other starter-kits.\nThe style of documentation is particularly influenced by the dotemacs config of Mathieu Marques, which I found very engaging to read.\n Note: The configuration posted on my website and github repo are updated from time to time, and may be older than the version I am using everyday.\n This configuration Scimax\u0026rsquo;s init calls the user.el script placed in the user folder. The following snippet is placed in user.el to load this org file and then my encrypted personal configuration. This org file and the tangled emacs-lisp script is also available in a github repo.\nLoading external packages: there are some packages which are not avaialble on MELPA and have to be loaded via cloning their git Repositories. This is especially relevant to new packages.\n(let ((default-directory \u0026#34;~/scimax/user/external_packages/\u0026#34;)) (normal-top-level-add-subdirs-to-load-path));; Loading this file that you are viewing, which I name sr-config.org (org-babel-load-file (expand-file-name \u0026#34;sr-config.org\u0026#34; user-emacs-directory)) ;; Loading secret config containing personal information (org-babel-load-file (expand-file-name \u0026#34;sr-secrets.org.gpg\u0026#34; user-emacs-directory)) (garbage-collect) TODO Using this configuration While using the Org file - you may need to set :tangle no in the headers for the code snippets that you do not need, and set the location of directories for org files, org agenda etc.\nA bunch these scripts are not tangled and kept for testing or reference purposes. The tangled config.el contains the actual configuration that is used.\n Method 1\n Clone Scimax Add the above snippet to user.el in the user directory. Update the file name and paths as required. Place this org file in the user directory. Run the provided script for installing the packages needed for Scimax. Once that is done, user.el will call this org file.  Method 2\nPick up snippets that you like from the config.el file, which is tangled from this org file, and only includes the snippets that I actually use.\n  TODO Overall Tasks and Areas of Improvement [0/5] Remove packages that are no longer used Switch to the use-package approach everywhere. Improve the documentation to make it more user friendly. Improve instructions to use this configuration Figure out how external packages can be installed.  Other literate Emacs configs These references were used for exploration and inspiration. Other resources and references are included with the code.\n Karl Voit Mathieu Marques Lee Hinman Sacha Chua Bernt Hansen\u0026rsquo;s very detailed Org-mode config  TODO Tangle org mode config on save  Note taken on [2019-02-14 Thu 13:14]  Need to add a condition of check: tangle if the file does not exist.  Source: https://thewanderingcoder.com/2015/02/literate-emacs-configuration/\nThis is a nice code snippet to automate the tangling on saving the config. This saves time while starting up Emacs\u0026hellip;\n(defun sr/tangle-on-save-emacs-config-org-file() (interactive) (if (string= buffer-file-name (file-truename \u0026#34;~/scimax/user/sr-config.org\u0026#34;)) (org-babel-tangle-file \u0026#34;~/scimax/user/sr-config.org\u0026#34; \u0026#34;~/scimax/user/sr-config.el\u0026#34;) ) ) (defun sr/tangle-if-file-absent () (interactive) (if nil (file-exists-p \u0026#34;~/scimax/user/sr-config.el\u0026#34;) (org-babel-tangle-file \u0026#34;~/scimax/user/sr-config.org\u0026#34; \u0026#34;~/scimax/user/sr-config.el\u0026#34;) ) ) ;; (add-hook \u0026#39;after-save-hook \u0026#39;sr/dotemacs-export) (add-hook \u0026#39;after-save-hook \u0026#39;sr/tangle-on-save-emacs-config-org-file) OS Level variables [0/0] Since I switch between a Linux machine and a Mac frequently, it is better to define variables that can be used to set other variables depending on the OS.\n;; Get current system\u0026#39;s name (defun insert-system-name() (interactive) \u0026#34;Get current system\u0026#39;s name\u0026#34; (insert (format \u0026#34;%s\u0026#34; system-name)) ) ;; Get current system type (defun insert-system-type() (interactive) \u0026#34;Get current system type\u0026#34; (insert (format \u0026#34;%s\u0026#34; system-type)) ) ;; Check if system is Darwin/Mac OS X (defun system-type-is-darwin () (interactive) \u0026#34;Return true if system is darwin-based (Mac OS X)\u0026#34; (string-equal system-type \u0026#34;darwin\u0026#34;) ) ;; Check if system is GNU/Linux (defun system-type-is-gnu () (interactive) \u0026#34;Return true if system is GNU/Linux-based\u0026#34; (string-equal system-type \u0026#34;gnu/linux\u0026#34;) ) (message \u0026#34;Completed OS Level variables load\u0026#34;) PDF Tools  Note taken on [2019-02-18 Mon 14:30]  Install epdfinfo via \u0026lsquo;brew install pdf-tools\u0026rsquo; and then install the pdf-tools elisp via the use-package below. To upgrade the epdfinfo server, use \u0026lsquo;brew upgrade pdf-tools\u0026rsquo; prior to upgrading to newest pdf-tools package using Emacs package system. If things get messed up, just do \u0026lsquo;brew uninstall pdf-tools\u0026rsquo;, wipe out the elpa pdf-tools package and reinstall both as at the start. source: https://emacs.stackexchange.com/questions/13314/install-pdf-tools-on-emacs-macosx  (use-package pdf-tools :ensure t :config (custom-set-variables \u0026#39;(pdf-tools-handle-upgrades nil)) ; Use brew upgrade pdf-tools instead in the mac (setq pdf-info-epdfinfo-program \u0026#34;/usr/local/bin/epdfinfo\u0026#34;) (pdf-tools-install) ) Better defaults I need to explore the changed made by this package. For now, it is loaded right in the beginning so that it does not overwrite other customisations down the line.\n(use-package better-defaults :ensure t ) (message \u0026#34;Loaded better-defaults package\u0026#34;) Crypto setup (setq epa-file-encrypt-to \u0026#39;(\u0026#34;shreyas@fastmail.com\u0026#34;)) (require \u0026#39;org-crypt) (add-to-list \u0026#39;org-modules \u0026#39;org-crypt) ; Encrypt all entries before saving (org-crypt-use-before-save-magic) (setq org-tags-exclude-from-inheritance (quote (\u0026#34;crypt\u0026#34;))) ; GPG key to use for encryption. nil for symmetric encryption (setq org-crypt-key nil) (setq org-crypt-disable-auto-save t) (setq org-crypt-tag-matcher \u0026#34;locked\u0026#34;) (message \u0026#34;Loaded crypto setup\u0026#34;) github token access Source: https://emacs.stackexchange.com/questions/40994/using-auth-source-with-magit-and-bitbucket\nFill the out the following details before executing the script. Machine can be found be executing \u0026lsquo;hostname\u0026rsquo; in shell.\ncat \u0026gt; ~/.gh.authinfo \u0026lt;\u0026lt; EOF machine shrysr@github.com password ABCD EOF M-x epa-encrypt-file and point towards the above file and choose your key. This will generate the .gpg file.\n(setq auth-sources \u0026#39;((:source \u0026#34;~/.my.authinfo.gpg\u0026#34;))) (setq magit-process-find-password-functions \u0026#39;(magit-process-password-auth-source)) Dired Source: https://github.com/angrybacon/dotemacs/blob/master/dotemacs.org\n(use-package dired :ensure nil :delight dired-mode \u0026#34;Dired\u0026#34; :preface (defun me/dired-directories-first () \u0026#34;Sort dired listings with directories first before adding marks.\u0026#34; (save-excursion (let (buffer-read-only) (forward-line 2) (sort-regexp-fields t \u0026#34;^.*$\u0026#34; \u0026#34;[ ]*.\u0026#34; (point) (point-max))) (set-buffer-modified-p nil))) ;:hook ;(dired-mode . dired-hide-details-mode) :config (advice-add \u0026#39;dired-readin :after #\u0026#39;me/dired-directories-first) (setq-default dired-auto-revert-buffer t dired-dwim-target t dired-hide-details-hide-symlink-targets nil dired-listing-switches \u0026#34;-alh\u0026#34; dired-ls-F-marks-symlinks nil dired-recursive-copies \u0026#39;always)) (use-package dired-x :ensure nil :preface (defun me/dired-revert-after-command (command \u0026amp;optional output error) (revert-buffer)) :config (advice-add \u0026#39;dired-smart-shell-command :after #\u0026#39;me/dired-revert-after-command)) (message \u0026#34;Loaded Dired customisation\u0026#34;) Emacs General config Remove trailing whitespace at the end of lines (add-hook \u0026#39;before-save-hook \u0026#39;delete-trailing-whitespace) Remove \u0026lsquo;^\u0026rsquo; at the start of ivy commands (setq ivy-initial-inputs-alist nil) Package installation Package list Though the use-package approach is a lot more elegant, I also like to have a list of all my installed packages. In any case, this is more in line with my earlier configurations. As things evolve, I will probably shift completely to the use-package method.\n(setq package-list \u0026#39;(diminish ztree org-gcal w3m org-trello org-web-tools auto-indent-mode ob-sql-mode dash org-super-agenda workgroups2 switch-window ess ess-R-data-view interleave deft org-bookmark-heading writeroom-mode evil evil-leader polymode poly-R helm-ag writegood-mode artbollocks-mode multiple-cursors ox-reveal better-defaults jedi jedi-core ag ein ein-mumamo ido-vertical-mode company-jedi conda spacemacs-theme elfeed-goodies helpful browse-kill-ring ivy-yasnippet speed-type clojure-mode cider helm-dash org-projectile bash-completion elmacro helm-org-rifle sx define-word)) Fetch and install missing packages ;;fetch the list of packages available (unless package-archive-contents (package-refresh-contents)) ;; install the missing packages (dolist (package package-list) (unless (package-installed-p package) (package-install package))) Switch-window configuration Source link: https://github.com/dimitri/switch-window\n(use-package switch-window :config ;; (require \u0026#39;switch-window) (global-set-key (kbd \u0026#34;C-x o\u0026#34;) \u0026#39;switch-window) (global-set-key (kbd \u0026#34;C-x 1\u0026#34;) \u0026#39;switch-window-then-maximize) (global-set-key (kbd \u0026#34;C-x 2\u0026#34;) \u0026#39;switch-window-then-split-below) (global-set-key (kbd \u0026#34;C-x 3\u0026#34;) \u0026#39;switch-window-then-split-right) (global-set-key (kbd \u0026#34;C-x 0\u0026#34;) \u0026#39;switch-window-then-delete) (global-set-key (kbd \u0026#34;C-x 4 d\u0026#34;) \u0026#39;switch-window-then-dired) (global-set-key (kbd \u0026#34;C-x 4 f\u0026#34;) \u0026#39;switch-window-then-find-file) (global-set-key (kbd \u0026#34;C-x 4 m\u0026#34;) \u0026#39;switch-window-then-compose-mail) (global-set-key (kbd \u0026#34;C-x 4 r\u0026#34;) \u0026#39;switch-window-then-find-file-read-only) (global-set-key (kbd \u0026#34;C-x 4 C-f\u0026#34;) \u0026#39;switch-window-then-find-file) (global-set-key (kbd \u0026#34;C-x 4 C-o\u0026#34;) \u0026#39;switch-window-then-display-buffer) (global-set-key (kbd \u0026#34;C-x 4 0\u0026#34;) \u0026#39;switch-window-then-kill-buffer) ;; selecting minibuffer (setq switch-window-minibuffer-shortcut ?z) ) TEST Activating windmove to facilitate Hydras Super would actually be a good option. However, this interferes with default configurations in MS Windows, especially while using virtualbox. Using Meta for now.\n(windmove-default-keybindings \u0026#39;meta) Create intermediate directories while saving files Source: https://superuser.com/questions/131538/can-i-create-directories-that-dont-exist-while-creating-a-new-file-in-emacs\n(defadvice find-file (before make-directory-maybe (filename \u0026amp;optional wildcards) activate) \u0026#34;Create parent directory if not exists while visiting file.\u0026#34; (unless (file-exists-p filename) (let ((dir (file-name-directory filename))) (unless (file-exists-p dir) (make-directory dir))))) Shortcuts and registers Registers (set-register ?n (cons \u0026#39;file \u0026#34;~/my_org/notes.org\u0026#34;)) (set-register ?l (cons \u0026#39;file \u0026#34;~/application_letters/letter.md\u0026#34;)) (set-register ?k (cons \u0026#39;file \u0026#34;~/application_letters/Cover_letter_Shreyas_R.pdf\u0026#34;)) (set-register ?p (cons \u0026#39;file \u0026#34;~/org_cv/CV_Shreyas_Ragavan.pdf\u0026#34;)) (set-register ?r (cons \u0026#39;file \u0026#34;~/org_cv/CV_Shreyas_Ragavan.org\u0026#34;)) (set-register ?t (cons \u0026#39;file \u0026#34;~/my_org/todo-global.org\u0026#34;)) (set-register ?i (cons \u0026#39;file \u0026#34;~/dotemacs/.emacs.d/new-init.org\u0026#34;)) (set-register ?j (cons \u0026#39;file \u0026#34;~/my_org/mrps_canjs.org\u0026#34;)) (set-register ?f (cons \u0026#39;file \u0026#34;~/scimax/user/sr-cust/\u0026#34;)) (set-register ?d (cons \u0026#39;file \u0026#34;~/my_org/datascience.org\u0026#34;)) (set-register ?m (cons \u0026#39;file \u0026#34;~/my_org/\u0026#34;)) (set-register ?g (cons \u0026#39;file \u0026#34;~/my_gits/\u0026#34;)) Google this (global-set-key (kbd \u0026#34;M-s g\u0026#34;) \u0026#39;google-this-mode-submap) ivy-yasnippet (global-set-key (kbd \u0026#34;M-s i\u0026#34;) \u0026#39;ivy-yasnippet) Mu4e related (global-set-key (kbd \u0026#34;M-s u\u0026#34;) \u0026#39;mu4e-update-mail-and-index) (global-set-key (kbd \u0026#34;M-s m\u0026#34;) \u0026#39;mu4e~headers-jump-to-maildir) (global-set-key (kbd \u0026#34;C-x m\u0026#34;) \u0026#39;mu4e-compose-new) Org related (global-set-key (kbd \u0026#34;C-x t\u0026#34;) \u0026#39;org-insert-todo-heading) (global-set-key (kbd \u0026#34;C-c d\u0026#34;) \u0026#39;org-time-stamp) (global-set-key (kbd \u0026#34;M-s s\u0026#34;) \u0026#39;org-save-all-org-buffers) (global-set-key (kbd \u0026#34;M-s j\u0026#34;) \u0026#39;org-journal-new-entry) Shortcuts for punching in and Out (global-set-key (kbd \u0026#34;C-\u0026lt;f9\u0026gt;\u0026#34;) \u0026#39;sr/punch-in) (global-set-key (kbd \u0026#34;M-\u0026lt;f9\u0026gt;\u0026#34;) \u0026#39;sr/punch-out) TODO Setting the super and hyper Key (if system-name-is-darwin (progn (setq mac-right-command-modifier \u0026#39;hyper) (setq mac-right-option-modifier \u0026#39;super) ) ) (if system-name-is-gnu (progn (setq right-command-) ) ) Shortcut for frog-jump-Buffer (global-set-key (kbd \u0026#34;M-s f\u0026#34;) \u0026#39;frog-jump-buffer) #+END_SRC\nfrog-jump-buffer yanking links in org format Source: sacha chua.\nEnables inserting a URL into an org document as \u0026lsquo;[][link]\u0026rsquo; by tapping F6 after copying the URL. This is useful to reduce clutter with long links, and even include links in headings.\n(defun my/yank-more () (interactive) (insert \u0026#34;[[\u0026#34;) (yank) (insert \u0026#34;][link]]\u0026#34;)) (global-set-key (kbd \u0026#34;\u0026lt;f6\u0026gt;\u0026#34;) \u0026#39;my/yank-more) Export setup (require \u0026#39;ox-org) (require \u0026#39;ox-word) (require \u0026#39;ox-md) (load \u0026#34;~/scimax/ox-ipynb/ox-ipynb.el\u0026#34;) Markdown config Setting pandoc as the markdown command for live previews. The default command is markdown, which could be installed as a separate package.\n(setq markdown-command \u0026#34;pandoc\u0026#34;) org-bookmark-heading For some reason, the default bookmark behavior in org mode is that the bookmark is not linked to the org-id. This means that if the heading is shifted somewhere, the bookmark becomes useless! The remedy seems to be using the package org-bookmark-Heading\n(use-package org-bookmark-heading :ensure t :config (require \u0026#39;org-bookmark-heading) ) TEST Export async  Note taken on [2019-02-14 Thu 16:03]  This requires a separate init file to be setup that enables Emacs to launch a separate process to export large files. It would be better as a vanilla emacs file.  (setq org-export-async-init-file (expand-file-name \u0026#34;async-export.el\u0026#34; user-emacs-directory) ) TEST Ob-async  Note taken on [2019-02-14 Thu 16:02]  This should enable evaluating code in org babel source blocks asynchronously. The header in the source block should have the async enabled.  (use-package ob-async :ensure t ) TEST Auto saving all org files by the hour  Note taken on [2019-07-05 Fri 11:49]  On the mac, this seems to be saving for each house since the time specified ? This behavior needs to be checked out.  This is adopted from Bernt Hansen\u0026rsquo;s configuration. Essentially, all the org buffers are saved 1 minute before the hour, every hour.\n(run-at-time \u0026#34;00:59\u0026#34; 3600 \u0026#39;org-save-all-org-buffers) TEST Marking I want a way to efficiently mark a location in a long script and jump around these locations (forward and backwards). The transient-mark-mode and the different mark-rings need to be leveraged to do accomplish this. First step is to set a mark using C-spc C-spc.\nAdopting the approach described at Mastering Emacs. This enables a single key for a mark to activate and then deactivate, thus creating a mark.\n(defun push-mark-no-activate () \u0026#34;Pushes `point\u0026#39;to `mark-ring\u0026#39;and does not activate the region Equivalent to \\\\[set-mark-command] when \\\\[transient-mark-mode] is disabled\u0026#34; (interactive) (push-mark (point) t nil) (message \u0026#34;Pushed mark to ring\u0026#34;)) (global-set-key (kbd \u0026#34;C-`\u0026#34;) \u0026#39;push-mark-no-activate) The tmm-menu command\u0026rsquo;s shortcut M-` is much better served by M-x counsel-tmm where search is possible.\n(defun jump-to-mark () \u0026#34;Jumps to the local mark, respecting the `mark-ring\u0026#39;order. This is the same as using \\\\[set-mark-command] with the prefix argument.\u0026#34; (interactive) (set-mark-command 1)) (global-set-key (kbd \u0026#34;M-`\u0026#34;) \u0026#39;jump-to-mark) TEST Semantic Mode  Semantic is a package that provides language-aware editing commands based on \u0026lsquo;source-code parsers\u0026rsquo;. When enabled, each file you visit is automatically parsed.\nhttps://tuhdo.github.io/helm-intro.html\n (semantic-mode 1) Completed loading message (message \u0026#34;Loaded Emacs general config\u0026#34;) TODO Crux - basic movement Source: https://jamiecollinson.com/blog/my-emacs-config/ Contains functions from Prelude. I should check this out in more detail.\nSet C-a to move to the first non-whitespace character on a line, and then to toggle between that and the beginning of the line.\n(use-package crux :ensure t :bind ((\u0026#34;C-a\u0026#34; . crux-move-beginning-of-line))) Swiper  Note taken on [2019-02-07 Thu 16:50]  I use swiper for a general search. However helm-swoop is awesome.  (global-set-key (kbd \u0026#34;C-s\u0026#34;) \u0026#39;swiper) (setq ivy-display-style \u0026#39;fancy) ;; advise swiper to recenter on exit (defun bjm-swiper-recenter (\u0026amp;rest args) \u0026#34;recenter display after swiper\u0026#34; (recenter) ) (advice-add \u0026#39;swiper :after #\u0026#39;bjm-swiper-recenter) (message \u0026#34;Loaded Swiper customisation\u0026#34;) Easier selection TODO Expand region  Note taken on [2019-02-07 Thu 09:27]  Explore how this works  (use-package expand-region :ensure t :bind (\u0026#34;C-=\u0026#34; . er/expand-region)) (message \u0026#34;Loaded easier selection\u0026#34;) git related TODO Git gutter  Note taken on [2019-02-07 Thu 09:30]  Started using this today. It is actually very convenient to quickly view the changes made in the document. There is a function to pop up the changes at that location. I need to learn more about using this tool effectively.  (use-package git-gutter :ensure t :config (global-git-gutter-mode \u0026#39;t) :diminish git-gutter-mode) magit settings (setq magit-revert-buffers \u0026#39;silent) TODO Time machine for git  Note taken on [2019-02-08 Fri 13:21]  Launched by M-x git-timemachine, this lets you navigate through the commit history with a single key press! This is especially awesome for tracking changes to a particular snippet of code. Note taken on [2019-02-07 Thu 09:30]  Need to evaluate this. The purpose is for stepping through the history of a file recorded in git. This should be very interesting.  (use-package git-timemachine :ensure t) Completed loading message (message \u0026#34;Loaded git related config\u0026#34;) Writeroom customisations The goal is to enable a customised zen writing mode, especially facilitating blog posts and other longer forms of writing. As of now, there are customisations for the width, and calling the art-bollocks mode when writeroom mode is enabled.\n(with-eval-after-load \u0026#39;writeroom-mode (define-key writeroom-mode-map (kbd \u0026#34;C-s-,\u0026#34;) #\u0026#39;writeroom-decrease-width) (define-key writeroom-mode-map (kbd \u0026#34;C-s-.\u0026#34;) #\u0026#39;writeroom-increase-width) (define-key writeroom-mode-map (kbd \u0026#34;C-s-=\u0026#34;) #\u0026#39;writeroom-adjust-width)) (advice-add \u0026#39;text-scale-adjust :after #\u0026#39;visual-fill-column-adjust) ;; loading artbollocks whenever the writeroom mode is called in particular. (autoload \u0026#39;artbollocks-mode \u0026#34;artbollocks-mode\u0026#34;) (add-hook \u0026#39;writeroom-mode-hook \u0026#39;artbollocks-mode) (message \u0026#34;Loaded writeroom customisations\u0026#34;) TODO ESS configuration [0/0]  Note taken on [2019-02-19 Tue 10:14]  Using the tabviewer application for Antergos.link Note taken on [2019-02-09 Sat 12:36]  Set this up with use-package and explore further customisations. As of now, I use yasnippet to insert commonly used operators like the assign and pipe operators.  Main configuration Note: I use the TAD application to view CSV files. It is a cross platform application that is a lot faster than launching a spreadsheet based program.\n(use-package ess :ensure t :config (require \u0026#39;ess) (setq ess-describe-at-point-method nil) (setq ess-switch-to-end-of-proc-buffer t) (setq ess-rutils-keys +1) (setq ess-eval-visibly \u0026#39;nil) (setq ess-use-flymake +1) (setq ess-use-company t) (setq ess-history-file \u0026#34;~/.Rhistory\u0026#34;) (setq ess-use-ido t) (setq ess-roxy-hide-show-p t) ;;(speedbar-add-supported-extension \u0026#34;.R\u0026#34;) (setq comint-scroll-to-bottom-on-input t) (setq comint-scroll-to-bottom-on-output t) (setq comint-move-point-for-output t) ) (require \u0026#39;ess-R-data-view) (require \u0026#39;ess-rutils) (use-package ess-view :ensure t :config (require \u0026#39;ess-view) (if (system-type-is-darwin) (setq ess-view--spreadsheet-program \u0026#34;/Applications/Tad.app/Contents/MacOS/Tad\u0026#34; ) ) (if (system-type-is-gnu) (setq ess-view--spreadsheet-program \u0026#34;tad\u0026#34; ) ) ) (message \u0026#34;Loaded ESS configuration\u0026#34;) ESS Buffer display Config Setting buffer display setting for ESS, similar to Rstudio. This is taken from the ESS Manual. This seems most convenient as of now.\n(setq display-buffer-alist `((\u0026#34;*R Dired\u0026#34; (display-buffer-reuse-window display-buffer-in-side-window) (side . right) (slot . -1) (window-width . 0.33) (reusable-frames . nil)) (\u0026#34;*R\u0026#34; (display-buffer-reuse-window display-buffer-at-bottom) (window-width . 0.35) (reusable-frames . nil)) (\u0026#34;*Help\u0026#34; (display-buffer-reuse-window display-buffer-in-side-window) (side . right) (slot . 1) (window-width . 0.33) (reusable-frames . nil)))) TEST Icicles  Note taken on [2019-02-28 Thu 16:01]  The default key bindings of icicles changes the org source block edit shortcut. However, the package appears very interesting so far, if not a bit slow to respond. Switching over to icicles will need some research for making sure none of the existing keybindings and workflows are crippled. This package cannot be installed via Melpa. The easiest method appears to be to download the files as a zip folder from the icicle git repository. The automatic install script draws files from the Emacs wiki, which at times may be down. As such icicles can be switched off by using M-x icy-mode.  (load \u0026#34;~/scimax/user/external_packages/icicles-install.el\u0026#34;) (setq icicle-download-dir \u0026#34;~/scimax/user/external_packages/icicle_packages/\u0026#34;) (add-to-list \u0026#39;load-path \u0026#34;~/scimax/user/external_packages/icicle_packages/\u0026#34;) (require \u0026#39;icicles) (icy-mode 1) TODO lintr  Note taken on [2019-02-11 Mon 07:21]  It appears there is no package called lintr. This needs further investigation.  This package is deemed necessary to enable flymake in ESS. Without it, there is significantly more lag while the suggestions / corrections are generated in ESS modes.\n(use-package lintr :ensure nil ) Multiple Cursors (use-package multiple-cursors :ensure t :config (global-set-key (kbd \u0026#34;C-S-c C-S-c\u0026#34;) \u0026#39;mc/edit-lines) (global-set-key (kbd \u0026#34;C-\u0026gt;\u0026#34;) \u0026#39;mc/mark-next-like-this) (global-set-key (kbd \u0026#34;C-\u0026lt;\u0026#34;) \u0026#39;mc/mark-previous-like-this) (global-set-key (kbd \u0026#34;C-c C-\u0026lt;\u0026#34;) \u0026#39;mc/mark-all-like-this) ) (message \u0026#34;Loaded MC\u0026#34;) ox-reveal - presentations (use-package ox-reveal :ensure ox-reveal :defer t :config (setq org-reveal-root \u0026#34;http://cdn.jsdelivr.net/reveal.js/3.0.0/\u0026#34;) (setq org-reveal-mathjax t) ) (use-package htmlize :ensure t) (message \u0026#34;Loaded ox-reveal cust\u0026#34;) Org mode related Default org directory and agenda file directory (setq org-directory \u0026#34;~/my_org/\u0026#34; org-agenda-files \u0026#39;(\u0026#34;~/my_org/\u0026#34;) ) Org-notes into log drawer I\u0026rsquo;ve been inserting org notes into the body of the text, since I do not make extensive use of the log book in the agenda and prefer active time stamped notes and the org-journal and org-projectile to take down \u0026lsquo;linked\u0026rsquo; log notes. However, I would like the notes to be inserted after any properties drawers.\n(setq org-log-state-notes-insert-after-drawers t) (setq org-log-redeadline \u0026#39;time) TODO Enabling org capture and org protocol  Note taken on [2019-02-07 Thu 08:55]  Need to actually get org-capture via external browser protocol working. Not sure if I need to require org-capture in scimax.  Source: http://www.diegoberrocal.com/blog/2015/08/19/org-protocol/\n(require \u0026#39;org-capture) (require \u0026#39;org-protocol) TODO Ensuring archive files are also in org mode  Note taken on [2019-02-07 Thu 08:31]  check whether the add-to-list function is sufficient.  (add-hook \u0026#39;find-file-hooks (lambda () (let ((file (buffer-file-name))) (when (and file (equal (file-name-directory file) \u0026#34;~/my_org/archive/\u0026#34;)) (org-mode))))) (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\\\.org_archive\\\\\u0026#39;\u0026#34; . org-mode)) Archiving mechanics Archive organised by Top level headings in the original file and with Tag preservation\n(defun my-org-inherited-no-file-tags () (let ((tags (org-entry-get nil \u0026#34;ALLTAGS\u0026#34; \u0026#39;selective)) (ltags (org-entry-get nil \u0026#34;TAGS\u0026#34;))) (mapc (lambda (tag) (setq tags (replace-regexp-in-string (concat tag \u0026#34;:\u0026#34;) \u0026#34;\u0026#34; tags))) (append org-file-tags (when ltags (split-string ltags \u0026#34;:\u0026#34; t)))) (if (string= \u0026#34;:\u0026#34; tags) nil tags))) (defadvice org-archive-subtree (around my-org-archive-subtree-low-level activate) (let ((tags (my-org-inherited-no-file-tags)) (org-archive-location (if (save-excursion (org-back-to-heading) (\u0026gt; (org-outline-level) 1)) (concat (car (split-string org-archive-location \u0026#34;::\u0026#34;)) \u0026#34;::* \u0026#34; (car (org-get-outline-path))) org-archive-location))) ad-do-it (with-current-buffer (find-file-noselect (org-extract-archive-file)) (save-excursion (while (org-up-heading-safe)) (org-set-tags-to tags))))) org-id Using the org-id for reference to headings ensures that even if the heading changes, the links will still work.\nIn addition, I would like an org id to be created every time the capture is used. This facilitates using packages like org-brain which rely extensively on org-id\u0026rsquo;s.\n(setq org-id-method (quote uuidgen)) (add-hook \u0026#39;org-capture-prepare-finalize-hook \u0026#39;org-id-get-create) TODO Setting custom keywords with fast access  Note taken on [2019-02-12 Tue 12:19]  This requires a complete reload of org to come in effect.  (setq org-todo-keywords \u0026#39;((sequence \u0026#34;TODO(t)\u0026#34; \u0026#34;NEXT(n)\u0026#34; \u0026#34;CANCEL(c)\u0026#34; \u0026#34;POSTPONED(p)\u0026#34; \u0026#34;|\u0026#34; \u0026#34;DONE(d)\u0026#34; \u0026#34;STABLE(s)\u0026#34;) (sequence \u0026#34;TEST(T)\u0026#34; \u0026#34;BUG(b)\u0026#34; \u0026#34;KNOWNCAUSE(k)\u0026#34; \u0026#34;|\u0026#34; \u0026#34;FIXED(f)\u0026#34;) (sequence \u0026#34;|\u0026#34; ))) Refiling settings  Note taken on [2019-07-06 Sat 13:56]  Helm org rifle is mapped to the refile command. See Helm section.  Refile target level for search (setq org-refile-targets \u0026#39;((nil :maxlevel . 4) (org-agenda-files :maxlevel . 4))) TODO General refile settings  Note taken on [2019-02-07 Thu 08:33]  Needs further review and optimisation  (setq org-refile-use-outline-path \u0026#39;file) (setq org-outline-path-complete-in-steps nil) (setq org-reverse-note-order t) (setq org-refile-allow-creating-parent-nodes \u0026#39;confirm) Also refer Refiling hydra Agenda mechanics Weekday starts on Monday (setq org-agenda-start-on-weekday 1) Display heading tags farther to the right (setq org-agenda-tags-column -150) TODO Agenda customisation  Note taken on [2019-02-07 Thu 08:26]  Need to clear up the search functions, enabling complete search in journal files. Archive and some external directories are included, since they are explictly in org mode.  (setq org-agenda-custom-commands \u0026#39;((\u0026#34;c\u0026#34; \u0026#34;Simple agenda view\u0026#34; ((tags \u0026#34;recurr\u0026#34; ((org-agenda-overriding-header \u0026#34;Recurring Tasks\u0026#34;))) (agenda \u0026#34;\u0026#34;) (todo \u0026#34;\u0026#34;))) (\u0026#34;o\u0026#34; agenda \u0026#34;Office mode\u0026#34; ((org-agenda-tag-filter-preset \u0026#39;(\u0026#34;-course\u0026#34; \u0026#34;-habit\u0026#34; \u0026#34;-someday\u0026#34; \u0026#34;-book\u0026#34; \u0026#34;-emacs\u0026#34;)))) (\u0026#34;qc\u0026#34; tags \u0026#34;+commandment\u0026#34;) (\u0026#34;e\u0026#34; tags \u0026#34;+org\u0026#34;) (\u0026#34;w\u0026#34; agenda \u0026#34;Today\u0026#34; ((org-agenda-tag-filter-preset \u0026#39;(\u0026#34;+work\u0026#34;)))) (\u0026#34;W\u0026#34; todo-tree \u0026#34;WAITING\u0026#34;) (\u0026#34;q\u0026#34; . \u0026#34;Custom queries\u0026#34;) ;; gives label to \u0026#34;q\u0026#34; (\u0026#34;d\u0026#34; . \u0026#34;ds related\u0026#34;)\t;; gives label to \u0026#34;d\u0026#34; (\u0026#34;ds\u0026#34; agenda \u0026#34;Datascience\u0026#34; ((org-agenda-tag-filter-preset \u0026#39;(\u0026#34;+datascience\u0026#34;)))) (\u0026#34;qw\u0026#34; agenda \u0026#34;MRPS\u0026#34; ((org-agenda-tag-filter-preset \u0026#39;(\u0026#34;+canjs\u0026#34;)))) (\u0026#34;qa\u0026#34; \u0026#34;Archive tags search\u0026#34; org-tags-view \u0026#34;\u0026#34; ((org-agenda-files (file-expand-wildcards \u0026#34;~/my_org/*.org*\u0026#34;)))) (\u0026#34;j\u0026#34; \u0026#34;Journal Search\u0026#34; search \u0026#34;\u0026#34; \u0026#39;\u0026#39;((org-agenda-text-search-extra-files (file-expand-wildcards \u0026#34;~/my_org/journal/\u0026#34;)))) (\u0026#34;S\u0026#34; search \u0026#34;\u0026#34; ((org-agenda-files \u0026#39;(\u0026#34;~/my_org/\u0026#34;)) (org-agenda-text-search-extra-files ))) ) ) Include gpg files in agenda generation Source: https://emacs.stackexchange.com/questions/36542/include-org-gpg-files-in-org-agenda\n;; (unless (string-match-p \u0026#34;\\\\.gpg\u0026#34; org-agenda-file-regexp) ;; (setq org-agenda-file-regexp ;; (replace-regexp-in-string \u0026#34;\\\\\\\\\\\\.org\u0026#34; \u0026#34;\\\\\\\\.org\\\\\\\\(\\\\\\\\.gpg\\\\\\\\)?\u0026#34; ;; org-agenda-file-regexp))) (setq org-agenda-file-regexp \u0026#34;\\\\`\\\\\\([^.].*\\\\.org\\\\\\|[0-9]\\\\\\{8\\\\\\}\\\\\\(\\\\.gpg\\\\\\)?\\\\\\)\\\\\u0026#39;\u0026#34;) Expanding search locations I initially included my journal location to the agenda search. However it is very slow compared to using grep/rgrep/ag. Therefore, the agenda full text search is now limited to the project directory and the org-brain directory. The snippet below enables searching recursively within folders.\n(setq org-agenda-text-search-extra-files \u0026#39;(agenda-archives)) (setq org-agenda-text-search-extra-files (apply \u0026#39;append (mapcar (lambda (directory) (directory-files-recursively directory org-agenda-file-regexp)) \u0026#39;(\u0026#34;~/my_projects/\u0026#34; \u0026#34;~/my_org/brain/\u0026#34;)))) TODO Adding org archive for text search. Optimise this :CREATED: \u0026lt;2019-02-07 Thu 08:29\u0026gt;\n(setq org-agenda-text-search-extra-files \u0026#39;(agenda-archives)) Enable default fuzzy search like in google (setq org-agenda-search-view-always-boolean t) Enable sticky agenda Experimenting with this setting.\n(setq org-agenda-sticky t) DONE org-habit  Note taken on [2019-02-12 Tue 13:20]  Adding a require has brought org-habit back on track. Note taken on [2019-02-07 Thu 09:50]  Appears the use-package config for org-habit is not correct and there is some issue in downloading it as a package.  I want to shift the org habit graph in the agenda further out right so as to leave enough room for the headings to be visible.\n(require \u0026#39;org-habit) (setq org-habit-graph-column 90) TODO Capture mechanics  Note taken on [2019-02-07 Thu 08:24]  need to clean this up.  Capture templates (setq org-capture-templates \u0026#39;((\u0026#34;t\u0026#34; \u0026#34;Task entry\u0026#34;) (\u0026#34;tt\u0026#34; \u0026#34;Todo - Fast\u0026#34; entry (file+headline \u0026#34;~/my_org/todo-global.org\u0026#34; \u0026#34;@Inbox\u0026#34;) \u0026#34;** TODO %?\u0026#34;) (\u0026#34;tb\u0026#34; \u0026#34;Todo -BGR\u0026#34; entry (file+headline \u0026#34;~/my_org/bgr.org\u0026#34; \u0026#34;#BGR #Inbox\u0026#34;) \u0026#34;** TODO %?\u0026#34;) (\u0026#34;te\u0026#34; \u0026#34;Todo - Emacs\u0026#34; entry (file+headline \u0026#34;~/my_org/todo-global.org\u0026#34; \u0026#34;@Emacs notes and tasks\u0026#34;) \u0026#34;** TODO %?\u0026#34;) (\u0026#34;td\u0026#34; \u0026#34;Datascience inbox\u0026#34; entry (file+headline \u0026#34;~/my_org/datascience.org\u0026#34; \u0026#34;@Datascience @Inbox\u0026#34;) \u0026#34;** TODO %?\u0026#34;) (\u0026#34;tm\u0026#34; \u0026#34;Mail Link Todo\u0026#34; entry (file+headline \u0026#34;~/my_org/todo-global.org\u0026#34; \u0026#34;@Inbox\u0026#34;) \u0026#34;** TODO Mail: %a \u0026#34;) (\u0026#34;l\u0026#34; \u0026#34;Link/Snippet\u0026#34; entry (file+headline \u0026#34;~/my_org/link_database.org\u0026#34; \u0026#34;.UL Unfiled Links\u0026#34;) \u0026#34;** %? %a \u0026#34;) (\u0026#34;e\u0026#34; \u0026#34;Protocol info\u0026#34; entry ;; \u0026#39;w\u0026#39; for \u0026#39;org-protocol\u0026#39; (file+headline \u0026#34;~/my_org/link_database.org\u0026#34; \u0026#34;.UL Unfiled Links\u0026#34;) \u0026#34;*** %a, \\n %:initial\u0026#34;) (\u0026#34;n\u0026#34; \u0026#34;Notes\u0026#34;) (\u0026#34;ne\u0026#34; \u0026#34;Emacs note\u0026#34; entry (file+headline \u0026#34;~/my_org/todo-global.org\u0026#34; \u0026#34;@Emacs notes and tasks\u0026#34;) \u0026#34;** %?\\n:PROPERTIES:\\n:CREATED: [%\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;]\\n:END:\u0026#34;) (\u0026#34;nn\u0026#34; \u0026#34;General note\u0026#34; entry (file+headline \u0026#34;~/my_org/notes.org\u0026#34; \u0026#34;@NOTES\u0026#34;) \u0026#34;** %?\\n:PROPERTIES:\\n:CREATED: [%\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;]\\n:END:\u0026#34;) (\u0026#34;nd\u0026#34; \u0026#34;Datascience note\u0026#34; entry (file+headline \u0026#34;~/my_org/datascience.org\u0026#34; \u0026#34;@Datascience @Notes\u0026#34;) \u0026#34;** %?\\n:PROPERTIES:\\n:CREATED: [%\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;]\\n:END:\u0026#34;) (\u0026#34;g\u0026#34; \u0026#34;BGR stuff\u0026#34;) (\u0026#34;gi\u0026#34; \u0026#34;Inventory project\u0026#34;) (\u0026#34;gil\u0026#34; \u0026#34;Daily log\u0026#34; entry (file+olp+datetree \u0026#34;~/my_org/bgr.org\u0026#34; \u0026#34;Inventory management Project\u0026#34;) \u0026#34;** %? %i\u0026#34;) (\u0026#34;C\u0026#34; \u0026#34;Commandment\u0026#34; entry (file+datetree \u0026#34;~/my_org/lifebook.org\u0026#34; \u0026#34;\u0026#34;) \u0026#34;** %? %i :commandment:\u0026#34;) (\u0026#34;J\u0026#34; \u0026#34;Job search\u0026#34; entry (file+headline \u0026#34;~/my_org/mrps_canjs.org\u0026#34; \u0026#34;MRPS #CANJS\u0026#34;) \u0026#34;** TODO %? %i \u0026#34;) (\u0026#34;w\u0026#34; \u0026#34;Website\u0026#34; plain (function org-website-clipper) \u0026#34;* %a %T\\n\u0026#34; :immediate-finish t) (\u0026#34;j\u0026#34; \u0026#34;Journal entry\u0026#34; entry (function org-journal-find-location) \u0026#34;* %(format-time-string org-journal-time-format) %?\u0026#34;) (\u0026#34;i\u0026#34; \u0026#34;Whole article capture\u0026#34; entry (file+headline \u0026#34;~/my_org/full_article_archive.org\u0026#34; \u0026#34;\u0026#34; :empty-lines 1) \u0026#34;** %a, %T\\n %:initial\u0026#34; :empty-lines 1) (\u0026#34;c\u0026#34; \u0026#34;Clocking capture\u0026#34;) (\u0026#34;ct\u0026#34; \u0026#34;Clock TODO\u0026#34; entry (clock) \u0026#34;** TODO %?\u0026#34;) (\u0026#34;cn\u0026#34; \u0026#34;Clock Note\u0026#34; entry (clock) \u0026#34;** %?\\n:PROPERTIES:\\n:CREATED: [%\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;]\\n:END:\u0026#34;) (\u0026#34;r\u0026#34; \u0026#34;Review note\u0026#34; entry (file+weektree \u0026#34;~/my_org/lifebook.org\u0026#34; \u0026#34;#Personal #Reviews\u0026#34;) \u0026#34;** %?\\n:PROPERTIES:\\n:CREATED: [%\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;]\\n:END:\u0026#34;) )) TEST Closing org-capture frame on abort  Note taken on [2019-03-13 Wed 07:35]  This basically ensures a clean exit in case of aborting a capture. Note taken on [2019-02-07 Thu 08:53]  Needs further review.  Source: http://stackoverflow.com/questions/23517372/hook-or-advice-when-aborting-org-capture-before-template-selection\n(defadvice org-capture (after make-full-window-frame activate) \u0026#34;Advise capture to be the only window when used as a popup\u0026#34; (if (equal \u0026#34;emacs-capture\u0026#34; (frame-parameter nil \u0026#39;name)) (delete-other-windows))) (defadvice org-capture-finalize (after delete-capture-frame activate) \u0026#34;Advise capture-finalize to close the frame\u0026#34; (if (equal \u0026#34;emacs-capture\u0026#34; (frame-parameter nil \u0026#39;name)))) TODO Controlling org-capture buffers  Note taken on [2019-03-13 Wed 08:01]  This interferes with org-journal\u0026rsquo;s capture format.  I dislike the way org-capture disrupts my current window, and shows me the capture buffer, and the target buffer as well. I would prefer a small pop up window, and then a revert back to the existing windows once the capture is completed or aborted. However this does not seem possible without modifying Org-mode\u0026rsquo;s source code. This is a workaround described at https://stackoverflow.com/questions/54192239/open-org-capture-buffer-in-specific-Window ,which partially resolves the issue by enabling just a single capture buffer.\n(defun my-org-capture-place-template-dont-delete-windows (oldfun args) (cl-letf (((symbol-function \u0026#39;delete-other-windows) \u0026#39;ignore)) (apply oldfun args))) (with-eval-after-load \u0026#34;org-capture\u0026#34; (advice-add \u0026#39;org-capture-place-template :around \u0026#39;my-org-capture-place-template-dont-delete-windows)) TODO version control and backup of files  Note taken on [2019-02-07 Thu 08:15]  Need to check out how this works and whether this is still necessary, since I am using Git.  (setq delete-old-versions -1) (setq version-control t) org-noter  Org-noter’s purpose is to let you create notes that are kept in sync when you scroll through the document, but that are external to it - the notes themselves live in an Org-mode file. As such, this leverages the power of Org-mode (the notes may have outlines, latex fragments, babel, etc…) while acting like notes that are made inside the document. Also, taking notes is very simple: just press i and annotate away!\nGonçalo Santos\n (use-package org-noter :ensure t :defer t :config (setq org-noter-set-auto-save-last-location t) ) TODO Persp-projectile Refer Howard\u0026rsquo;s config snippet to setup a test.\nTODO org-projectile  Note taken on [2019-02-07 Thu 08:42]  need to optimise further and convert to use-package style. Also need a way to capture Notes from projects, in addition to tasks.  Starting off with the basic configuration posted in org-projectile github repo.\n(use-package org-projectile :ensure t :bind ((\u0026#34;C-c n p\u0026#34; . org-projectile-project-todo-completing-read) (\u0026#34;C-c c\u0026#34; . org-capture)) :config (setq org-projectile-projects-file \u0026#34;~/my_org/project-tasks.org\u0026#34;) ;; (setq org-agenda-files (append org-agenda-files (org-projectile-todo-files))) ;; Not necessary as my task projects are a part of the main org folder (push (org-projectile-project-todo-entry) org-capture-templates) ) TODO org-gcal customisation TODO Property customisation TEST Optimise CREATED and PLANNED property tags  Note taken on [2019-02-07 Thu 09:10]  Needs further review and optimisation.  Using an active date tag on the heading itself makes the org document look ugly, and makes navigation difficult. This is better entered into a property drawer. Two properties should work well - CREATED (inactive date-time tag) and PLANNED (active date-time tag). This will enable me to filter based on property in the future and easily archive older or irrelevant tasks. When the task is shifted or postponed, only the PLANNED property is changed, leaving clear reference of the created date.\nThe above is implemented only for tasks with a TODO heading. For now, I want to test using Notes with an inactive date-time tag, which can be individually setup via the capture templates. The attempt is to have a clear separation between tasks and notes.\nThis is a modified version of the snippet at https://emacs.stackexchange.com/questions/35751/how-to-add-a-created-field-to-any-todo-task\n(defun sr/log-todo-creation-date (\u0026amp;rest ignore) \u0026#34;Log TODO creation time in the property drawer under the key \u0026#39;CREATED\u0026#39;.\u0026#34; (when (and (org-get-todo-state) (not (org-entry-get nil \u0026#34;CREATED\u0026#34;))) (org-entry-put nil \u0026#34;CREATED\u0026#34; (format-time-string \u0026#34;[%Y-%m-%d %a]\u0026#34;)) (org-entry-put nil \u0026#34;PLANNED\u0026#34; (format-time-string (cdr org-time-stamp-formats))) )) (advice-add \u0026#39;org-insert-todo-heading :after #\u0026#39;sr/log-todo-creation-date) (advice-add \u0026#39;org-insert-todo-heading-respect-content :after #\u0026#39;sr/log-todo-creation-date) (advice-add \u0026#39;org-insert-todo-subheading :after #\u0026#39;sr/log-todo-creation-date) (advice-add \u0026#39;org-capture :after #\u0026#39;sr/log-todo-creation-date) (advice-add \u0026#39;org-projectile-project-todo-completing-read :after #\u0026#39;sr/log-todo-creation-date) ;; (require \u0026#39;org-expiry) ;; ;; Configure it a bit to my liking ;; (setq ;; org-expiry-created-property-name \u0026#34;CREATED\u0026#34; ; Name of property when an item is created ;; org-expiry-inactive-timestamps nil ; Don\u0026#39;t have everything in the agenda view ;; ) ;; (defun mrb/insert-created-timestamp() ;; \u0026#34;Insert a CREATED property using org-expiry.el for TODO entries\u0026#34; ;; (org-expiry-insert-created) ;; (org-back-to-heading) ;; (org-end-of-line) ;; (insert \u0026#34; \u0026#34;) ;; ) ;; ;; Whenever a TODO entry is created, I want a timestamp ;; ;; Advice org-insert-todo-heading to insert a created timestamp using org-expiry ;; (defadvice org-insert-todo-heading (after mrb/created-timestamp-advice activate) ;; \u0026#34;Insert a CREATED property using org-expiry.el for TODO entries\u0026#34; ;; (mrb/insert-created-timestamp) ;; ) ;; ;; Make it active ;; (ad-activate \u0026#39;org-insert-todo-heading) ;; (require \u0026#39;org-capture) ;; (defadvice org-capture (after mrb/created-timestamp-advice activate) ;; \u0026#34;Insert a CREATED property using org-expiry.el for TODO entries\u0026#34; ;; ; Test if the captured entry is a TODO, if so insert the created ;; ; timestamp property, otherwise ignore ;; (mrb/insert-created-timestamp)) ;; ;; (when (member (org-get-todo-state) org-todo-keywords-1) ;; ;; (mrb/insert-created-timestamp))) ;; (ad-activate \u0026#39;org-capture) Enabling adding tags in the capture window ;; Add feature to allow easy adding of tags in a capture window (defun mrb/add-tags-in-capture() (interactive) \u0026#34;Insert tags in a capture window without losing the point\u0026#34; (save-excursion (org-back-to-heading) (org-set-tags))) ;; Bind this to a reasonable key (define-key org-capture-mode-map \u0026#34;\\C-c\\C-t\u0026#34; \u0026#39;mrb/add-tags-in-capture) TODO org web clipper  Note taken on [2019-02-07 Thu 09:11]  This works fine now. However, it would be nice to find a way to strip the headers and menu columns and other unnecessary information before capture.  Source: http://www.bobnewell.net/publish/35years/webclipper.html\n;; org-eww and org-w3m should be in your org distribution, but see ;; note below on patch level of org-eww. (require \u0026#39;org-eww) (require \u0026#39;org-w3m) (defvar org-website-page-archive-file \u0026#34;~/my_org/full_article_archive.org\u0026#34;) (defun org-website-clipper () \u0026#34;When capturing a website page, go to the right place in capture file, but do sneaky things. Because it\u0026#39;s a w3m or eww page, we go ahead and insert the fixed-up page content, as I don\u0026#39;t see a good way to do that from an org-capture template alone. Requires Emacs 25 and the 2017-02-12 or later patched version of org-eww.el.\u0026#34; (interactive) ;; Check for acceptable major mode (w3m or eww) and set up a couple of ;; browser specific values. Error if unknown mode. (cond ((eq major-mode \u0026#39;w3m-mode) (org-w3m-copy-for-org-mode)) ((eq major-mode \u0026#39;eww-mode) (org-eww-copy-for-org-mode)) (t (error \u0026#34;Not valid -- must be in w3m or eww mode\u0026#34;))) ;; Check if we have a full path to the archive file. ;; Create any missing directories. (unless (file-exists-p org-website-page-archive-file) (let ((dir (file-name-directory org-website-page-archive-file))) (unless (file-exists-p dir) (make-directory dir)))) ;; Open the archive file and yank in the content. ;; Headers are fixed up later by org-capture. (find-file org-website-page-archive-file) (goto-char (point-max)) ;; Leave a blank line for org-capture to fill in ;; with a timestamp, URL, etc. (insert \u0026#34;\\n\\n\u0026#34;) ;; Insert the web content but keep our place. (save-excursion (yank)) ;; Don\u0026#39;t keep the page info on the kill ring. ;; Also fix the yank pointer. (setq kill-ring (cdr kill-ring)) (setq kill-ring-yank-pointer kill-ring) ;; Final repositioning. (forward-line -1) ) Org-babel Loading language base (org-babel-do-load-languages \u0026#39;org-babel-load-languages \u0026#39;((clojure . t) (scheme . t) (sqlite . t) (R . t) ;(jupyter . t) ) ) Clojure and cider (require \u0026#39;cider) (setq org-babel-clojure-backend \u0026#39;cider) TODO Org-trello Clock Customisation Continuous clocking + punch in/out approach This approach and code snippets are adapted (and shamelessly borrowed) from Bernt Hansen\u0026rsquo;s approach. While Bernt follows a complex approach of clocking into parent tasks - my current workflow favors clocking in directly to set clocking headlines within projects, which are placed in my org-projectile todo task file.\nI have a default continuous clock after punching in (defined by org-id) which will cater to general re-organisation, including capturing notes, refiling , email etc. Other tasks or even mini projects can be directly clocked into when required. These mini-projets are often just located within my org-agenda files and not as a separate git repositoy. Every time I am on my computer, whether on Emacs or not, I would like the automatic clock to capture time, unless it is being clocked to a specific project.\n Defining default Task\n(defvar sr/organization-task-id \u0026#34;a8712a47-a648-477f-bdbf-d6004a0cc70b\u0026#34;) (defun sr/clock-in-organization-task-as-default () (interactive) (org-with-point-at (org-id-find sr/organization-task-id \u0026#39;marker) (org-clock-in \u0026#39;(16)))) Punch in\nBernt Hansen shares that he has a default punch in and punch out task that keeps the clock on all day. I think this will work for me as well. Other than work and projects, most of the time I am tinkering with Emacs, or writing a journal note or trying to re-organise my stuff. By using a punch in and out, I can track how much time I am engaged with a computer, other than specific projects.\n(defun sr/punch-in (arg) (interactive \u0026#34;p\u0026#34;) (setq sr/keep-clock-running t) (sr/clock-in-organization-task-as-default)) Punch Out\n(defun sr/punch-out () (interactive) (setq sr/keep-clock-running nil) (when (org-clock-is-active) (org-clock-out)) ) Advising clock Out\n(defun sr/clock-out-maybe () (when (and sr/keep-clock-running (not org-clock-clocking-in) (marker-buffer org-clock-default-task) (not org-clock-resolving-clocks-due-to-idleness)) (sr/clock-in-organization-task-as-default))) (add-hook \u0026#39;org-clock-out-hook \u0026#39;sr/clock-out-maybe \u0026#39;append)  TEST org-mru-clock  Note taken on [2019-03-14 Thu 10:16]  Issue is with the org-mru-select-recent-task command - it doesn\u0026rsquo;t jump to the specified task and always pesudo messes up the format of the headings.  This is a handy package to quickly select past tasks which have been clocked in.\n(use-package org-mru-clock :ensure t :bind ((\u0026#34;M-s 1\u0026#34; . org-mru-clock-in) (\u0026#34;C-c C-x C-j\u0026#34; . org-mru-clock-select-recent-task)) :init (setq org-mru-clock-how-many 100 org-mru-clock-completing-read #\u0026#39;ivy-completing-read)) Do not log or consider 0 Clocks (setq org-clock-out-remove-zero-time-clocks t) set idle timer for clocked task ;; setting idle timer to 15 minutes (setq org-clock-idle-time 15) Show clocked task history and enable re-clocking Source: link\nThis should enable me to quickly clock back into specific tasks.\n;; Show lot of clocking history so it\u0026#39;s easy to pick items off the `C-c I` list (setq org-clock-history-length 23) (defun eos/org-clock-in () (interactive) (org-clock-in \u0026#39;(4))) (global-set-key (kbd \u0026#34;C-c I\u0026#34;) #\u0026#39;eos/org-clock-in) (global-set-key (kbd \u0026#34;C-c O\u0026#34;) #\u0026#39;org-clock-out) Org-Brain [1\u0026frasl;2]  org-brain implements a variant of concept mapping in Emacs, using org-mode.\nYou can think of org-brain as a combination of a wiki and a mind map, where each wiki page / mind map node is an org-mode file which resides in your org-brain-path, or a headline with an ID property in one of those files. These are called entries. Entries can be linked together, and you can then view the network of links as a mind map, using M-x org-brain-visualize\norg-brain on github\n STABLE Basic setup along with org-id Since org-brain requires the org id for a heading to be recognized and displayed, it is convenient to have capture and refile mechanisms that create the org-id if the heading does not have it.\nFurther streamlining is necessary as such.\n(use-package org-brain :ensure t :init (setq org-brain-path \u0026#34;~/my_org/brain/\u0026#34;) ;; ;; For Evil users ;; (with-eval-after-load \u0026#39;evil ;; (evil-set-initial-state \u0026#39;org-brain-visualize-mode \u0026#39;emacs)) :config (setq org-id-track-globally t) (setq org-id-locations-file \u0026#34;~/my_org/emacs_meta/.org-id-locations\u0026#34;) (push \u0026#39;(\u0026#34;b\u0026#34; \u0026#34;Brain\u0026#34; plain (function org-brain-goto-end) \u0026#34;* %i%?\\n:PROPERTIES:\\n:CREATED: [%\u0026lt;%Y-%m-%d %a %H:%M\u0026gt;]\\n:END:\u0026#34; :empty-lines 1) org-capture-templates) (setq org-brain-visualize-default-choices \u0026#39;all) (setq org-brain-title-max-length 12) (add-hook \u0026#39;org-brain-refile \u0026#39;org-id-get-create) (global-set-key (kbd \u0026#34;M-s v\u0026#34;) #\u0026#39;org-brain-visualize) ) Org journal Base config (use-package org-journal :ensure t :defer t :custom (org-journal-dir \u0026#34;~/my_org/journal/\u0026#34;) (org-journal-file-format \u0026#34;%Y%m%d\u0026#34;) (org-journal-enable-agenda-integration t) ) setting org-capture template for Journal (defun org-journal-find-location () ;; Open today\u0026#39;s journal, but specify a non-nil prefix argument in order to ;; inhibit inserting the heading; org-capture will insert the heading. (org-journal-new-entry t) ;; Position point on the journal\u0026#39;s top-level heading so that org-capture ;; will add the new entry as a child entry. (goto-char (point-min))) TODO Figure out easy encryption approach for org journal TEST Org sticky Header [0/1] Explore further options : example full path or customised path to be shown   This package displays in the header-line the Org heading for the node that’s at the top of the window. This way, if the heading for the text at the top of the window is beyond the top of the window, you don’t forget which heading the text belongs to. The display can be customized to show just the heading, the full outline path, or the full outline path in reverse.\norg-sticky-header\n This is especially useful for free form longer Documentation.\n(use-package org-sticky-header :ensure t :config (org-sticky-header-mode) ) TEST Org wild Notifier  Note taken on [2019-03-28 Thu 13:48]  This seems to be able to do exactly what I am looking for. However there are unexplained errors while starting up the package.  (use-package org-wild-notifier :ensure t :custom (require \u0026#39;org-wild-notifier) (org-wild-notifier-mode) ) TEST Org to RST Exporter It is useful to be able to export to the RST format to develop documentation for projects and host with the sphinx or readthedocs platform.\nThis platform is actually pleasant to browse through documentation and has good search facilities as well.\n(use-package ox-rst :ensure t :defer t :config (require \u0026#39;ox-rst) ) TEST Org to Slack exporter This should prove handy as I write almost all my responses within Org mode and copy this into Slack.\n(use-package ox-slack :ensure t :defer t :config (require \u0026#39;ox-slack) ) TEST ox-pandoc (use-package ox-pandoc :ensure t :defer t :config (require \u0026#39;ox-pandoc) ) TEST Projectile behavior (setq projectile-sort-order \u0026#39;recently-active) ;; Change cache file location (setq projectile-cache-file \u0026#34;~/my_org/emacs_meta/.projectile-cache\u0026#34;) TEST Treemacs Setup (use-package treemacs :ensure t :defer t :init (with-eval-after-load \u0026#39;winum (define-key winum-keymap (kbd \u0026#34;M-0\u0026#34;) #\u0026#39;treemacs-select-window)) :config (progn (setq treemacs-collapse-dirs (if (executable-find \u0026#34;python3\u0026#34;) 3 0) treemacs-deferred-git-apply-delay 0.5 treemacs-display-in-side-window t treemacs-eldoc-display t treemacs-file-event-delay 5000 treemacs-file-follow-delay 0.2 treemacs-follow-after-init t treemacs-git-command-pipe \u0026#34;\u0026#34; treemacs-goto-tag-strategy \u0026#39;refetch-index treemacs-indentation 2 treemacs-indentation-string \u0026#34; \u0026#34; treemacs-is-never-other-window nil treemacs-max-git-entries 5000 ttt treemacs-no-png-images nil treemacs-no-delete-other-windows t treemacs-project-follow-cleanup nil treemacs-persist-file \u0026#34;~/my_org/emacs_meta/.treemacs-persist\u0026#34; treemacs-recenter-distance 0.1 treemacs-recenter-after-file-follow nil treemacs-recenter-after-tag-follow nil treemacs-recenter-after-project-jump \u0026#39;always treemacs-recenter-after-project-expand \u0026#39;on-distance treemacs-show-cursor nil treemacs-show-hidden-files t treemacs-silent-filewatch nil treemacs-silent-refresh nil treemacs-sorting \u0026#39;alphabetic-desc treemacs-space-between-root-nodes t treemacs-tag-follow-cleanup t treemacs-tag-follow-delay 1.5 treemacs-width 35) ;; The default width and height of the icons is 22 pixels. If you are ;; using a Hi-DPI display, uncomment this to double the icon size. ;;(treemacs-resize-icons 44) (treemacs-follow-mode t) (treemacs-filewatch-mode t) (treemacs-fringe-indicator-mode t) (pcase (cons (not (null (executable-find \u0026#34;git\u0026#34;))) (not (null (executable-find \u0026#34;python3\u0026#34;)))) (`(t . t) (treemacs-git-mode \u0026#39;deferred)) (`(t . _) (treemacs-git-mode \u0026#39;simple)))) :bind (:map global-map (\u0026#34;M-0\u0026#34; . treemacs-select-window) (\u0026#34;M-s t t\u0026#34; . treemacs) (\u0026#34;M-s t w\u0026#34; . treemacs-switch-workspace) ;; (\u0026#34;C-x t 1\u0026#34; . treemacs-delete-other-windows) ;; (\u0026#34;C-x t t\u0026#34; . treemacs) ;; (\u0026#34;C-x t B\u0026#34; . treemacs-bookmark) ;; (\u0026#34;C-x t C-t\u0026#34; . treemacs-find-file) ;; (\u0026#34;C-x t M-t\u0026#34; . treemacs-find-tag) ) );; (use-package treemacs-evil ;; :after treemacs evil ;; :ensure t) (use-package treemacs-projectile :after treemacs projectile :ensure t) (use-package treemacs-icons-dired :after treemacs dired :ensure t :config (treemacs-icons-dired-mode)) (use-package treemacs-magit :after treemacs magit :ensure t) TEST Sauron (use-package sauron :ensure t :config (require \u0026#39;sauron) (setq sauron-modules \u0026#39;(sauron-org sauron-notifications)) ) Deft  Deft is an Emacs mode for quickly browsing, filtering, and editing directories of plain text notes, inspired by Notational Velocity. It was designed for increased productivity when writing and taking notes by making it fast and simple to find the right file at the right time and by automating many of the usual tasks such as creating new files and saving files.\nDeft project\n (use-package deft :bind (\u0026#34;\u0026lt;f8\u0026gt; d\u0026#34; . deft) :commands (deft) :config (setq deft-directory \u0026#34;~/my_org/brain/\u0026#34; deft-extensions \u0026#39;(\u0026#34;md\u0026#34; \u0026#34;org\u0026#34; \u0026#34;txt\u0026#34;) deft-recursive t )) Helm TEST helm-ext  Note taken on [2019-04-29 Mon 08:01]  Disabling excecution for the time being.   Extensions to helm, which I find useful but are unlikely to be accepted in the upstream. A collection of dirty hacks for helm!\nhttps://github.com/cute-jumper/helm-ext\n (use-package helm-ext :ensure t :config (helm-ext-ff-enable-skipping-dots t) ;; Testing the auto path expansion ;;(helm-ff-ext-enable-auto-path-expansion t) ) Enabling Helm mode and activation for basic functions  Note taken on [2019-07-05 Fri 11:55]  Adding helm-for-files as this is not being autoloaded for enabling the hotspot feature in Scimax. Note taken on [2019-03-06 Wed 17:26]  I tried using Ivy for a period. However, Helm\u0026rsquo;s interface is simply a lot more pleasing and there are actually several additional actions that can be performed via helm itself. Note taken on [2019-03-04 Mon 15:48]  Though I preferred Helm initially for several commands - I realised that scimax has several useful customisations for the ivy and counsel packages. Overall ivy is also lighter than helm and therefore these customisations are being discarded for now.  I prefer using Helm for specific functions like M-x, find files and bookmarks and switching buffers.\n(global-set-key (kbd \u0026#34;M-x\u0026#34;) \u0026#39;helm-M-x) ;; Enable fuzzy match for helm-M-x (setq helm-M-x-fuzzy-match t) (global-set-key (kbd \u0026#34;C-x C-f\u0026#34;) #\u0026#39;helm-find-files) (global-set-key (kbd \u0026#34;C-x b\u0026#34;) #\u0026#39;helm-mini) (require \u0026#39;helm-config) (require \u0026#39;helm-for-files) (helm-mode 1) Bookmarks with Helm The default save location in the .emacs folder is not very convenient. I would rather store this with my org files since I commit them Everyday.\n(setq bookmark-default-file \u0026#34;~/my_org/emacs_meta/bookmarks\u0026#34;) The default bookmarks list C-x r l can be accessed using helm-bookmarks. The location of the file would be a nice addition. Technically, helm-filtered-bookmarks has almost the same functionality as the list in terms of being able to fuzzy-match a bookmark.\n(global-set-key (kbd \u0026#34;C-x r b\u0026#34;) #\u0026#39;helm-filtered-bookmarks) (global-set-key (kbd \u0026#34;C-x r l\u0026#34;) #\u0026#39;helm-bookmarks) (setq helm-bookmark-show-location t) STABLE Setting sources for helm  Note taken on [2019-07-04 Thu 08:08]  Interim issue with bookmarks file becoming corrupted due to a git conflict. The sources work as expected, with helm mini as well as hotspots. Note taken on [2019-04-29 Mon 07:43]  After a package update, setting the sources explicitly is causing issues with helm-mini and with scimax hotspots. Note taken on [2019-03-04 Mon 15:49]  The scimax hotspots can be customised with an improved function that only requires commands locations to be separately defined. This resolved the helm-recentf problem. Note taken on [2019-02-12 Tue 14:55]  This is still causing issues: the recentf list has to be cleared via helm-mini first. Note taken on [2019-02-07 Thu 16:28]  This was needed as it seems helm was not sourcing from recentf file lists. With this source list defined, it provides options to choose from recent files, bookmarks, open buffers.  As an example: setting these sources enables my bookmarks to be available along with my buffers, enabling a jump to either.\n(setq helm-mini-default-sources \u0026#39;(helm-source-buffers-list helm-source-recentf helm-source-bookmarks helm-source-bookmark-set helm-source-buffer-not-found)) (setq helm-buffers-list-default-sources \u0026#39;(helm-source-buffers-list helm-source-recentf helm-source-bookmarks helm-source-bookmark-set helm-source-buffer-not-found)) helm-semantic This needs Semantic Mode enabled, and is a really cool function that enables jumping around variables and functions in a script file with fuzzy matching !\n(setq helm-semantic-fuzzy-match t helm-imenu-fuzzy-match t) TODO Persistent follow mode for Helm  Note taken on [2019-02-07 Thu 07:46]  Need to find exactly what this does  (custom-set-variables \u0026#39;(helm-follow-mode-persistent t)) helm-ag and helm-org-rifle, with refiling set to helm-org-rifle (require \u0026#39;helm-ag) (require \u0026#39;helm-org-rifle) (global-set-key (kbd \u0026#34;C-c C-w\u0026#34;) #\u0026#39;helm-org-rifle--refile) helm-swoop  Note taken on [2019-02-07 Thu 16:53]  This is an awesome find. Helm swoop changes the search pattern depending on the location of the cursor. Therefore, while placed on an org headline, calling helm-swoop will preset the search pattern to have headings. The same is true for source code blocks! Fantastic.  Source: https://writequit.org/org/#orgheadline92\n(use-package helm-swoop :ensure t :bind ((\u0026#34;M-i\u0026#34; . helm-swoop) (\u0026#34;M-I\u0026#34; . helm-swoop-back-to-last-point) (\u0026#34;C-c M-i\u0026#34; . helm-multi-swoop)) :config ;; When doing isearch, hand the word over to helm-swoop (define-key isearch-mode-map (kbd \u0026#34;M-i\u0026#34;) \u0026#39;helm-swoop-from-isearch) ;; From helm-swoop to helm-multi-swoop-all (define-key helm-swoop-map (kbd \u0026#34;M-i\u0026#34;) \u0026#39;helm-multi-swoop-all-from-helm-swoop) ;; Save buffer when helm-multi-swoop-edit complete (setq helm-multi-swoop-edit-save t ;; If this value is t, split window inside the current window helm-swoop-split-with-multiple-windows t ;; Split direcion. \u0026#39;split-window-vertically or \u0026#39;split-window-horizontally helm-swoop-split-direction \u0026#39;split-window-vertically ;; If nil, you can slightly boost invoke speed in exchange for text color helm-swoop-speed-or-color nil)) Helm Loading completed (message \u0026#34;Loaded Helm customisations\u0026#34;) Spell Checking Flycheck  Note taken on [2019-02-09 Sat 11:51]  disabling flycheck for the moment and enabling flymake  Source: https://writequit.org/org/\nBasic config\n(use-package flycheck :defer 5 :bind ((\u0026#34;M-g M-n\u0026#34; . flycheck-next-error) (\u0026#34;M-g M-p\u0026#34; . flycheck-previous-error) (\u0026#34;M-g M-=\u0026#34; . flycheck-list-errors)) :init (global-flycheck-mode) :diminish flycheck-mode :config (progn (setq-default flycheck-disabled-checkers \u0026#39;(emacs-lisp-checkdoc json-jsonlint json-python-json ess iess)) (use-package flycheck-pos-tip :init (flycheck-pos-tip-mode)) (use-package helm-flycheck :init (define-key flycheck-mode-map (kbd \u0026#34;C-c ! h\u0026#34;) \u0026#39;helm-flycheck)) (use-package flycheck-haskell :init (add-hook \u0026#39;flycheck-mode-hook #\u0026#39;flycheck-haskell-setup)))) Enabling Flyspell Reference: https://alhassy.github.io/init/\nOrg mode is derived from text mode, therefore it is sufficient to activate for text mode.\n(use-package flyspell :hook ( (prog-mode . flyspell-prog-mode) (text-mode . flyspell-mode)) ) Replacing flycheck with flymake This is especially for python modules at the moment.\n(when (require \u0026#39;flycheck nil t) (setq elpy-modules (delq \u0026#39;elpy-module-flymake elpy-modules)) (add-hook \u0026#39;elpy-mode-hook \u0026#39;flycheck-mode)) TEST Switching to aspell on the mac Facing trouble enabling flyspell in the mac. This seems to be a solution, as outlined in this SO discussion.\n(if (system-type-is-darwin) (setq ispell-program-name \u0026#34;/opt/local/bin/aspell\u0026#34;) ) Scheme setup  References  http://praveen.kumar.in/2011/03/06/gnu-emacs-and-mit-scheme-on-mac-os-x/   (setq scheme-program-name \u0026#34;/Applications/MIT-GNU-Scheme.app/Contents/Resources/mit-scheme\u0026#34;) (require \u0026#39;xscheme) (message \u0026#34;Loaded scheme setup\u0026#34;) Hydras and some custom functions Refiling Adapted from https://emacs.stackexchange.com/questions/8045/org-refile-to-a-known-fixed-location\nsource: https://gist.github.com/mm--/60e0790bcbf8447160cc87a66dc949ab\nAlso see\n(defun my/refile (file headline \u0026amp;optional arg) \u0026#34;Refile to a specific location. With a \u0026#39;C-u\u0026#39; ARG argument, we jump to that location (see `org-refile\u0026#39;). Use `org-agenda-refile\u0026#39;in `org-agenda\u0026#39;mode.\u0026#34; (let* ((pos (with-current-buffer (or (get-buffer file) ;Is the file open in a buffer already? (find-file-noselect file)) ;Otherwise, try to find the file by name (Note, default-directory matters here if it isn\u0026#39;t absolute) (or (org-find-exact-headline-in-buffer headline) (error \u0026#34;Can\u0026#39;t find headline `%s\u0026#39;\u0026#34; headline)))) (filepath (buffer-file-name (marker-buffer pos))) ;If we\u0026#39;re given a relative name, find absolute path (rfloc (list headline filepath nil pos))) (if (and (eq major-mode \u0026#39;org-agenda-mode) (not (and arg (listp arg)))) ;Don\u0026#39;t use org-agenda-refile if we\u0026#39;re just jumping (org-agenda-refile nil rfloc) (org-refile arg nil rfloc)))) (defun josh/refile (file headline \u0026amp;optional arg) \u0026#34;Refile to HEADLINE in FILE. Clean up org-capture if it\u0026#39;s activated. With a `C-u` ARG, just jump to the headline.\u0026#34; (interactive \u0026#34;P\u0026#34;) (let ((is-capturing (and (boundp \u0026#39;org-capture-mode) org-capture-mode))) (cond ((and arg (listp arg))\t;Are we jumping? (my/refile file headline arg)) ;; Are we in org-capture-mode? (is-capturing ;Minor mode variable that\u0026#39;s defined when capturing (josh/org-capture-refile-but-with-args file headline arg)) (t (my/refile file headline arg))) (when (or arg is-capturing) (setq hydra-deactivate t)))) (defun josh/org-capture-refile-but-with-args (file headline \u0026amp;optional arg) \u0026#34;Copied from `org-capture-refile\u0026#39;since it doesn\u0026#39;t allow passing arguments. This does.\u0026#34; (unless (eq (org-capture-get :type \u0026#39;local) \u0026#39;entry) (error \u0026#34;Refiling from a capture buffer makes only sense for `entry\u0026#39;-type templates\u0026#34;)) (let ((pos (point)) (base (buffer-base-buffer (current-buffer))) (org-capture-is-refiling t) (kill-buffer (org-capture-get :kill-buffer \u0026#39;local))) (org-capture-put :kill-buffer nil) (org-capture-finalize) (save-window-excursion (with-current-buffer (or base (current-buffer)) (org-with-wide-buffer (goto-char pos) (my/refile file headline arg)))) (when kill-buffer (kill-buffer base)))) (defmacro josh/make-org-refile-hydra (hydraname file keyandheadline) \u0026#34;Make a hydra named HYDRANAME with refile targets to FILE. KEYANDHEADLINE should be a list of cons cells of the form (\\\u0026#34;key\\\u0026#34; . \\\u0026#34;headline\\\u0026#34;)\u0026#34; `(defhydra ,hydraname (:color blue :after-exit (unless (or hydra-deactivate current-prefix-arg) ;If we\u0026#39;re just jumping to a location, quit the hydra (josh/org-refile-hydra/body))) ,file ,@(cl-loop for kv in keyandheadline collect (list (car kv) (list \u0026#39;josh/refile file (cdr kv) \u0026#39;current-prefix-arg) (cdr kv))) (\u0026#34;q\u0026#34; nil \u0026#34;cancel\u0026#34;))) ;;;;;;;;;; ;; Here we\u0026#39;ll define our refile headlines ;;;;;;;;;; (josh/make-org-refile-hydra josh/org-refile-hydra-file-ds \u0026#34;~/my_org/datascience.org\u0026#34; ((\u0026#34;1\u0026#34; . \u0026#34;@Datascience @Inbox\u0026#34;) (\u0026#34;2\u0026#34; . \u0026#34;@Datascience @Notes\u0026#34;))) (josh/make-org-refile-hydra josh/org-refile-hydra-file-bgr \u0026#34;~/my_org/bgr.org\u0026#34; ((\u0026#34;1\u0026#34; . \u0026#34;#BGR #Inbox\u0026#34;) (\u0026#34;2\u0026#34; . \u0026#34;#questions @ BGR\u0026#34;) (\u0026#34;3\u0026#34; . \u0026#34;Inventory management Project\u0026#34;))) (josh/make-org-refile-hydra josh/org-refile-hydra-file-todoglobal \u0026#34;todo-global.org\u0026#34; ((\u0026#34;1\u0026#34; . \u0026#34;;Emacs Stuff\u0026#34;) (\u0026#34;2\u0026#34; . \u0026#34;;someday\u0026#34;))) (defhydra josh/org-refile-hydra (:foreign-keys run) \u0026#34;Refile\u0026#34; (\u0026#34;a\u0026#34; josh/org-refile-hydra-file-ds/body \u0026#34;File A\u0026#34; :exit t) (\u0026#34;b\u0026#34; josh/org-refile-hydra-file-bgr/body \u0026#34;File B\u0026#34; :exit t) (\u0026#34;c\u0026#34; josh/org-refile-hydra-file-todoglobal/body \u0026#34;File C\u0026#34; :exit t) (\u0026#34;j\u0026#34; org-refile-goto-last-stored \u0026#34;Jump to last refile\u0026#34; :exit t) (\u0026#34;q\u0026#34; nil \u0026#34;cancel\u0026#34;)) (global-set-key (kbd \u0026#34;\u0026lt;f8\u0026gt; r\u0026#34;) \u0026#39;josh/org-refile-hydra/body) Window manipulation Source : Hydra documentation\n;; Hydras for window configuration. Using the deluxe (defhydra hydra-window () \u0026#34; Movement^^ ^Split^ ^Switch^\t^Resize^ ---------------------------------------------------------------- _h_ ← _v_ertical _b_uffer\t_q_ X← _j_ ↓ _x_ horizontal\t_f_ind files\t_w_ X↓ _k_ ↑ _z_ undo _a_ce 1\t_e_ X↑ _l_ → _Z_ reset _s_wap\t_r_ X→ _F_ollow\t_D_lt Other _S_ave\tmax_i_mize _SPC_ cancel\t_o_nly this _d_elete \u0026#34; (\u0026#34;h\u0026#34; windmove-left ) (\u0026#34;j\u0026#34; windmove-down ) (\u0026#34;k\u0026#34; windmove-up ) (\u0026#34;l\u0026#34; windmove-right ) (\u0026#34;q\u0026#34; hydra-move-splitter-left) (\u0026#34;w\u0026#34; hydra-move-splitter-down) (\u0026#34;e\u0026#34; hydra-move-splitter-up) (\u0026#34;r\u0026#34; hydra-move-splitter-right) (\u0026#34;b\u0026#34; helm-mini) (\u0026#34;f\u0026#34; helm-find-files) (\u0026#34;F\u0026#34; follow-mode) (\u0026#34;a\u0026#34; (lambda () (interactive) (ace-window 1) (add-hook \u0026#39;ace-window-end-once-hook \u0026#39;hydra-window/body)) ) (\u0026#34;v\u0026#34; (lambda () (interactive) (split-window-right) (windmove-right)) ) (\u0026#34;x\u0026#34; (lambda () (interactive) (split-window-below) (windmove-down)) ) (\u0026#34;s\u0026#34; (lambda () (interactive) (ace-window 4) (add-hook \u0026#39;ace-window-end-once-hook \u0026#39;hydra-window/body))) (\u0026#34;S\u0026#34; save-buffer) (\u0026#34;d\u0026#34; delete-window) (\u0026#34;D\u0026#34; (lambda () (interactive) (ace-window 16) (add-hook \u0026#39;ace-window-end-once-hook \u0026#39;hydra-window/body)) ) (\u0026#34;o\u0026#34; delete-other-windows) (\u0026#34;i\u0026#34; ace-maximize-window) (\u0026#34;z\u0026#34; (progn (winner-undo) (setq this-command \u0026#39;winner-undo)) ) (\u0026#34;Z\u0026#34; winner-redo) (\u0026#34;SPC\u0026#34; nil) ) (global-set-key (kbd \u0026#34;\u0026lt;f8\u0026gt; w\u0026#34;) \u0026#39;hydra-window/body) helm-do-ag in specific locations Reference: https://emacs.stackexchange.com/questions/44128/function-to-do-helm-do-ag-for-a-specific-project\nIn project directory (defun helm-do-ag-projects () \u0026#34;Grep string in Project directory\u0026#34; (interactive) (let ((rootdir (concat \u0026#34;~/my_projects/\u0026#34;))) (let ((helm-ag-command-option (concat helm-ag-command-option \u0026#34;\u0026#34;))) (helm-do-ag rootdir)))) Scimax config directory (defun helm-do-ag-emacs-config () \u0026#34;Grep string in Emacs custom code\u0026#34; (interactive) (let ((rootdir (concat \u0026#34;~/scimax/user/sr-cust/\u0026#34;))) (let ((helm-ag-command-option (concat helm-ag-command-option \u0026#34;\u0026#34;))) (helm-do-ag rootdir)))) Journal directory (defun helm-do-ag-journal () \u0026#34;Grep string in journal directory\u0026#34; (interactive) (let ((specfile (concat \u0026#34;~/my_org/journal/\u0026#34;))) (let ((helm-ag-command-option (concat helm-ag-command-option \u0026#34;\u0026#34;))) (helm-ag-this-file specfile)))) BGR file (defun helm-do-ag-bgr () \u0026#34;Grep string in BGR file\u0026#34; (interactive) (let ((specfile (concat \u0026#34;~/my_org/bgr.org\u0026#34;))) (let ((helm-ag-command-option (concat helm-ag-command-option \u0026#34;\u0026#34;))) (helm-do-ag-this-file specfile)))) Defining hydra (defhydra shrysr/hydra-helm-ag-do-menu () \u0026#34; Helm-do-ag in specified locations ^location^ ^command^ ---------------------------------------------------------- e: emacs custom config b: bgr file o: org files j: journal search \u0026#34; (\u0026#34;e\u0026#34; helm-do-ag-emacs-config) (\u0026#34;j\u0026#34; helm-do-ag-journal :color blue) (\u0026#34;p\u0026#34; helm-do-ag-projects) (\u0026#34;o\u0026#34; helm-do-ag-org) (\u0026#34;q\u0026#34; quit-window \u0026#34;quit\u0026#34; :color red)) (global-set-key (kbd \u0026#34;\u0026lt;f8\u0026gt; h\u0026#34;) \u0026#39;shrysr/hydra-helm-ag-do-menu/body) Frame configurations fo magit and project launch Scimax - magit and windows ;; scimax directory magit status (defun sr/windows-magit-scimax () (interactive) (ace-delete-other-windows) (dired \u0026#34;~/scimax/user/\u0026#34;) (switch-window-then-split-right nil) (magit-status \u0026#34;~/scimax/\u0026#34;) (switch-window) (split-window-vertically) (dired-up-directory) (windmove-right) ) Org files - magit and windows ;; my_org magit status (defun sr/windows-magit-org () (interactive) (ace-delete-other-windows) (magit-status \u0026#34;~/my_org/\u0026#34;) ) Project directory - magit and windows ;; magit status (defun sr/windows-magit-projects () (interactive) (ace-delete-other-windows) (switch-window-then-split-right nil) (magit-status \u0026#34;~/my_projects/\u0026#34;) (switch-window) (dired \u0026#34;~/my_projects/\u0026#34;) (switch-window) ) TODO Project: Switch and windows  Note taken on [2019-02-10 Sun 07:09]  Experiment with helm-swoop functions to target only top level headings  (defun sr/windows-projects () (interactive) (ace-delete-other-windows) (switch-window-then-split-right nil) (projectile-switch-project) (switch-window) (find-file \u0026#34;~/my_org/project-tasks.org\u0026#34;) (widen) (helm-org-rifle-current-buffer) (org-narrow-to-subtree) (outline-show-children) ) Defining Hydra (defhydra sr/process-window-keys () \u0026#34; Key^^ ^Workflow^ -------------------- o org magit s scimax magit p projects magit w select project and set window config SPC exit \u0026#34; (\u0026#34;o\u0026#34; sr/windows-magit-org ) (\u0026#34;p\u0026#34; sr/windows-magit-projects ) (\u0026#34;s\u0026#34; sr/windows-magit-scimax ) (\u0026#34;w\u0026#34; sr/windows-projects) (\u0026#34;SPC\u0026#34; nil) ) (global-set-key (kbd \u0026#34;\u0026lt;f8\u0026gt; m\u0026#34;) \u0026#39;sr/process-window-keys/body) Loading completed (message \u0026#34;Loaded Hydras\u0026#34;) Elfeed customisation  Note taken on [2019-07-08 Mon 08:10]  Disabling elfeed for now.  Elfeed Basic + Customisations Source: http://heikkil.github.io/blog/2015/05/09/notes-from-elfeed-entries/\n;; Elfeed configuration source : (use-package elfeed :bind (:map elfeed-search-mode-map (\u0026#34;A\u0026#34; . bjm/elfeed-show-all) (\u0026#34;E\u0026#34; . bjm/elfeed-show-emacs) (\u0026#34;D\u0026#34; . bjm/elfeed-show-daily) (\u0026#34;q\u0026#34; . bjm/elfeed-save-db-and-bury)) :init (setq my/default-elfeed-search-filter \u0026#34;@1-month-ago +unread !sport \u0026#34;) (setq-default elfeed-search-filter my/default-elfeed-search-filter) (setq elfeed-db-direcory \u0026#34;~/scimax/user/elfeeddb\u0026#34;) :config (elfeed-org) (elfeed-goodies/setup) ;; ;; linking and capturing ;; (defun elfeed-link-title (entry) \u0026#34;Copy the entry title and URL as org link to the clipboard.\u0026#34; (interactive) (let* ((link (elfeed-entry-link entry)) (title (elfeed-entry-title entry)) (titlelink (concat \u0026#34;[[\u0026#34; link \u0026#34;][\u0026#34; title \u0026#34;]]\u0026#34;))) (when titlelink (kill-new titlelink) (x-set-selection \u0026#39;PRIMARY titlelink) (message \u0026#34;Yanked: %s\u0026#34; titlelink)))) ;; show mode (defun elfeed-show-link-title () \u0026#34;Copy the current entry title and URL as org link to the clipboard.\u0026#34; (interactive) (elfeed-link-title elfeed-show-entry)) (defun elfeed-show-quick-url-note () \u0026#34;Fastest way to capture entry link to org agenda from elfeed show mode\u0026#34; (interactive) (elfeed-link-title elfeed-show-entry) (org-capture nil \u0026#34;n\u0026#34;) (yank) (org-capture-finalize)) (bind-keys :map elfeed-show-mode-map (\u0026#34;l\u0026#34; . elfeed-show-link-title) (\u0026#34;v\u0026#34; . elfeed-show-quick-url-note)) ;; search mode (defun elfeed-search-link-title () \u0026#34;Copy the current entry title and URL as org link to the clipboard.\u0026#34; (interactive) (let ((entries (elfeed-search-selected))) (cl-loop for entry in entries when (elfeed-entry-link entry) do (elfeed-link-title entry)))) (defun elfeed-search-quick-url-note () \u0026#34;In search mode, capture the title and link for the selected entry or entries in org aganda.\u0026#34; (interactive) (let ((entries (elfeed-search-selected))) (cl-loop for entry in entries do (elfeed-untag entry \u0026#39;unread) when (elfeed-entry-link entry) do (elfeed-link-title entry) do (org-capture nil \u0026#34;n\u0026#34;) do (yank) do (org-capture-finalize) (mapc #\u0026#39;elfeed-search-update-entry entries)) (unless (use-region-p) (forward-line)))) (bind-keys :map elfeed-search-mode-map (\u0026#34;l\u0026#34; . elfeed-search-link-title) (\u0026#34;v\u0026#34; . elfeed-search-quick-url-note)) ;;functions to support syncing .elfeed between machines ;;makes sure elfeed reads index from disk before launching (defun bjm/elfeed-load-db-and-open () \u0026#34;Wrapper to load the elfeed db from disk before opening\u0026#34; (interactive) (elfeed-db-load) (elfeed) (elfeed-search-update--force)) ;;write to disk when quiting (defun bjm/elfeed-save-db-and-bury () \u0026#34;Wrapper to save the elfeed db to disk before burying buffer\u0026#34; (interactive) (elfeed-db-save) (quit-window)) ) Elfeed-org and elfeed-goodies setup [/] Using an org source is the easiest way to organise my RSS feeds for reading with Elfeed.\n;; use an org file to organise feeds (use-package elfeed-org :ensure t :config (setq rmh-elfeed-org-files (list \u0026#34;~/my_org/elfeed.org\u0026#34;)) ) (use-package elfeed-goodies :ensure t :init (elfeed-goodies/setup) ) TODO Consider storing the Feed sources here in org format  Note taken on [2019-02-17 Sun 18:11]  This will need an export to a source org file per the settings.  Loading completed (message \u0026#34;Loaded Elfeed customisations\u0026#34;) w3m customisation w3m is a suprisingly able browser that is able to cater to most websites, except those that are a little too rich with java and etc. Being within Emacs, and launching almost instantly with significantly less overhead in terms of RAM no matter how many tabs are open - it is also easy to customise the behavior as needed and is an excellent method of distraction free browsing.\nHowever, it pays to have handy shortcuts to open a link in the default browser of the OS. This is especially to cater to heavier websites. The w3m package would need to be installed using the package manager of the OS to use w3m.\nA few snippets were sourced from: http://beatofthegeek.com/2014/02/my-setup-for-using-emacs-as-web-browser.html\nSetting default browser to be w3m ;;(setq browse-url-browser-function \u0026#39;browse-url-default-browser) (setq browse-url-browser-function \u0026#39;w3m-goto-url-new-session) (setq w3m-default-display-inline-images t) TODO Appending HTTP to web addresses entered by hand  Note taken on [2019-02-07 Thu 07:40]  Check whether this is necessary  ;;when I want to enter the web address all by hand (defun w3m-open-site (site) \u0026#34;Opens site in new w3m session with \u0026#39;http://\u0026#39; appended\u0026#34; (interactive (list (read-string \u0026#34;Enter website address(default: w3m-home):\u0026#34; nil nil w3m-home-page nil ))) (w3m-goto-url-new-session (concat \u0026#34;http://\u0026#34; site))) Changing w3m shortcuts for better tabbed browsing Source: Sacha Chua : http://sachachua.com/blog/2008/09/emacs-and-w3m-making-tabbed-browsing-easier/\n(eval-after-load \u0026#39;w3m \u0026#39;(progn (define-key w3m-mode-map \u0026#34;q\u0026#34; \u0026#39;w3m-previous-buffer) (define-key w3m-mode-map \u0026#34;w\u0026#34; \u0026#39;w3m-next-buffer) (define-key w3m-mode-map \u0026#34;x\u0026#34; \u0026#39;w3m-close-window))) TODO Default external browser settings  Note taken on [2019-02-07 Thu 07:37]  Need to have this change depending whether the OS is Linux or Mac OS  (defun wicked/w3m-open-current-page-in-default-browser () \u0026#34;Open the current URL in Mozilla Firefox.\u0026#34; (interactive) (browse-url-default-browser w3m-current-url)) ;; (1) (defun wicked/w3m-open-link-or-image-in-default-browser () \u0026#34;Open the current link or image in Firefox.\u0026#34; (interactive) (browse-url-default-browser (or (w3m-anchor) ;; (2) (w3m-image)))) ;; (3) (eval-after-load \u0026#39;w3m \u0026#39;(progn (define-key w3m-mode-map \u0026#34;o\u0026#34; \u0026#39;wicked/w3m-open-current-page-in-default-browser) (define-key w3m-mode-map \u0026#34;O\u0026#34; \u0026#39;wicked/w3m-open-link-or-image-in-default-browser))) Wikipedia search (defun wikipedia-search (search-term) \u0026#34;Search for SEARCH-TERM on wikipedia\u0026#34; (interactive (let ((term (if mark-active (buffer-substring (region-beginning) (region-end)) (word-at-point)))) (list (read-string (format \u0026#34;Wikipedia (%s):\u0026#34; term) nil nil term))) ) (browse-url (concat \u0026#34;http://en.m.wikipedia.org/w/index.php?search=\u0026#34; search-term )) ) Access Hacker News (defun hn () (interactive) (browse-url \u0026#34;http://news.ycombinator.com\u0026#34;)) TODO Open specific browser depending on the URL  Note taken on [2019-03-07 Thu 11:59]  This is worth setting up. It would be convenient for frequently visited websites like reddit and others, to open in the external browser, especially as they do not render well within w3m.  Source : http://ergoemacs.org/emacs/emacs%5Fset%5Fdefault%5Fbrowser.Html\n;; use browser depending on url (setq browse-url-browser-function \u0026#39;( (\u0026#34;wikipedia\\\\.org\u0026#34; . browse-url-firefox) (\u0026#34;github\u0026#34; . browse-url-chromium) (\u0026#34;thefreedictionary\\\\.com\u0026#34; . eww-browse-url) (\u0026#34;.\u0026#34; . browse-url-default-browser) )) ediff I have to diff between org files pretty often, and need the headings to be unfolded.\nSource: http://emacs.stackexchange.com/questions/21335/prevent-folding-org-files-opened-by-ediff\n;; Check for org mode and existence of buffer (defun f-ediff-org-showhide (buf command \u0026amp;rest cmdargs) \u0026#34;If buffer exists and is orgmode then execute command\u0026#34; (when buf (when (eq (buffer-local-value \u0026#39;major-mode (get-buffer buf)) \u0026#39;org-mode) (save-excursion (set-buffer buf) (apply command cmdargs))))) (defun f-ediff-org-unfold-tree-element () \u0026#34;Unfold tree at diff location\u0026#34; (f-ediff-org-showhide ediff-buffer-A \u0026#39;org-reveal) (f-ediff-org-showhide ediff-buffer-B \u0026#39;org-reveal) (f-ediff-org-showhide ediff-buffer-C \u0026#39;org-reveal)) (defun f-ediff-org-fold-tree () \u0026#34;Fold tree back to top level\u0026#34; (f-ediff-org-showhide ediff-buffer-A \u0026#39;hide-sublevels 1) (f-ediff-org-showhide ediff-buffer-B \u0026#39;hide-sublevels 1) (f-ediff-org-showhide ediff-buffer-C \u0026#39;hide-sublevels 1)) (add-hook \u0026#39;ediff-select-hook \u0026#39;f-ediff-org-unfold-tree-element) (add-hook \u0026#39;ediff-unselect-hook \u0026#39;f-ediff-org-fold-tree) Hugo Function to create specific properties for a blog post Modified this function from:\nTODO Defining content directory  Note taken on [2019-02-07 Thu 08:06]  Need to check if this is still required since I have switche to ox-hugo  (defvar hugo-content-dir \u0026#34;~/my_gits/hugo-sr/content/post/\u0026#34; \u0026#34;Path to Hugo\u0026#39;s content directory\u0026#34;) Ensuring properties exist and creating if they dont exist (defun hugo-ensure-property (property) \u0026#34;Make sure that a property exists. If not, it will be created. Returns the property name if the property has been created, otherwise nil.\u0026#34; (org-id-get-create) (if (org-entry-get nil property) nil (progn (org-entry-put nil property \u0026#34;\u0026#34;) property))) (defun hugo-ensure-properties () (require \u0026#39;dash) (let ((current-time (format-time-string (org-time-stamp-format t t) (org-current-time))) first) (save-excursion (setq first (--first it (mapcar #\u0026#39;hugo-ensure-property \u0026#39;(\u0026#34;HUGO_TAGS\u0026#34; \u0026#34;HUGO_CATEGORIES\u0026#34;)))) (unless (org-entry-get nil \u0026#34;HUGO_DATE\u0026#34;) (org-entry-put nil \u0026#34;EXPORT_DATE\u0026#34; current-time))) (org-entry-put nil \u0026#34;EXPORT_FILE_NAME\u0026#34; (org-id-get-create)) (org-entry-put nil \u0026#34;EXPORT_HUGO_CUSTOM_FRONT_MATTER\u0026#34; \u0026#34;:profile false\u0026#34;) (when first (goto-char (org-entry-beginning-position)) ;; The following opens the drawer (forward-line 1) (beginning-of-line 1) (when (looking-at org-drawer-regexp) (org-flag-drawer nil)) ;; And now move to the drawer property (search-forward (concat \u0026#34;:\u0026#34; first \u0026#34;:\u0026#34;)) (end-of-line)) first)) Hugo function calling the above (defun hugo () (interactive) (unless (hugo-ensure-properties) (let* ((type (concat \u0026#34;type = \\\u0026#34;\u0026#34; (org-entry-get nil \u0026#34;HUGO_TYPE\u0026#34;) \u0026#34;\\\u0026#34;\\n\u0026#34;)) (date (concat \u0026#34;date = \\\u0026#34;\u0026#34; (format-time-string \u0026#34;%Y-%m-%d\u0026#34; (apply \u0026#39;encode-time (org-parse-time-string (org-entry-get nil \u0026#34;HUGO_DATE\u0026#34;))) t) \u0026#34;\\\u0026#34;\\n\u0026#34;)) (tags (concat \u0026#34;tags = [ \\\u0026#34;\u0026#34; (mapconcat \u0026#39;identity (split-string (org-entry-get nil \u0026#34;HUGO_TAGS\u0026#34;) \u0026#34;\\\\( *, *\\\\)\u0026#34; t) \u0026#34;\\\u0026#34;, \\\u0026#34;\u0026#34;) \u0026#34;\\\u0026#34; ]\\n\u0026#34;)) (fm (concat \u0026#34;+++\\n\u0026#34; title type date tags topics \u0026#34;+++\\n\\n\u0026#34;)) (coding-system-for-write buffer-file-coding-system) (backend \u0026#39;md) (blog)) ;; try to load org-mode/contrib/lisp/ox-gfm.el and use it as backend (if (require \u0026#39;ox-gfm nil t) (setq backend \u0026#39;gfm) (require \u0026#39;ox-md)) (setq blog (org-export-as backend t)) ;; Normalize save file path (unless (string-match \u0026#34;^[/~]\u0026#34; file) (setq file (concat hugo-content-dir file)) (unless (string-match \u0026#34;\\\\.md$\u0026#34; file) (setq file (concat file \u0026#34;.md\u0026#34;))) ;; save markdown (with-temp-buffer (insert fm) (insert blog) (untabify (point-min) (point-max)) (write-file file) (message \u0026#34;Exported to %s\u0026#34; file)))))) ox-hugo setup (use-package ox-hugo :ensure t :defer t :after ox :custom (org-hugo--tag-processing-fn-replace-with-hyphens-maybe t) ) TODO LOB  Note taken on [2019-04-25 Thu 07:39]  Since shifting to using org-brain for permanent notes and snippets, I need to review this ingest.  There are a bunch of scripts that I would like ingested into the Library of Babel to be available for ready use. In some cases, with specific and relatively simple actions these are useful, and generally easier to define that Emacs Functions.\n(org-babel-lob-ingest \u0026#34;~/my_projects/sr-snip-lob/README.org\u0026#34;) Scimax customisations These are settings which custmise scimax specific variables. These are separated out here so that it becomes easier to try out Emacs configurations that are outside scimax.\norg-Db  `org-db\u0026rsquo; is an org-mode database. When it is active every org-mode file you visit will be indexed into a sqlite database. In each file, each headline with its title, tags and properties are stored, and every link in each file is stored.\nThis becomes useful because you can then search all of your org-files and jump to different locations.\nScimax help documentation\n (use-package emacsql-sqlite :ensure t :config (require \u0026#39;org-db) ) Scimax autoformat and corrections  Note taken on [2019-03-07 Thu 16:24]  Changing keyboard shortcut for equation insertion as this interferes with i3wm functioning.  Note: any expansion can be undone with C-/\n(add-hook \u0026#39;org-mode-hook \u0026#39;scimax-autoformat-mode) (scimax-toggle-abbrevs \u0026#39;scimax-month-abbreviations +1) (scimax-toggle-abbrevs \u0026#39;scimax-transposition-abbreviations +1) (scimax-toggle-abbrevs \u0026#39;scimax-misc-abbreviations nil) (scimax-toggle-abbrevs \u0026#39;scimax-weekday-abbreviations +1) (global-set-key (kbd \u0026#34;s-q\u0026#34;) \u0026#39;org-latex-math-region-or-point) Scimax Hotspots (setq scimax-user-hotspot-commands \u0026#39;((\u0026#34;Agenda All\u0026#34; . (lambda () (org-agenda \u0026#34;\u0026#34; \u0026#34;a\u0026#34;))) (\u0026#34;Agenda Office\u0026#34; . (lambda () (org-agenda \u0026#34;\u0026#34; \u0026#34;o\u0026#34;))) (\u0026#34;Mail\u0026#34; . (lambda () (if (get-buffer \u0026#34;*mu4e-headers*\u0026#34;) (progn (switch-to-buffer \u0026#34;*mu4e-headers*\u0026#34;) (delete-other-windows)) (mu4e)))) (\u0026#34;Bookmarks\u0026#34; . (lambda () (helm-source-bookmarks))) (\u0026#34;Reload Scimax babel\u0026#34; . (lambda () (org-babel-load-file (expand-file-name \u0026#34;sr-config.org\u0026#34; user-emacs-directory)))) ) ) (setq scimax-user-hotspot-locations \u0026#39;( (\u0026#34;CV Org\u0026#34; . \u0026#34;~/org_cv/CV_Shreyas_Ragavan.org\u0026#34;) (\u0026#34;scd - scimax dir\u0026#34; . \u0026#34;~/scimax/\u0026#34; ) (\u0026#34;scu - scimax user dir\u0026#34; . \u0026#34;~/scimax/user/\u0026#34;) ( \u0026#34;sco - scimax org conf\u0026#34; . \u0026#34;~/scimax/user/sr-config.org\u0026#34;) (\u0026#34;blog\u0026#34; . \u0026#34;~/my_org/blog-book.org\u0026#34;) (\u0026#34;github\u0026#34; . \u0026#34;~/my_gits/\u0026#34;) (\u0026#34;project\u0026#34; . \u0026#34;~/my_projects/\u0026#34;) (\u0026#34;cheatsheet\u0026#34; . \u0026#34;~/my_projects/ds_cheatsheets/\u0026#34;) (\u0026#34;passwords\u0026#34; . \u0026#34;~/my_org/secrets.org.gpg\u0026#34;) (\u0026#34;references\u0026#34; . \u0026#34;~/Dropbox/bibliography/references.bib\u0026#34;) ) ) Scimax Elfeed (require \u0026#39;scimax-elfeed) Scimax Notebook directory (setq nb-notebook-directory \u0026#34;~/my_projects/\u0026#34;) Scimax notebook (global-set-key (kbd \u0026#34;M-s n\u0026#34;) \u0026#39;nb-open) Enabling Scimax Statistics (require \u0026#39;scimax-statistics) TODO Scimax Python (require \u0026#39;scimax-org-babel-python) (require \u0026#39;ob-ipython) (require \u0026#39;scimax-ob) (require \u0026#39;scimax-org-babel-ipython-upstream) (setq ob-ipython-exception-results nil) (scimax-ob-ipython-turn-on-eldoc) TODO Bibliography settings and customisation This was setup a long time ago to convert past technical repots into org mode, with references made in correct technical style. This project is on hold.\n(require \u0026#39;doi-utils) (require \u0026#39;org-ref-wos) (require \u0026#39;org-ref-pubmed) (require \u0026#39;org-ref-arxiv) (require \u0026#39;org-ref-bibtex) (require \u0026#39;org-ref-pdf) (require \u0026#39;org-ref-url-utils) (require \u0026#39;org-ref-helm) ;; note and bib location (setq org-ref-bibliography-notes \u0026#34;~/my_org/references/references.org\u0026#34; org-ref-bibliography-notes \u0026#34;~/my_org/references/research_notes.org\u0026#34; org-ref-default-bibliography \u0026#39;(\u0026#34;~/my_org/references/references.bib\u0026#34;) org-ref-pdf-directory \u0026#34;~/my_org/references/pdfs/\u0026#34;) ;; setting up helm-bibtex (setq helm-bibtex-bibliography \u0026#34;~/my_org/references/references.bib\u0026#34; helm-bibtex-library-path \u0026#34;~/my_org/org/references/pdfs\u0026#34; helm-bibtex-notes-path \u0026#34;~/my_org/references/research_notes.org\u0026#34;) Message : loaded scimax Customisations (message \u0026#34;Loaded scimax customisations\u0026#34;) Python [0/4] Using miniconda NEXT setup virtual environment approach NEXT setup conda, especially for auto complete General config  Note taken on [2019-02-12 Tue 14:52]  This is to take care of the annoying indentation message that always pops up.  (setq python-indent-guess-indent-offset nil) NEXT Autocomplete for python blocks (add-to-list \u0026#39;company-backends \u0026#39;company-ob-ipython) (company-mode) NEXT Emacs-jupyter  Note taken on [2019-02-12 Tue 14:48]  Since I am more familiar with ob-ipython and there are a bunch of interesting features already implemented in it like the automatic setting of a kernel and file names for graphic outputs and so on - I will explore jupyter-emacs at a later date.  (use-package jupyter :ensure t :defer t :config ;(org-babel-load-languages \u0026#39;(jupyter .t)) (setq org-babel-default-header-args:jupyter-python \u0026#39;((:async . \u0026#34;yes\u0026#34;) (:session . \u0026#34;jipython\u0026#34;) (:kernel . \u0026#34;python3\u0026#34;))) ) TEST Alfred Integration Source: https://github.com/jjasghar/alfred-org-capture\n(if (system-type-is-darwin) (progn ;;; Code: (defun make-orgcapture-frame () \u0026#34;Create a new frame and run org-capture.\u0026#34; (interactive) (make-frame \u0026#39;((name . \u0026#34;remember\u0026#34;) (width . 80) (height . 16) (top . 400) (left . 300) (font . \u0026#34;-apple-Monaco-medium-normal-normal-*-13-*-*-*-m-0-iso10646-1\u0026#34;) )) (select-frame-by-name \u0026#34;remember\u0026#34;) (org-capture)) ) ) TODO Project publishing setup [0/3] This is under construction and was initially started with the idea of having custom publishing settings for different projects. I was initially looking at this for publishing my hugo blog. However, the need has been negated with the excellent ox-hugo package.\nTEST ox-Tufte  Note taken on [2019-07-04 Thu 11:20]  Minor experiments are completed with this package. However, detailed exploration is required to incorporate intoa workflow.   This is an export backend for Org-mode that exports buffers to HTML that is compatible with Tufte CSS out of the box (meaning no CSS modifications needed).\nIt’s still a work-in-progress, but it works well right now.\nGithub\n (use-package ox-tufte :defer t :config (require \u0026#39;ox-tufte) ) TODO Exporting org projects ( setq org-publish-project-alist \u0026#39;( (\u0026#34;org-repo\u0026#34; :base-directory \u0026#34;./\u0026#34; :base-extension \u0026#34;org\u0026#34; :publishing-directory \u0026#34;/Users/shreyas/my_projects/dotemacs\u0026#34; :EXPORT_FILE_NAME \u0026#34;README.org\u0026#34; :recursive f :publishing-function org-html-publish-to-html ;; :html-head \u0026#34;\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;http://dakrone.github.io/org2.css\u0026#34; type=\u0026#34;text/css\u0026#34; /\u0026gt;\u0026#34; ) (\u0026#34;md\u0026#34; :base-directory \u0026#34;./\u0026#34; :base-extension \u0026#34;org\u0026#34; :publishing-directory \u0026#34;./export/\u0026#34; :recursive t :publishing-function org-md-export-to-markdown ) (\u0026#34;Documentation - html + md\u0026#34; :components (\u0026#34;html-static\u0026#34; \u0026#34;md\u0026#34; ) ))) TEST Function for exporting dotemacs config [1\u0026frasl;3] Note taken on [2019-02-14 Thu 14:05]  Save the filename as variables. Note taken on [2019-02-14 Thu 13:30]  Add a condition to check if the directory exists. Note taken on [2019-02-10 Sun 07:16]  Add a line to revert target export files if they are open. Prefer exporting the org file rather than copying.  This is the beginning of a function to perform 3 exports:\n Export to my hugo website as a part of my documentation (ox-hugo) Copy the org file to my github repo. Tangle the copied org file to the above github repository to have the script ready.  Maintaining the documentation on my website does not make it easy to others to view the changes in the configuration and fork or download the same as an org file or emacs-lisp script. Therefore the config that I publish should be maintained in it\u0026rsquo;s own repository.\nAs of now, I\u0026rsquo;m calling this function from my Emacs config file, and need to improve the above workflow.\n(defun sr/dotemacs-export() (interactive) \u0026#34;If directories exist - exporting Org config to Hugo blog, and to Github repository org file and lisp\u0026#34; (if (file-directory-p \u0026#34;~/my_projects/dotemacs\u0026#34;) (progn (copy-file \u0026#34;~/scimax/user/sr-config.org\u0026#34; \u0026#34;~/my_projects/dotemacs/README.org\u0026#34; \u0026#34;OK-IF-ALREADY-EXISTS\u0026#34;) (copy-file \u0026#34;~/scimax/user/sr-config.el\u0026#34; \u0026#34;~/my_projects/dotemacs/config.el\u0026#34; \u0026#34;OK-IF-ALREADY-EXISTS\u0026#34;) ;; (org-babel-tangle-file \u0026#34;~/my_projects/dotemacs/README.org\u0026#34; \u0026#34;~/my_projects/dotemacs/config.el\u0026#34;) ) ) (if (file-directory-p \u0026#34;~/my_gits/hugo-sr\u0026#34;) (progn (org-hugo-export-to-md) ) ) ) TODO mu4e  Note taken on [2019-02-12 Tue 14:53]  The use-package documentation specifies a method to do this via use-package itself, without enclosing the whole snippet within a if clause. Note taken on [2019-02-07 Thu 20:43]  The mu4e config has to be broken down and the send email with htmlize has to be evaluated. Note taken on [2019-02-07 Thu 09:04]  As of now, I do not acess my email on different computers via Emacs. The end goal is to setup a mail server via VPS and store my email online, which can then be searched via Emacs and mu4e from any location.  (if (system-type-is-darwin) (progn (add-to-list \u0026#39;load-path \u0026#34;/usr/local/share/emacs/site-lisp/mu4e\u0026#34;) (require \u0026#39;mu4e) (require \u0026#39;mu4e-contrib) (require \u0026#39;org-mu4e) (setq mue4e-headers-skip-duplicates t mu4e-view-show-images t mu4e-view-show-addresses \u0026#39;t mu4e-compose-format-flowed nil mu4e-update-interval 200 message-ignored-cited-headers \u0026#39;nil mu4e-date-format \u0026#34;%y/%m/%d\u0026#34; mu4e-headers-date-format \u0026#34;%Y/%m/%d\u0026#34; mu4e-change-filenames-when-moving t mu4e-attachments-dir \u0026#34;~/Downloads/Mail-Attachments/\u0026#34; mu4e-maildir (expand-file-name \u0026#34;~/my_mail/fmail\u0026#34;) ) ;; mu4e email refiling loations (setq mu4e-refile-folder \u0026#34;/Archive\u0026#34; mu4e-trash-folder \u0026#34;/Trash\u0026#34; mu4e-sent-folder \u0026#34;/Sent\u0026#34; mu4e-drafts-folder \u0026#34;/Drafts\u0026#34; ) ;; setup some handy shortcuts (setq mu4e-maildir-shortcuts \u0026#39;((\u0026#34;/INBOX\u0026#34; . ?i) (\u0026#34;/Sent\u0026#34; . ?s) (\u0026#34;/Archive\u0026#34; . ?a) (\u0026#34;/Trash\u0026#34; . ?t))) ;;store link to message if in header view, not to header query (setq org-mu4e-link-query-in-headers-mode nil org-mu4e-convert-to-html t) ;; org -\u0026gt; html ;; Enabling view in browser for HTML heavy emails that don\u0026#39;t render well (add-to-list \u0026#39;mu4e-view-actions \u0026#39;(\u0026#34;ViewInBrowser\u0026#34; . mu4e-action-view-in-browser) t) (autoload \u0026#39;mu4e \u0026#34;mu4e\u0026#34; \u0026#34;mu for Emacs.\u0026#34; t) ;; Config for sending email (setq message-send-mail-function \u0026#39;message-send-mail-with-sendmail send-mail-function \u0026#39;sendmail-send-it message-kill-buffer-on-exit t ) ;; allow for updating mail using \u0026#39;U\u0026#39; in the main view: (setq mu4e-get-mail-command \u0026#34;mbsync -a -q\u0026#34;) ;; Don\u0026#39;t keep asking for confirmation for every action (defun my-mu4e-mark-execute-all-no-confirm () \u0026#34;Execute all marks without confirmation.\u0026#34; (interactive) (mu4e-mark-execute-all \u0026#39;no-confirm)) ;; mapping x to above function (define-key mu4e-headers-mode-map \u0026#34;x\u0026#34; #\u0026#39;my-mu4e-mark-execute-all-no-confirm) ;; source: http://matt.hackinghistory.ca/2016/11/18/sending-html-mail-with-mu4e/ ;; this is stolen from John but it didn\u0026#39;t work for me until I ;; made those changes to mu4e-compose.el (defun htmlize-and-send () \u0026#34;When in an org-mu4e-compose-org-mode message, htmlize and send it.\u0026#34; (interactive) (when (member \u0026#39;org~mu4e-mime-switch-headers-or-body post-command-hook) (org-mime-htmlize) (org-mu4e-compose-org-mode) (mu4e-compose-mode) (message-send-and-exit))) ;; This overloads the amazing C-c C-c commands in org-mode with one more function ;; namely the htmlize-and-send, above. (add-hook \u0026#39;org-ctrl-c-ctrl-c-hook \u0026#39;htmlize-and-send t) )) frog jump buffer This package provides a nifty little pop up containing a list of buffers (that can be filtered), and enables jumping to the specified buffer with just a single key press.\n(use-package frog-jump-buffer :ensure t :defer t :config ) easy-kill and easy mark  Note taken on [2019-04-25 Thu 07:48]  The line selection, \u0026lsquo;e\u0026rsquo;, does not pick up lines separated with a full stop. Instead the entire paragraph is being selected.   Provide commands easy-kill and easy-mark to let users kill or mark things easily.\nGithub\n This looks like a very handy package. The easiest way to get started is to cycle through the selections and use the help. Activate the command with M-w and ? for help which provides the list of key bindings. Alternately, use SPC to cycle through the options available.\n(use-package easy-kill :config (global-set-key [remap kill-ring-save] \u0026#39;easy-kill) (global-set-key [remap mark-sexp] \u0026#39;easy-mark) ) Theme and visuals Emacsclient or frame specific settings Since I run emacs as a daemon and call the emacsclient, the background has to be set for new frames. Additionally, I\u0026rsquo;d like the frames to launch full screen.\n(setq default-frame-alist \u0026#39;(;; (background-color . \u0026#34;whitesmoke\u0026#34;) ;; (foreground-color . \u0026#34;black\u0026#34;) (fullscreen . maximized) )) Custom Safe themes and Background change to light grey (setq custom-safe-themes t) ;; (set-background-color \u0026#34;whitesmoke\u0026#34;) Disabling leuven and loading other theme (disable-theme \u0026#39;leuven) ;;(load-theme \u0026#39;spacemacs-dark t) (load-theme \u0026#39;zenburn t) TEST Initial setup of Zenburn ;; use variable-pitch fonts for some headings and titles (setq zenburn-use-variable-pitch t) ;; scale headings in org-mode (setq zenburn-scale-org-headlines t) ;; scale headings in outline-mode (setq zenburn-scale-outline-headlines t) TEST Use-package based template for customising zenburn Source: https://github.com/m-parashar/emax64/issues/5\n(use-package zenburn-theme :demand t :config (load-theme \u0026#39;zenburn t) (set-face-attribute \u0026#39;font-lock-comment-face nil :italic t) (set-face-attribute \u0026#39;font-lock-doc-face nil :italic t) (zenburn-with-color-variables (set-face-attribute \u0026#39;button nil :foreground zenburn-yellow-2) (set-face-attribute \u0026#39;default nil :background zenburn-bg-05 :height mp/font-size-default :font mp/font-family) (set-face-attribute \u0026#39;help-argument-name nil :foreground zenburn-orange :italic nil) (set-face-attribute \u0026#39;hl-line nil :background zenburn-bg+1) (set-face-attribute \u0026#39;header-line nil :background zenburn-bg-1 :box `(:line-width 2 :color ,zenburn-bg-1) :height mp/font-size-header-line) (set-face-attribute \u0026#39;mode-line nil :box `(:line-width 2 :color ,zenburn-bg-1) :foreground zenburn-bg+3 :height mp/font-size-mode-line) (set-face-attribute \u0026#39;mode-line-inactive nil :box `(:line-width 2 :color ,zenburn-bg-05) :foreground zenburn-bg+3 :height mp/font-size-mode-line) (set-face-attribute \u0026#39;region nil :background zenburn-fg-1 :distant-foreground \u0026#39;unspecified) (set-face-attribute \u0026#39;vertical-border nil :foreground zenburn-bg)) ;; NOTE: See https://github.com/bbatsov/zenburn-emacs/issues/278. (zenburn-with-color-variables (mapc (lambda (face) (when (eq (face-attribute face :background) zenburn-bg) (set-face-attribute face nil :background \u0026#39;unspecified))) (face-list)))) Font Customisation based on OS The same font is named differently in Antergos (Linux) and in the Mac OS.\n;; For Linux (if (system-type-is-gnu) (set-face-attribute \u0026#39;default nil :family \u0026#34;ttf-iosevka\u0026#34; :height 140)) ;; For Mac OS (if (system-type-is-darwin) (set-face-attribute \u0026#39;default nil :family \u0026#34;Iosevka Type\u0026#34; :height 160 )) Setting font faces for headline level  Note taken on [2019-03-28 Thu 07:09]  This is available as in-built settings for the zenburn theme. However, once the font is changed, the  (custom-set-faces \u0026#39;(org-level-1 ((t (:inherit outline-1 :height 1.2)))) \u0026#39;(org-level-2 ((t (:inherit outline-2 :height 1.1)))) \u0026#39;(org-level-3 ((t (:inherit outline-3 :height 1.05)))) \u0026#39;(org-level-4 ((t (:inherit outline-4 :height 1.00)))) \u0026#39;(org-level-5 ((t (:inherit outline-5 :height .95)))) ) TEST Spaceline : modeline configuration Source: http://pragmaticemacs.com/emacs/get-that-spacemacs-look-without-spacemacs/\n(use-package spaceline :demand t :init (setq powerline-default-separator \u0026#39;arrow-fade) :config (disable-theme \u0026#39;smart-mode-line-light) (require \u0026#39;spaceline-config) (spaceline-emacs-theme) (spaceline-toggle-buffer-position-off) ) TODO Basic cosmetics. Review \u0026amp; Convert to use-package style  Note taken on [2019-02-07 Thu 08:20]  These settings have to be cleaned up and the code optimised.  (setq org-hide-leading-stars t) ;;(setq org-alphabetical-lists t) (setq org-src-fontify-natively t) ;; you want this to activate coloring in blocks (setq org-src-tab-acts-natively t) ;; you want this to have completion in blocks (setq org-hide-emphasis-markers t) ;; to hide the *,=, or / markers (setq org-pretty-entities t) ;; to have \\alpha, \\to and others display as utf8 http://orgmode.org/manual/Special-symbols.html ;; Highlighting lines in the agenda, where the cursor is placed. (add-hook \u0026#39;org-agenda-mode-hook (lambda () (hl-line-mode 1))) ;; Setting up clean indenting below respective headlines at startup. - from the org mode website (setq org-startup-indented t) ;; ;; use org bullets from emacsist ;; (use-package org-bullets ;; :ensure t ;; :init ;; :config ;; (add-hook \u0026#39;org-mode-hook (lambda () (org-bullets-mode 1)))) Striking out Done headlines source: Sacha Chua\n(setq org-fontify-done-headline t) (custom-set-faces \u0026#39;(org-done ((t (:foreground \u0026#34;PaleGreen\u0026#34; :weight normal :strike-through t)))) \u0026#39;(org-headline-done ((((class color) (min-colors 16) (background dark)) (:foreground \u0026#34;LightSalmon\u0026#34; :strike-through t))))) Formatting keywords as boxes with inverted colors Source : SO link ,\n(set-face-attribute \u0026#39;org-todo nil :box \u0026#39;(:line-width 2 :color \u0026#34;black\u0026#34; :style released-button) :inverse-video t ) (set-face-attribute \u0026#39;org-done nil :box \u0026#39;(:line-width 2 :color \u0026#34;black\u0026#34; :style released-button) :inverse-video t ) (set-face-attribute \u0026#39;org-priority nil :inherit font-lock-keyword-face :inverse-video t :box \u0026#39;(:line-width 2 :color \u0026#34;black\u0026#34; :style released-button) ) TEST Background color for org source Blocks ;;(set-face-background \u0026#39;org-block-emacs-lisp \u0026#34;black\u0026#34;) (set-face-background \u0026#39;org-block \u0026#34;black\u0026#34;) visual-fill-column Source: https://github.com/wasamasa/dotemacs/blob/master/init.org\nI call the visual line mode once the visual fill column is called. In this way I can ensure that the columns are as long as I want them to be and the lines are globally visually filled.\nFor some strange reason, the visual column mode seems to be removed every time the file is saved (when a single buffer is in view). When the window is split, the mode comes back on.\n(use-package visual-fill-column :ensure t :config (global-visual-fill-column-mode) (setq-default fill-column 80) (setq-default visual-fill-column-center-text t) (setq split-window-preferred-function \u0026#39;visual-fill-column-split-window-sensibly) (add-hook \u0026#39;visual-fill-column-mode-hook #\u0026#39;visual-line-mode) (add-hook \u0026#39;org-mode-hook \u0026#39;turn-on-visual-fill-column-mode) )","date":1562788546,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562788546,"objectID":"c65676284286527aff7ae2f7eccfc28f","permalink":"https://shrysr.github.io/docs/sr-config/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/sr-config/","section":"docs","summary":"Introduction This is my literate, Org-mode based configuration for Emacs, which are essentially customisations built on top of the starter-kit Scimax. View a nicely rendered version with easy navigation on my website, or if you prefer: on github.\n Scimax - Awesome editing for scientists and engineers. Scimax is an Emacs starterkit for scientists and engineers. It provides a comprehensive configuration of Emacs for scientific programming and publishing.\nJohn Kitchin","tags":["Emacs"],"title":"My Emacs + Scimax configuration","type":"docs"},{"authors":null,"categories":["Linux"],"content":" Installing the Iosevka font On Debian distros There appear to be no packages for iosevka for debian. The prescribed method is to add the fonts to the fonts folder. The github issues point towards a PPA which can be added. However, this did not work for me, and I had to resort to manual means.\nDownloading the specified font version from github into a temp folder\ncd ~/temp wget \u0026#34;https://github.com/be5invis/Iosevka/releases/download/v2.2.1/01-iosevka-2.2.1.zip\u0026#34; Extracting the contents of the downloaded zip file to a folder named iosevka.\ncd ~/temp unzip -u 01-iosevka-2.2.1.zip -d iosevka For system wide recognition, the ttf files have to be placed in usr/share/fonts as per the debian wiki. Sudo permission is required for writing to this location. Optionally, the font folder can also be copied to ~/.local/share/fonts/, for a user specific setting.\nsudo cp -r ~/temp/iosevka /usr/share/fonts/ Finally, it is a good idea to refresh the font cache\nfc-cache -fv To set the font in Emacs:\n(set-face-attribute \u0026#39;default nil :family \u0026#34;ttf-iosevka\u0026#34; :height 140) Note: The file permissions for the ttf files have to be set to 644 to be usable. This should be checked if the above does not work.\nTODO On Arch / Antergos Use AUR to install iosevka in Antergos / Arch as the package is already available.\nyay -S ttf-iosevka Setting the font in Emacs. This should be added to the init. The font height could vary based on the monitor size.\n(set-face-attribute \u0026#39;default nil :family \u0026#34;ttf-iosevka\u0026#34; :height 120) Installing iosevka in Debian:\nThe font files have to be downloaded and placed in to the location /usr/local/share/Fonts for system wide access.\nSetup gpg-agent to be running whenever gpg is called For some reason, it appears though the gpg-agent is shown to be running, this configuration is required to make sure that the entered keys are stored in the keyring.\ncat \u0026gt;\u0026gt; ~/.gnupg/gpg.conf \u0026lt;\u0026lt;EOF no-greeting no-permission-warning lock-never keyserver-options timeout=10 use-agent EOF Install tk especially for being able to select the CRAN mirrors in R This is pertinent to Arch based distros.\nsudo pacman -S tk Git global config git config --global user.email \u0026#34;abcs@gmail.com\u0026#34; git config --global user.name \u0026#34;Mad Max\u0026#34; Upgrading a debian distro sudo apt-get update sudo apt-get dist-upgrade App installation in debian using flatpak Some apps are not available in the so called stable debian software archives. Therefore alternative sources have to be established for the same.\nInstalling flatpak on debian and adding the flatpak repository:\nsudo apt-get install flatpak sudo flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo Reboot after the above commands.\nNote: Calling a flatpak based app is rather verbose, and is better served by defining appropriate aliases.\nFranz: Multi-network messenger This app covers Slack and Whatsap and other networks. It still takes up about 1GB of RAM and the app itself is about 500MB, but it atleast covers all the platforms in one go and should be useful in the office.\nIn addition, the org.freedesktop.Platform package has to be installed. The latter gets installed automatically, when executed in the terminal.\nPre-requisites for debian/ubuntu\nsudo apt install libx11-dev libxext-dev libxss-dev libxkbfile-devflatpak install flathub com.meetfranz.Franz Slack: The Slack app takes up a lot of memory.\nflatpak install flathub com.slack.Slack Swapping control and Capslock Creating xmodmap script : Swapping control and capslock keys Source: link\ncat \u0026gt; ~/.xmodmap \u0026lt;\u0026lt;EOF ! ! Swap Caps_Lock and Control_L ! remove Lock = Caps_Lock remove Control = Control_L keysym Control_L = Caps_Lock keysym Caps_Lock = Control_L add Lock = Caps_Lock add Control = Control_L EOF Executing xmodmap on the configuration above\nxmodmap ~/.xmodmap TODO The above command should be added as the last command in the autostart option of ~/.config cat \u0026gt; ~/.config/ Installing Firefox developer edition The developer edition of Firefox contains interesting features, and it appears to perform better. The developer edition is available as a package on Arch Linux (AUR). For Debian, the procedure is a little round-about.\nThe following procedure using flatpak is picked up from the Debian wiki page.\nUsing flatpak\nUnofficial builds are provided by Fedora at https://firefox-flatpak.mojefedora.Cz/\nsudo apt install flatpak sudo flatpak remote-add --from gnome https://sdk.gnome.org/gnome.flatpakrepo sudo flatpak remote-add --from org.mozilla.FirefoxRepo https://firefox-flatpak.mojefedora.cz/org.mozilla.FirefoxRepo.flatpakrepo Then for \u0026ldquo;developer edition\u0026rdquo; (aka \u0026ldquo;Beta\u0026rdquo;):\nflatpak install org.mozilla.FirefoxRepo org.mozilla.FirefoxDevEdition and Running:\nflatpak run org.mozilla.FirefoxRepo org.mozilla.FirefoxNightly The Debian wiki also describes a method to add the flatpak installations to the Path. However, this is a newer feature and is unavailable at the moment on my machine.\necho \u0026#39;export PATH=$PATH:/var/lib/flatpak/exports/bin\u0026#39; \u0026gt;\u0026gt; ~/.zshrc Emacs can be installed via Conda The advantage of using conda is being able to quickly install reasonably recent versions of Emacs quickly on Debian type OS\u0026rsquo;s which often reference older (stable) versions of software packages by default. Using conda would avoid adding PPA\u0026rsquo;s or hunting for binaries or even compiling from source. Another advantage is that this approach can be used cross platform.\nOne disadvantage of this method is that the package is installed into the miniconda / anaconda package installation path. Though the instillation script of miniconda adds the path for bash, it has to be manually set for any other shell like zsh. However, once this is done - there appear to be no issues in using Emacs.\nconda install -c conda-forge emacs Virtualbox: resizing virtual disk image - vdi Reference: http://derekmolloy.ie/resize-a-virtualbox-disk\nIt does not appear to be possible to expand the size of a fixed format vdi. The floating format has a disadvantage of a read-write overhead for expanding the disk image as it is utilised.\nHowever, as per the documentation, after the hard disk size reaches a stable stage, this overhead becomes negligible on an average.\nTherefore the vdi has to be copied (or cloned), and the floating format has to be selected. This is done using the copy option in the virtualbox media manager. Once copied, the expanded vdi image has to be attached to the guest OS.\nWhen the attachment is complete, the hardisk will show up in the virtualbox media manager app. Now the vdi size can be adjusted to the desired value.\nThe next step is to download the live iso of gparted. This should be loaded as a storage device with the live CD option selected. With this loaded, the existing partitions have to be changed appropriately1. This step has to be done to enable Linux to recognise the expanded harddisk.\nOnce this has been, the gparted iso can be removed and the guest OS can be booted as usual. However, the UUID of the paritions have to be changed appropriately. If not changed, there will be delay during boot, especially if the swap partition has been modified.\nThe actual partition setup and the UUIDs can be viewed with:\nlsblk -f The appropriate UUID has to be replaced in the file /etc/fstab. Technically, the fstab file is generated by the command mkinitcpio, but sometimes a manual change is necessary.\nDowngrading a single package in Arch linux From the Arch linux wiki : archive : downgrading via downloading the Package from URL. Find the package you want under /packages and let pacman fetch it for installation. For example:\npacman -U https://archive.archlinux.org/packages/ ... packagename.pkg.tar.xz Downgrading via local cache\npacman -U /var/cache/pacman/pkg/\u0026lt;package-name\u0026gt; It seems to be a very good idea to maintain a few older versions of packages in the cache, even at the expense of Harddisk space.\nFurther options are provided at this Unix stack exchange discussion.\n It is likely that the swap partition is the last partition, and the previous partition is the root which has to be extended. In this case, the swap has to be deleted and the root partiion should be expanded to the desired size, leaving behind room for the swap partition. The final unallocated space has to be used for a new extension partition and then a logical partition to create the linux-swap. For some reason, there is a space of 1MB preceding the swap partition. ^   ","date":1562464396,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562464396,"objectID":"cc24663f79dfeaba481bfa9b2e745c77","permalink":"https://shrysr.github.io/docs/linux-notes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/linux-notes/","section":"docs","summary":"Installing the Iosevka font On Debian distros There appear to be no packages for iosevka for debian. The prescribed method is to add the fonts to the fonts folder. The github issues point towards a PPA which can be added. However, this did not work for me, and I had to resort to manual means.\nDownloading the specified font version from github into a temp folder\ncd ~/temp wget \u0026#34;https://github.","tags":["Linux"],"title":"Linux notes","type":"docs"},{"authors":null,"categories":["programming","database","NoSQL"],"content":" Introduction These are my notes on NoSQL databases and the prime differences between them and SQL databases. The notes are mostly based off the Udemy course Introduction to MongoDB, and therefore primarily focused on using MongoDB at the moment.\nMethodology and Tools Installing Mongodb The instructions are available in the mongoDB manual. This is for the Community edition, and on a Mac as welll as Linux machine (Antergos)\nMac If never installed before, tap the resource first.\nbrew tap mongodb/brew Actual installation: Note the version being specified. This could change in the future. It may be possible that specifying mongodb-community along is sufficient to get the latest version, otherwise a specific version shellould be specified.\nbrew install mongodb-community@4.0 To know the packages available, a search could be performed using brew. However, the latest package 4.0 is not listed in the search.\nbrew search mongodb-community Antergos (Linux) Mongodb and Compass are available in AUR. The development and beta versions of these packages are also available. Note: the Arch wiki clearly states that the mongodb package builds from source and will take several hours to complete. The pre-compiled bin package is the better choice.\nSearching for relevant Packages:\nyaourt -Ss mongodb Installing packages:\nyaourt -S mongodb-bin yaourt -S mongodb-compass-community Note that mongodb-compass does not install mongodb as a requirement or dependency. There also seem to be a lot of python 2 dependencies for mongodb. This can be viewed during the build process.\nConfiguration files and paths The following directories and files are created during the installation:\n the configuration file (/usr/local/etc/mongod.Conf) the log directory path (/usr/local/var/log/Mongodb) the data directory path (/usr/local/var/mongodb)  Running mongoDB It appears that the config file cannot be set without activating mongoDB as a service or a daemon first, the config file cannot be set.\nAs a service via brew:\nbrew services start mongodb-community@4.0 Setting the configuration file:\nmongod --config /usr/local/etc/mongod.conf Check whether mongoDB is Running\nmongod Running the above shows an error that the socket is already in use, which prevents mongodb from starting. I wonder if this is because of the earlier hugo server running at the same IP as specified in the config file.\nPerhaps a restart will help? This would not mean the process using the 27017 port woult magically stop.\nError shell output:\n#+name: name2019-03-29T11:12:12.579-0600 I CONTROL [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols \u0026#39;none\u0026#39; 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] MongoDB starting : pid=7885 port=27017 dbpath=/data/db 64-bit host=Shreyass-MacBook-Pro-2.local 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] db version v4.0.7 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] git version: 1b82c812a9c0bbf6dc79d5400de9ea99e6ffa025 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] allocator: system 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] modules: none 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] build environment: 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] distarch: x86_64 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] target_arch: x86_64 2019-03-29T11:12:12.590-0600 I CONTROL [initandlisten] options: {} 2019-03-29T11:12:12.591-0600 E STORAGE [initandlisten] Failed to set up listener: SocketException: Address already in use 2019-03-29T11:12:12.611-0600 I CONTROL [initandlisten] now exiting 2019-03-29T11:12:12.611-0600 I CONTROL [initandlisten] shutting down with code:48 One solution for this has been to change the port number while launching mongod Server. Since the port 2717 is busy, the subsequent (or an arbitrary) port number can be used.\nmongod --port 27018 This brought up a new error related to the path of the database. This can be seen below with dbpath = /data/db which does not exist.\n2019-03-29T21:01:31.704-0600 I CONTROL [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols \u0026#39;none\u0026#39; 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] MongoDB starting : pid=2791 port=27018 dbpath=/data/db 64-bit host=Shreyass-MacBook-Pro-2.local 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] db version v4.0.7 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] git version: 1b82c812a9c0bbf6dc79d5400de9ea99e6ffa025 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] allocator: system 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] modules: none 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] build environment: 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] distarch: x86_64 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] target_arch: x86_64 2019-03-29T21:01:31.714-0600 I CONTROL [initandlisten] options: { net: { port: 27018 } } 2019-03-29T21:01:31.714-0600 I STORAGE [initandlisten] exception in initAndListen: NonExistentPath: Data directory /data/db not found., terminating 2019-03-29T21:01:31.714-0600 I NETWORK [initandlisten] shutdown: going to close listening sockets... 2019-03-29T21:01:31.741-0600 I NETWORK [initandlisten] removing socket file: /tmp/mongodb-27018.sock 2019-03-29T21:01:31.741-0600 I CONTROL [initandlisten] now exiting 2019-03-29T21:01:31.742-0600 I CONTROL [initandlisten] shutting down with code:100 Stack Overflow discussions indicate that there are atleast 2 possible ways to resolve this as shown below.\n Create the /data/db folder and assign the user read and write permission for the same.  sudo mkdir /data/db/ sudo chmod 600 /data/db  Start the mongod process in a specified directory.  mongod --port 27018 --dbpath ~/temp/ I have followed the latter approach to begin with, as the port number and path can always be changed.\nGeneral exploration of mongo Shell Type in mongo in the terminal to enter the mongo shell.\nmongo Showing a list of the available dbs. The admin, config and local dbs are created by default during installation.\nmongo show dbs The use command can be employed to switch to db\u0026rsquo;s, or create dbs.\nmongo use test Collection: similar to the concept of a bunch of tables in Sql. db.createCollection('\u0026lt;name\u0026gt;'). Existing collections can be viewed with show connections\nmongo use test db.createCollection(\u0026#39;test1\u0026#39;) show collections Note that the name of the collection should be enclosed within single quotes and not double quotes.\nInserting values in a Database or collection The Insert method can be used to fill in entries that in a combination of keyword name pairs.\nmongo show dbs db.user.insert({\u0026#39;name\u0026#39; : \u0026#39;shreyas\u0026#39;, \u0026#39;height\u0026#39;: 154}) Adding a few more users with a name and an Age.\nmongo db.user.insert({\u0026#39;name\u0026#39;: \u0026#39;joe\u0026#39;, \u0026#39;age\u0026#39; : 22}) db.user.insert({\u0026#39;name\u0026#39;: \u0026#39;sam\u0026#39;, \u0026#39;age\u0026#39; : 56}) db.user.insert({\u0026#39;name\u0026#39;: \u0026#39;siri\u0026#39;, \u0026#39;age\u0026#39; : 87, \u0026#39;height\u0026#39; : 145}) db.user.insert({\u0026#39;name\u0026#39;: \u0026#39;pitt\u0026#39;, \u0026#39;age\u0026#39; : 60}) Manipulating collections Listing all the entries in the use collection can done with the find method.\nmongo db.user.find() Remove method to remove an Entry (document?)\nmongo db.user.remove({\u0026#39;name\u0026#39; : \u0026#39;joe\u0026#39;}) db.user.find() Alternate specification to remove age above 60\nmongo db.user.remove({\u0026#39;age\u0026#39; : 60}) db.user.find() Other than manually entering entries, there is no way to recover entries that are removed.\nIf no arguments are specifiedd in remove, then all the collections are Removed, as shown below.\nmongo db.users.remove({}) Queries using Find mongo show dbs db.user.find() The Objectid is added by mongoDB. This is a unique key generated for each document.\nGrabbing just one user from the Collection/:\nmongo db.user.find({\u0026#39;name\u0026#39;: \u0026#39;sam\u0026#39;}) Specifying a Condition, will match all the documents that match the condition specified\nmongo db.user.find({\u0026#34;name\u0026#34;:\u0026#34;siri\u0026#34;}) Note: 2 entries and object ID\u0026rsquo;s are being returned even when one document is present. This needs to be Checked.\nConsidering multiple search criterion. For example, not all the documents have the height parameter entered in. The null parameter can be used to filter documents with empty attributes.\nmongo db.user.insert({\u0026#34;name\u0026#34;: \u0026#34;goldstone\u0026#34;, \u0026#34;age\u0026#34;: 50}) db.user.find({\u0026#39;height\u0026#39; : null}) Finding documents or users with age greater than 40. {$gt : 40}. Similarly, use $lt for lesser than.\nmongo db.user.find({\u0026#39;age\u0026#39; : {$gt: 40}})mongo db.user.find({\u0026#34;age\u0026#34;: {$lt : 60}}) Updating users already inserted into the collection Adding the height for Goldston, using db.user.update(). The document to be updated has to be specified first, and then the updated entry has to be keyed in.\nmongo db.user.update({\u0026#34;name\u0026#34; : \u0026#34;goldstone\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;goldstone\u0026#34;, \u0026#34;height\u0026#34; : 167}) db.user.find({\u0026#34;name\u0026#34; : \u0026#34;goldstone\u0026#34;}) db.user.find({\u0026#34;height\u0026#34; : null}) db.user.update({\u0026#34;name\u0026#34; : \u0026#34;sam\u0026#34;}, {\u0026#34;name\u0026#34; : \u0026#34;sam\u0026#34;, \u0026#34;height\u0026#34; : 189}) db.user.find({\u0026#34;height\u0026#34; : null}) Data Types String: enclosed within quotes. Integer: Whole number. Can be positive, negative or zero. Float: positive or negative. Does not have to be a whole number. Boolean: true or false. Quotes are not to be used with Booleans, otherwise it would be converted to a string.\nPrimary Key  Unique for all documents in a collection Cannot have null values. Additional custom keys can be created and should be for easier filtering of the data.  Establishing Relationships  useful to create relationships between documents. One to one One to many many to one  Example of one to many : where the same user id is the connecting property across multiple documents.\nmongo use test2 db.createCollection(\u0026#34;one2onecoll1\u0026#34;) db.createCollection(\u0026#34;one2onecoll2\u0026#34;)mongo db.one2onecoll1.insert({ \u0026#34;user_id\u0026#34; : 3173, \u0026#34;name\u0026#34; : \u0026#34;helen\u0026#34;, \u0026#34;age\u0026#34; : 24}) db.one2onecoll1.insert({ \u0026#34;user_id\u0026#34; : 4545, \u0026#34;name\u0026#34; : \u0026#34;jack\u0026#34;, \u0026#34;age\u0026#34; : 45, }) db.one2onecoll1.insert({ \u0026#34;user_id\u0026#34; : 67866, \u0026#34;name\u0026#34; : \u0026#34;joe\u0026#34;, \u0026#34;age\u0026#34; : 65, \u0026#34;about\u0026#34; : \u0026#34;Lorem ipsum dolor sit amet\u0026#34; })mongo db.one2onecoll1.find() Embedded documents Example of using arrays to establish Relationships. Example, a friend list in a social media network. Similarly, blog posts or comments can be stored as a list of parameters.\n\u0026#34;_id\u0026#34; : ObjectID(\u0026#34;Sdinaskdas123fds\u0026#34;), \u0026#34;name\u0026#34; : \u0026#34;Lydia\u0026#34;, \u0026#34;user_id\u0026#34; : 78787 \u0026#34;friend_ids\u0026#34; : [ 6767, 78788, 99899, 12109 ] Embedded documents versus collections This depends on the data characteristics and should be designed such that all the necessary data could be accessed with a single query.\nThinking Examples:\n Facebook: Homepage is accessing only a specific amount of information. Reddit: Comments are not loaded unless the post is opened. So the comments could be stored as separate documents, so they are not loaded only when the posts are loaded.  Think about how to mimimise the unnecessary loading of data.\nMongoDB compass MongoDB compass is a GUI for MongoDB. It helps with the visualisation of data. Download link. Note: the community edition should be downloaded.\nDepending on the setup, the mongod (daemon?) has to be successfully running so that compass can connect to that instance.\n","date":1562436739,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562436739,"objectID":"9f158cdf7be9cbdc4bc61eff9425ec0a","permalink":"https://shrysr.github.io/docs/nosql-mongodb-notes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/docs/nosql-mongodb-notes/","section":"docs","summary":"Introduction These are my notes on NoSQL databases and the prime differences between them and SQL databases. The notes are mostly based off the Udemy course Introduction to MongoDB, and therefore primarily focused on using MongoDB at the moment.\nMethodology and Tools Installing Mongodb The instructions are available in the mongoDB manual. This is for the Community edition, and on a Mac as welll as Linux machine (Antergos)\nMac If never installed before, tap the resource first.","tags":["NoSQL","Data-Science","mongoDB"],"title":"MongoDB and NoSQL Databases","type":"docs"},{"authors":null,"categories":null,"content":" “I never made one of my discoveries through the process of rational thinking” ― Albert Einstein “To be fully alive, fully human, and completely awake is to be continually thrown out of the nest. To live fully is to be always in no-man’s-land, to experience each moment as completely new and fresh. To live is to be willing to die over and over again. ” ― Pema Chödrön, When Things Fall Apart: Heart Advice for Difficult Times Perfectionism can’t survive unless it is fed with the oxygen of indulgence and paranoia and irrationality. link “Creativity — like human life itself — begins in darkness.”— Julia Cameron, The Artist’s Way “The best way out is always through.” — Robert Frost “If you plan on being anything less than you are capable of being, you will probably be unhappy all the days of your life.” ― Abraham Maslow \u0026ldquo;Success is going from failure to failure without losing enthusiasm.\u0026rdquo; - Winston Churchill “A man who dares to waste an hour of time has not discovered the value of his life.” — Charles Darwin \u0026ldquo;A goal without a plan is just a pipe dream\u0026rdquo; \u0026ldquo;I have no responsibility to live up to what others expect of me. That\u0026rsquo;s their mistake, not my failing.\u0026rdquo; \u0026ndash; Richard Feynman \u0026ldquo;You just can\u0026rsquo;t differentiate between a robot and the very best of humans\u0026rdquo; - Isaac Asimov “Nobody succeeds beyond his or her wildest expectations unless he or she begins with some wild expectations.” - Ralph Charell \u0026ldquo;Be a philosopher; but, amidst all your philosophy, be still a man.” - David Hume, An enquiry concerning human understanding \u0026ldquo;Make your interests gradually wider and more impersonal, until bit by bit the walls of the ego recede, and your life becomes increasingly merged in the universal life.\u0026rdquo; - Bertrand Russell “I don\u0026rsquo;t like that man. I must get to know him better.” - Abraham Lincoln “Always remember that to argue, and win, is to break down the reality of the person you are arguing against. It is painful to lose your reality, so be kind, even if you are right.” - Haruki Murakami When I write, I feel like an armless legless man with a crayon in my mouth. - Kurt Vonnegut \u0026ldquo;Life is too short to not read the very best book you know of right now.\u0026rdquo; - Patrick Collison, Founder of Stripe \u0026ldquo;When you have exhausted all possibilities, remember this - you haven\u0026rsquo;t\u0026rdquo; - Thomas Edison “Knowledge has to be improved, challenged, and increased constantly, or it vanishes.” — Dr.Peter Drucker \u0026ldquo;You take away our top 20 employees and we become a mediocre company\u0026rdquo; - Bill Gates “It took me thirty years to draw that masterpiece in thirty seconds.” - Pablo Picasso Inspiration is for amateurs. The rest of us just show up and get to work. - Chuck Close ","date":1552671780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552671780,"objectID":"fb79f6b5788c80e5cc152eeb85e39e1e","permalink":"https://shrysr.github.io/docs/quotes/","publishdate":"2019-03-15T11:43:00-06:00","relpermalink":"/docs/quotes/","section":"docs","summary":"“I never made one of my discoveries through the process of rational thinking” ― Albert Einstein “To be fully alive, fully human, and completely awake is to be continually thrown out of the nest. To live fully is to be always in no-man’s-land, to experience each moment as completely new and fresh. To live is to be willing to die over and over again. ” ― Pema Chödrön, When Things Fall Apart: Heart Advice for Difficult Times Perfectionism can’t survive unless it is fed with the oxygen of indulgence and paranoia and irrationality.","tags":["Quotes"],"title":"quotes","type":"docs"},{"authors":null,"categories":null,"content":"It\u0026rsquo;s a well known trick that installing a SSD in place of the conventional Hard disk can breathe new life into very old machines. My mid 2010 Macbook Pro is one such example, being over 8 years old.\nIn particular, within Emacs - mu4e responds much more quickly and there is significantly less lag in searching / accessing emails and HTML rendering.\nThe other advantage of using a Mac over Linux is that installation and setup instructions are more often available out the box for the Mac OS (though this is changing). I have access to dedicated apps including Evernote, Dash, Spotify, Whatsap, Slack etc on my Mac. This is in addition to several other high quality apps on the App store.\nI do love using Arch Linux and Antergos and the packing management and rolling OS upgrades are totally cool. However, a little bit of elegance in the user interface and hardware (being available out of the box) does ease up the mind and progress. It takes quite a bit of effort to achieve that unless you are at the level of purely using Emacs as window manager.\nOn the Mac, it is easy to move around virtual desktops and use the magic track pad to rapidly switch between applications as well. I\u0026rsquo;m sure many of these \u0026lsquo;gimmicks\u0026rsquo; may be setup with diligence and due time on Linux through solutions with varying levels of quality.\nHowever, as of today : it\u0026rsquo;s likely I would have struggled with some aspects on Linux that are readily available on other systems. Evernote is an example. After hours of searching for an alternate (and acceptable) solution for software packages that are not yet ported to Linux, I would quite possibly end up making a compromise. Typically, the compromises would mean using Electron or Web based versions of apps, which are often not as powerful as the desktop app, not to mention inconvenient. A prime example would be Evernote, on Arch Linux. Some other examples are apps like Word, Pages, Outlook and Excel and so on, which are more critical.\nUltimately, my preference would be to use a Mac as my daily driver and play around with Linux on a back up computer. In any case, multiple Linux distros can be run on Virtual Box within the Mac.\n","date":1531180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531180800,"objectID":"fd316138721b75ebc19db9ed43b7e613","permalink":"https://shrysr.github.io/post/01252410-853f-4570-858f-f3d609f5def5/","publishdate":"2018-07-10T00:00:00Z","relpermalink":"/post/01252410-853f-4570-858f-f3d609f5def5/","section":"post","summary":"It\u0026rsquo;s a well known trick that installing a SSD in place of the conventional Hard disk can breathe new life into very old machines. My mid 2010 Macbook Pro is one such example, being over 8 years old.\nIn particular, within Emacs - mu4e responds much more quickly and there is significantly less lag in searching / accessing emails and HTML rendering.\nThe other advantage of using a Mac over Linux is that installation and setup instructions are more often available out the box for the Mac OS (though this is changing).","tags":["Emacs","productivity","Mac","Linux"],"title":"An SSD can breathe life into old computers","type":"post"},{"authors":null,"categories":null,"content":" I\u0026rsquo;ve used Evernote since 2014, with over 3k notes of all kinds stored in it. Though I did try to capture everything of interest - the procedure was never fast or streamlined enough for me. The Evernote app runs ridiculously slower on older phones. In particular, being used to the speed of Emacs and Org mode - I was mostly displeased with the Evernote Mac / Windows apps as well. I ended up using the drafts app for writing on iOS devices.\nHowever, using Evernote was still worth due to the availability of an excellent catch-all bucket for multiple kinds of information, that can be searched on demand. I could literally whip up important receipts or scanned copies of a document and it felt wonderful to have that kind of control over your information. This foray was also fueled by the deficiencies of Emacs in mobile apps and the ability to store and refer to rich content and several file types.\nSwitching to DEVONthink Pro (DTP) I\u0026rsquo;ve recently converted to DEVONthink Pro (DTP). Though DTP is Mac / iOS only, I would personally prefer DTP over Evernote. Some advantages of DTP:\n blazing fast application response + search on both iOS and Mac. leverages AI to provide interesting connections between notes and ideas. Users have leveraged these connections to help generate new ideas from unforeseen connections. There\u0026rsquo;s more information here.  so far, my experience is that the notes have to be in a particular format,I.e one article or principal idea per note to enable a sensible matching with other relevant articles. There are several incorrect connections also made.  Better control over content organisation.  Project and folder creation, including separate databases for different kinds of work.  One time payment for a major version of the software, along with discounted upgrades. Ability to index local folders. using multiple \u0026lsquo;databases\u0026rsquo; customised to any workflow, along with the provision of password protection and syncing to multiple sources. ability to confidently store private information based on the encryption and custom syncing options available. Ability to store web archives of Linked in posts (or any content). This was not always possible with Evernote. The iOS share option of clipping to the DEVONthink to go app as a web archive works rather well most of the time. The Evernote plug-in for Chrome/ Firefox works relatively slower. connection with DEVONAgent Pro (a fascinating tool dedicated to customised and deep web search. More on this on another blog post) Deploy scripts on databases / notes and thus allowing custom workflows with particular note categories. DTP can import all your Evernote notes and tags as they are. This worked for me in a single attempt.  It\u0026rsquo;s actually hard to quantify the benefits of using DTP. There are a myriad of features within, including the ability to index locations and script automated workflows.\nFor most of the part, I found the speed and response of Evernote to be frustrating. It hindered a streamlined workflow. There are also additional irritations with respect to the .enex format and being able to encrypt information.\nNo doubt, the ubiquity of Evernote in almost all the platforms (except Linux1) works in its favor. However, the search response with DTP is incredibly rapid and the note viewing experience of DTP is extremely smooth. This is on an ancient mid 2010 macbook pro!\nIt\u0026rsquo;s also worth noting that unlike Evernote - I was actually intrigued enough to correspond with the technical support team of DTP to understand features like indexing a folder, and their responses have been prompt and helpful.\nThe best place to find up to date information is on the DEVONtechnologies forum. Even a deep search on the internet does not lead to many articles about the DEVONthink technologies products.\nSome caveats of DTP  DTP does offer all the flexibility above. However the quality of the Evernote webclipper\u0026rsquo;s output is better in several cases. The uncluttered text grab is not automated well enough. I\u0026rsquo;m yet to discover the best pattern. Several apps offer Evernote integration as a premium feature. Evernote offers a more \u0026lsquo;polished\u0026rsquo; and simpler interface and is mainstream and available on multiple platforms. The note taking editors and capture mechanism is more user friendly.  DEVONagent Pro (DAP) DAP is an intriguing bit of software that facilitates deep searches of the web and developing automated workflows including report development. Their algorithm filters searches from any number of databases / engines / websites to provide the best matches.\nOne could use this to monitor the website of a competitor for news announcements. Or crawl Hackernews for the keyword Datascience. It appears to be a tool that can provide exactly the information that we seek by processing the information out there in the web.\nThis includes generation of mind-map esque graphs connecting keywords in all the search results. I\u0026rsquo;m yet to explore more, but it is very interesting so far, especially to gain an overview of the subject.\nSome Conclusions Exploring DTP in conjunction with DEVONagent Pro is absolutely a worthwhile exercise for those relying a lot on information from the internet for their jobs and work, and those working in an apple eco-system. It has a steep(er) learning curve, but will transform your information management. DAP is also a worthy option to explore to deep search the web on focused topics.\nYes, it is mac only software. I have not been able to find any equivalent apps on windows. Another reason to stick to the Apple-verse.\nThe system is addictive and once a good workflow has been built up, it would be difficult to use anything else.\nArchiving interesting Linked in posts: One of the most killer features of using the DEVON 2 GO app is the ability to capture Linked in posts as web archives. Though not optimal, in terms of the format - it is still extremely useful to rapidly build up a reference database of web resources.\nFootnotes 1 Nixnote is one solution. I\u0026rsquo;ve seen it in action and it is useful, and probably even closer to DEVONthink. However, I could never get it working in Arch Linux reliably.\n","date":1531180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531180800,"objectID":"12fba69aa9b6ae945723d2f4de10e064","permalink":"https://shrysr.github.io/post/ec354a8e-a276-4c89-8560-ce82b1693744/","publishdate":"2018-07-10T00:00:00Z","relpermalink":"/post/ec354a8e-a276-4c89-8560-ce82b1693744/","section":"post","summary":"I\u0026rsquo;ve used Evernote since 2014, with over 3k notes of all kinds stored in it. Though I did try to capture everything of interest - the procedure was never fast or streamlined enough for me. The Evernote app runs ridiculously slower on older phones. In particular, being used to the speed of Emacs and Org mode - I was mostly displeased with the Evernote Mac / Windows apps as well.","tags":["Evernote","note-taking","productivity"],"title":"Switching from Evernote to DEVONtechnologies products","type":"post"},{"authors":null,"categories":null,"content":" Introduction To integrate tasks, reminders, notes, coding workflow into a single framework is no easy challenge. Org mode and Emacs help you do just that.\nAfter trying out several tools, IMHO : Todoist offers the best bang for your buck, especially with it\u0026rsquo;s natural language parsing ability, smooth and reliable sync as well as its multi-platform availability. Many describe Omnifocus to be the king of task management tools, with dedicated apps for different purposes and probably well integrated.\nMy journey veered away from Omnifocus since it is limited to the Apple platform and this is obviously a serious handicap for people (like me) who are often forced to use multiple operating systems and devices distributed between personal and work environments.\nI\u0026rsquo;d religiously managed my tasks on Todoist for over a year via the Chrome extensions/add-ins, the stand alone apps on Windows and the Mac, and on Android as well as iOS.\nHowever, there was something missing in terms of being able to truly capture it all. This led me to Emacs. My search is summarised in this article.\nNeeds versus the software development The real problem surfaced when my needs evolved at a pace and specificity that a general software\u0026rsquo;s development could not cater to. The problem is characterized by an endless wait for seemingly simple features that could make a phenomenal difference to personal workflow and productivity. This feature may range from a small tweak or bugfix to a rewiring of the basic behavior of the program itself.\nAdditionally, the proprietary format of tasks/notes and entries in Todoist or even Evernote is not a comforting aspect. On the other hand, using a simple text file with lists of work or notes is too simplistic to address a complex problem.\nHowever, the issue could be resolved when the simple and ubiquitous Text file is parsed by a system like Org mode with in built and novel routines to filter and present the data in the text file in a very useful. Ultimately the key factor is that the workflow and output can be completely customised as required.\nThings I\u0026rsquo;d like from a task management tool:  Rapid and seamless Task/Note taking ability - could be generic, or specific to a particular project/task. Quick capturing of links and snippets from websites and emails Consistent experience across multiple platforms and very fast sync. Ability to manage personal or work related projects A date management system with atleast reasonably good understanding of natural language Refiling tasks/notes very easily across main tasks or categories or projects Customisable Views of the task summary along with the deadlines Task and Note search and filtering at every level possible Ability to easily export notes to multiple formats and write in some form of markup language so as to take care of formatting on the go. Preferably an all-in-one tool for managing notes, all kinds of writing, research, tasks, recurring reminders, maintaining an activity log/journal, project summaries .. etc. Includes \u0026lsquo;clocking\u0026rsquo; abilities for tasks. Fast keyboard based shortcuts and \u0026lsquo;bookmarks\u0026rsquo; to do all that is required. Recording tasks or notes from the phone, while on the go. Should have the lightest footprint possible in terms of time spent on the tool, as well as system resources with no compromise in benefits derived.  Can it be achieved? Short answer: Yes. Through Emacs.\nSure, several of the above points can be done in Todoist and other tools, in one way or via combining different services.\nHowever, a holistic consideration of the above points indicate a system that is a cross between Todoist and Evernote, capable of being utilised for a multitude of purposes : a customised GTD workflow plus an organiser for notes or writings. Point no 9, could serve to be a concise but incomplete statement of Orgmode\u0026rsquo;s capabilities, and is a stark reminder of Todoist\u0026rsquo;s specific expertise in only task management. Additionally, the above points can be done in orgmode, very, very quickly. Evernote has a great system, but is not as fast, because it indexes a huge variety of content. 1\nExamples of workflows Lets say that while typing up a project summary, I remember an additional task for another project or perhaps need to note down a snippet of generic information. To compensate for the lack of a photographic memory without breaking my on-going workflow - I need to be able to store the task/note/idea in a place that I can easily look up for further processing.\nSuch an activity is not at all streamlined with Todoist, and definitely not so with Evernote. With Org mode its just a C-c c, or Control + c and hit c again. Optionally, a C-cw for refiling the note on the spot if desired. When I hit refile - I can search through my org headings or projects and place the newly captured item exactly where it should be.\nOnce accustomed to the speed of recording stuff with Org-capture, along with the myriad possibilities of auto-save, backups, moving the cursor to the last location you were at, switching to another document/heading at lightning speed and etc - it will be hard to find another system that is truly competitive.\nProject management via Emacs using the excellent projectile package can enable you to find information at a speed that is very pleasing. I have often needed to deal with several customers of different kinds, thoroughly understand their requirements, resolve technical and commercial ambiguities and be able to refer to earlier jobs where something was agreed upon. I\u0026rsquo;ve often worked in projects with a bewildering number of aspects to take care of, along with sporadic infusions of information which could be clarifications or even new information altogether.\nIncluded in project / productivity /relationship management are several subsets of activities like Minutes of Meetings (MOM\u0026rsquo;s), summaries of travel/visits to the customer, telephonic discussions, indications of future projects as well as generic or specific problems.\nUsing Org mode, it is possible create customised workflows and templates to manage all the above aspects, more than any other note taking system, including only handwritten notes. An excellent, comprehensive overview can be found in Bert Hansen\u0026rsquo;s article.\nEverybody\u0026rsquo;s needs are unique Eventually, I guess we all come to realise the fact that each human being is truly unique. Each one of us have our own ways of thinking, being and approaching problems.\nWhile Todoist worked very well for me - I was still bothered by being constrained by it\u0026rsquo;s proprietary format and the lack of a lifetime membership with a one time payment. Money spent should give me a tool that brings supreme value and satisfaction with it. It was also tiresome to take detailed notes on tasks and rely on a separate Simplenote/Evernote system via Sublime Text for this purpose. You may have a different viewpoint. You may want a great GUI design and app that works well on your phone in addition to other environments. 2\nOrgmode is more aligned to people who prefer to get most of their work done on their computers, who are or atleast don\u0026rsquo;t mind being keyboard shortcut freaks and those who would like to take the effort to learn a souped up text editor like Emacs that can evolve to cover a lot of needs efficiently. It\u0026rsquo;s not going to work well for people who need a reminder to pop up on their phones, with a fancy GUI and those who expect a software to work extremely well right out of the box. However, this is Org mode and Emacs\u0026#x2026;. there are ways to sync your iOS / outlook calendar with orgmode\u0026rsquo;s calendar, or with wunderlist or Toodledo. Anything is possible, but it just won\u0026rsquo;t be via some classy GUI..\nConcluding points While it may seem daunting at first - the feeling of being able to search through existing notes to know whether you have met this particular thought/aspect before, can be extremely valuable and very satisfying. There are people like Sacha Chua and Bert Hansen, who\u0026rsquo;ve built complex, efficient, and beautiful workflows through which a great deal of achievement has been made possible using the resulting streamlined tool. As Cal Newport often reiterates in his blog and exploration on productivity - it is important to be able to accurately quantify the time being spent on different things. The awesome-emacs list on github offers several worthy resources, along with the excellent Planet Emacsen.\nThe organiser tool by itself should have the lightest possible footprint in terms of the time taken to enter in stuff. Certainly - most people spend a lifetime in customising emacs and that may seem contrary to the previous point. However, it is possible to quickly reach a certain point that results in a marked improvement in productivity and workflow. Beyond this, leisure time can always be spent in fine-tuning the basic setup and understanding the code better.\nThe customisation options with Emacs and Org mode are literally endless and constrained only by programming skills, or Googling skills to find the code snippet that can get your work done, not to mention social skills in getting help via online communities. This is actually a lot easier than it sounds. While a bunch of people would call this a weakness, there are a large number of people who see the value in a customised tool which will evolve to facilitate a very fast and efficient workflow.\nDeliberate practise towards improvement is certainly boosted when one is able to work consistently in a environment customised to needs and workflows. Using Org mode and Emacs is a firm step in this direction.\nFootnotes 1 While Org mode is optimised for text, it is possible to attach any kind of file to a \u0026lsquo;heading\u0026rsquo;, and use interleave and other techniques to browse and annotate PDF\u0026rsquo;s. The possibilities are too numerous to be covered in a blog post or a single google search.\n2 On iOS - I\u0026rsquo;ve found Drafts is a great app for writing fast and appending the notes to an org file, which can be refiled later, using emacs. One problem I\u0026rsquo;m yet to resolve is that appending to an org file in dropbox, requires a network/internet connection. There should be a way to deal with situations without handy internet available.\n","date":1491177600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491177600,"objectID":"293b8d3f1f538b83ae47bfa2c9adfbc3","permalink":"https://shrysr.github.io/post/2b0b2c79-3f6e-4079-a07d-9e382fda8954/","publishdate":"2017-04-03T00:00:00Z","relpermalink":"/post/2b0b2c79-3f6e-4079-a07d-9e382fda8954/","section":"post","summary":"Introduction To integrate tasks, reminders, notes, coding workflow into a single framework is no easy challenge. Org mode and Emacs help you do just that.\nAfter trying out several tools, IMHO : Todoist offers the best bang for your buck, especially with it\u0026rsquo;s natural language parsing ability, smooth and reliable sync as well as its multi-platform availability. Many describe Omnifocus to be the king of task management tools, with dedicated apps for different purposes and probably well integrated.","tags":["Org mode","Emacs","writing","productivity"],"title":"Getting productive - an exploration into holistic task management","type":"post"},{"authors":null,"categories":null,"content":" EdX  EdX HarvardX PH125.1x Data Science Basics: R.  DataCamp  Intro to SQL\n Data Science R basics included in EdX HarvardX PH125.1x\n Introduction to Tidyverse\n Introduction to R for Finance\n  DataQuest  Data Analyst Path in R\n Git \u0026amp; Version control\n SQL Fundamentals\n  ","date":1487116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487116800,"objectID":"1bce6f50cd96148c211b09ac4568ada8","permalink":"https://shrysr.github.io/project/course-certificate-list/","publishdate":"2017-02-15T00:00:00Z","relpermalink":"/project/course-certificate-list/","section":"project","summary":"List of course certificates completed on platforms like DataCamp, DataQuest, EdX etc.","tags":["python","R","Data-Science","code","Course","Certificate","git","finance"],"title":"Course Certificates","type":"project"},{"authors":null,"categories":null,"content":"Embed your slides or video here using shortcodes. Further details can easily be added using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483254000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483254000,"objectID":"cd6d9d084287506b4668ad90c6aff50a","permalink":"https://shrysr.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00-07:00","relpermalink":"/talk/example-talk/","section":"talk","summary":"Embed your slides or video here using shortcodes. Further details can easily be added using Markdown and $\\rm \\LaTeX$ math code.","tags":null,"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":" It is possible (and prevalent) to create templates to post process CFD Simulation results in ANSYS CFD Post using session (.cse) files. Using Shell scripts, it would then be simple to apply these session files on multiple result files and extract the output dictated by the session file.\nThis python script that enables the user to set the location of: - the session file (.cse) - the CFD result files (.res) - create a BAT script with sequential lines, each calling ANSYS CFD Post with the necessary arguments - run the session script on all the result files available in a particular location. - gracefully exit, removing all the temporary script files.\nCode On Github\nHow it helped  While these operations could be done directly in python, it is easier and simpler to control ANSYS CFD post using a BASH script. Therefore the python program creates a BASH script.   Python script \u0026quot;\u0026quot;\u0026quot; Created on Thu Dec 18 16:10:49 2014 @author: shrysr \u0026quot;\u0026quot;\u0026quot; # Description: # This is a simple program that is designed to apply am ANSYS CFD post macro on all the results available at a particular location, one after the other. There are 3 strings required to be set as input by the user. # 1. The location of the ANSYS CFD Post executable # 2. THe path to the macro file (.cst/.cse) # 3. The folder location where the result files are located. # Note : the \u0026gt;quit command can be written in the post macro to optionally execute the post macro on one file after the other automatically. Otherwise CFD Post has to be quit manually by the user after the macro is applied on each file. ###---------- USER INPUT -------------### # Setting the paths to various locations. CFDPost_loc=r'\u0026quot;C:\\Program Files\\ANSYS Inc\\v145\\CFD-Post\\bin\\cfdpost\u0026quot;' #Setting the path to the ANSYS CFD Post executable. Post_template_loc=r'\u0026quot;C:\\\\example_location\\post_macro.cse\u0026quot;' #Path to the .cse/.cst post macro to be applied. Res_loc=r\u0026quot;Q:\\Queueing_sys\\Completed\\Archive\\Shreyas\u0026quot; #Folder location of the result file path ###---x---x--x-- USER INPUT -x---x---x---x--### #importing required libraries import os import glob import subprocess as sp #Creating BAT script for extracting the list of res files in the current working folder - sorted Date wise def res_list_syn(Res_loc): \u0026quot;\u0026quot;\u0026quot; Grabs all the CFX res files in the chosen location (Res_loc) and stores them in the variable (array) A1. The variableA1 is passed onto another function which uses the array contents Example: \u0026gt;\u0026gt;\u0026gt; Res_loc=r\u0026quot;Q:\\Queueing_sys\\Completed\\Archive\u0026quot; \u0026gt;\u0026gt;\u0026gt; post_syn(Res_loc) \u0026gt;\u0026gt;\u0026gt; return variableA1 \u0026quot;\u0026quot;\u0026quot; print \u0026quot;\u0026quot; print \u0026quot;Grabbing all res files from chosen location.\u0026quot; os.chdir(Res_loc) reslist=glob.glob('*.res') print \u0026quot;Passing the list of res files to the Post_Syn function\u0026quot; post_syn(reslist) def post_syn(variable): print \u0026quot; \u0026quot; print \u0026quot;Listing grabbed res files and creating Post BAT file in chosen location...\u0026quot; print \u0026quot;\u0026quot; post_batname='Post_bat_runner.BAT' post_bat_loc=os.path.join(Res_loc,post_batname) PC=open(post_bat_loc,'w') PC.write('cd /d \u0026quot;%s\u0026quot;\\n'%Res_loc) i=0 while i\u0026lt;len(variable): print \u0026quot;%d --%s\u0026quot; %(i,variable[i]) PC.write('%s -s %s %s\\n' %(CFDPost_loc,Post_template_loc,variable[i])) i+=1 PC.close() print \u0026quot;Running post macro on all the listed Res Files....\u0026quot; print '' sp.call(post_bat_loc) t.sleep(5) print 'Killing temp files...' t.sleep(5) File_killer(Res_loc,'BAT') #Function for deleting temp Files. Prevents Clutter. def File_killer(folder_location, type_of_extension): for variable in glob.glob('%s/*.%s'%(folder_location,type_of_extension)): if os.path.isfile(variable): os.remove(variable) #Starting Program. Geting current working directory print \u0026quot;Hello. Program Launch...--\u0026gt;\u0026quot; print \u0026quot;\u0026quot; print \u0026quot;The chosen result location to be scanned is: %s\u0026quot;%Res_loc print \u0026quot;\u0026quot; print \u0026quot;Starting scan\u0026quot; res_list_syn(Res_loc)  ","date":1369612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1369612800,"objectID":"ab64ac7d1072546b098562ba5c309e1d","permalink":"https://shrysr.github.io/project/cfd-post-processing-python/","publishdate":"2013-05-27T00:00:00Z","relpermalink":"/project/cfd-post-processing-python/","section":"project","summary":"`python` script to help automate post processing of simulations, by applying an extraction macro on multiple result files.","tags":["python","code","automation","CFD"],"title":"CFD Post Processing automation","type":"project"},{"authors":null,"categories":null,"content":" View : CFD-Online Wiki page.\nMotivation During my initial foray into open source CFD and especially getting started with Linux - there was a lot of information that I had to collate from different sources in order to figure out each step. In addition, there were perspectives on performance that could be gained only through experience. Therefore, I plugged back the knowledge gained to the CFD-Online wiki with the idea that it would help any newbie get started a little quicker.\nIn the last few years, the number of courses and the material available on-line on CFD, Linux and applying Numerical techniques has increased substantially. This is somewhat supported by the increasing trend of page views shown on the CFD-Online Wiki. Nevertheless, this document still serves as a useful overview and getting started guide.\nThe documentation explores the idea of Open Source software, and the basic techniques to get started with the exploration. Eg: the different options of running Linux on your current machine as well as the pros and cons of each approach, and the software options available, as well as links to useful and high quality information and tutorials.\n","date":1369612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1369612800,"objectID":"cf8665ab01bfa0ff109cdd1e591b9126","permalink":"https://shrysr.github.io/project/cfd-on-line-wiki/cfd-online-wiki/","publishdate":"2013-05-27T00:00:00Z","relpermalink":"/project/cfd-on-line-wiki/cfd-online-wiki/","section":"project","summary":"Documentation (based on actual exploration) to the popular CFD-Online wiki related to getting started with Open Source CFD.","tags":["documentation","CFD","open-source","Linux"],"title":"Contributions to the CFD-Online Wiki","type":"project"},{"authors":null,"categories":null,"content":"This project utilized MATLAB, Solidworks to research and design a human finger and calculate the range of it\u0026rsquo;s motion. SIMULINK is also utilised to design a PID controller for the wrist.\n","date":1369612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1369612800,"objectID":"efee832f269676d0c1e59ab8b0460559","permalink":"https://shrysr.github.io/project/kinematic-finger-design/kinematic-design-finger/","publishdate":"2013-05-27T00:00:00Z","relpermalink":"/project/kinematic-finger-design/kinematic-design-finger/","section":"project","summary":"This project utilized MATLAB, Solidworks to research and design a human finger and calculate the range of it's motion. SIMULINK is also utilised to design a PID controller for the wrist.","tags":["CAD","code","MATLAB","SIMULINK","Solidworks","Design","Research"],"title":"Design of an Electro-mechanical prosthetic finger, and a PID controller for the wrist.","type":"project"},{"authors":null,"categories":null,"content":"This project undertakes a technology study and survey covering the methods to controlling harmful emission from Diesel engines in particular and the efficacy different technologies. It explores current emission norms and the contradicting formation conditions of NOx and CO.\n","date":1297728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1297728000,"objectID":"b064dc5eb623115eb0997aa2ffb161be","permalink":"https://shrysr.github.io/project/emission-technology-ic/emission-technology/","publishdate":"2011-02-15T00:00:00Z","relpermalink":"/project/emission-technology-ic/emission-technology/","section":"project","summary":"This project undertakes a technology study and survey covering the methods to controlling harmful emission from Diesel engines in particular and the efficacy different technologies. It explores current emission norms and the contradicting formation conditions of NOx and CO","tags":["Combustion","Design","Research","IC Engines","Emission"],"title":"Current Trends of Emission Reduction Technology in Vehicular Diesel Engines.","type":"project"},{"authors":["Shreyas Ragavan"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"0f49ea72dfcdd6b8f374348cbf7c82dd","permalink":"https://shrysr.github.io/publication/emission-study/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/emission-study/","section":"publication","summary":"Combustion is the primary source of vehicular pollution,[1]. The Euro countries recently agreed on the goal that would reduce current vehicular emission , in particular carbon emissions by 85% by 2050. This would mean a 95% reduction in the carbonisation of the transportation sector, which is one of the accepted prolific contributors to pollution,[10]. As will be seen, de-carbonisation is a key issue with vehicular light duty diesel engine emissions, [9],along with reduction in NOx, with the latter being highlighted[3,4]. Two constituents of diesel emissions, Particulate Matter (PM) and NOx are contradictory in the conditions of their formation and hence require a combination of technologies to solve the problem satisfactorily. Consequently, emission reduction technologies are of extreme importance. The most stringent norms are those of Super Ultra Low Emission Vehicles (SULEV) formed by the Environmental Protection Agency (EPA) and the Euro 6 has been proposed and awaiting approval. The author’s opinion of a balanced solution being a combination of several technologies is established. The logical path to this conclusion is presented, duly referenced.","tags":null,"title":"Current Trends of Emission Reduction Technology in Vehicular Diesel Engines","type":"publication"},{"authors":["Shreyas Ragavan"],"categories":null,"content":"","date":1292371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1292371200,"objectID":"b84a9c47d8fe4565fdfcdafd32eb51b2","permalink":"https://shrysr.github.io/publication/kinematic-design-finger/","publishdate":"2010-12-15T00:00:00Z","relpermalink":"/publication/kinematic-design-finger/","section":"publication","summary":"The design of the finger to be attached to a modular prosthetic hand and a controller solution for the wrist are explored in this effort. A novel design of a sliding body has been proposed using a Solidworks model where the outershell, providing form to the finger can be slid in or out off a of a light weight chassis and tightened with a screw. In addition to this the end effector is removabl. This provides an easy method to inspect the mechanism especially as the wiring and the motors are embedded inside.The report deals with key aspects such as the using the forward kinematics (Denavit-Hartenberg equations (DHE)) to component selection for building the model. The wrist is treated as as separate design issue and a Proportional Integral Derivative (PID) controller has been designed and manually tuned to control the rotation of the wrist, using Simulink. Though these continuous equations applied, are assuming ideal conditions, a saturation of the output provides realistic limits and conditions and a more realistic view of what occurs. The results obtained and the tuning process are explained and the conclusions are reached.","tags":null,"title":"Design of an Electro-mechanical Anthropometric finger, and a PID controller for the wrist for applications in Prosthetics","type":"publication"}]